{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "H=200_le_8_3500.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cWACPRL869I4"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Os6feRY6ec_"
      },
      "cell_type": "code",
      "source": [
        "!pip install JSAnimation >/dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngMhg3fB9aA",
        "outputId": "2ee124a6-f097-4f41-c236-15d20433ecb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=642022c7a39bf028758c25f44a49bc635fe621cb96d492780065fe7ba4ff5a33\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "81cc770a-7cab-4b26-fd63-343f7e19e33a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "82ce61b0-5ad2-4a48-b9bb-f18b423f33d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "78768939-e4a3-4945-f3ba-df747086f682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "6343f96a-a08c-4cec-dd7b-87f82557b76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:44: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -16.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  display_frames_as_gif(frames)\n",
        "  env.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 200 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 10 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-8\n",
        "learning_rate = 1e-8\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "735fef75-a18b-4c35-b13e-f982e58e4b48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=3500)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n",
            "resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.990000\n",
            "resetting env. episode 3.000000, reward total was -19.000000. running mean: -20.970100\n",
            "resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.960399\n",
            "resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.950795\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.951287\n",
            "resetting env. episode 7.000000, reward total was -17.000000. running mean: -20.911774\n",
            "resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.912656\n",
            "resetting env. episode 9.000000, reward total was -19.000000. running mean: -20.893530\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.894595\n",
            "resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.885649\n",
            "resetting env. episode 12.000000, reward total was -19.000000. running mean: -20.866792\n",
            "resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.868124\n",
            "resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.869443\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.870749\n",
            "resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.872041\n",
            "resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.873321\n",
            "resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.874587\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.875842\n",
            "resetting env. episode 20.000000, reward total was -18.000000. running mean: -20.847083\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.848612\n",
            "resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.850126\n",
            "resetting env. episode 23.000000, reward total was -20.000000. running mean: -20.841625\n",
            "resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.833209\n",
            "resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.824877\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.826628\n",
            "resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.818362\n",
            "resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.820178\n",
            "resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.821976\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.823756\n",
            "resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.825519\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.827264\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.828991\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.830701\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.832394\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.834070\n",
            "resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.825729\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.827472\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.829197\n",
            "resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.820905\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.822696\n",
            "resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.814469\n",
            "resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.806325\n",
            "resetting env. episode 44.000000, reward total was -19.000000. running mean: -20.788262\n",
            "resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.780379\n",
            "resetting env. episode 46.000000, reward total was -19.000000. running mean: -20.762575\n",
            "resetting env. episode 47.000000, reward total was -19.000000. running mean: -20.744949\n",
            "resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.737500\n",
            "resetting env. episode 49.000000, reward total was -20.000000. running mean: -20.730125\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.732824\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.735495\n",
            "resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.718140\n",
            "resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.710959\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.703849\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.706811\n",
            "resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.709743\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.712645\n",
            "resetting env. episode 58.000000, reward total was -20.000000. running mean: -20.705519\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.708464\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.711379\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.714265\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.707123\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.710051\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.712951\n",
            "resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.705821\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.708763\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.711676\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.714559\n",
            "resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.717413\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.720239\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.713037\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.715906\n",
            "resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.708747\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.711660\n",
            "resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.714543\n",
            "resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.717398\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.720224\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.723022\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.725791\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.728533\n",
            "resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.731248\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.733936\n",
            "resetting env. episode 83.000000, reward total was -19.000000. running mean: -20.716596\n",
            "resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.719430\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.722236\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.725014\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.727763\n",
            "resetting env. episode 88.000000, reward total was -18.000000. running mean: -20.700486\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.703481\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.706446\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.709382\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.712288\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.715165\n",
            "resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.718013\n",
            "resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.710833\n",
            "resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.713725\n",
            "resetting env. episode 97.000000, reward total was -20.000000. running mean: -20.706588\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.709522\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.712427\n",
            "resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.715302\n",
            "resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.718149\n",
            "resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.720968\n",
            "resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.723758\n",
            "resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.726521\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.729255\n",
            "resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.731963\n",
            "resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.724643\n",
            "resetting env. episode 108.000000, reward total was -19.000000. running mean: -20.707397\n",
            "resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.710323\n",
            "resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.703220\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.706187\n",
            "resetting env. episode 112.000000, reward total was -19.000000. running mean: -20.689125\n",
            "resetting env. episode 113.000000, reward total was -19.000000. running mean: -20.672234\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.675512\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.678757\n",
            "resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.671969\n",
            "resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.675249\n",
            "resetting env. episode 118.000000, reward total was -18.000000. running mean: -20.648497\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.652012\n",
            "resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.645492\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.649037\n",
            "resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.642547\n",
            "resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.646121\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.649660\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.643163\n",
            "resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.636732\n",
            "resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.640364\n",
            "resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.643961\n",
            "resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.647521\n",
            "resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.651046\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.654535\n",
            "resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.657990\n",
            "resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.641410\n",
            "resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.644996\n",
            "resetting env. episode 135.000000, reward total was -18.000000. running mean: -20.618546\n",
            "resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.612361\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.606237\n",
            "resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.600175\n",
            "resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.604173\n",
            "resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.608131\n",
            "resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.612050\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.615929\n",
            "resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.609770\n",
            "resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.613672\n",
            "resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.617536\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.621360\n",
            "resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.625147\n",
            "resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.628895\n",
            "resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.632606\n",
            "resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.636280\n",
            "resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.629917\n",
            "resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.623618\n",
            "resetting env. episode 153.000000, reward total was -18.000000. running mean: -20.597382\n",
            "resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.591408\n",
            "resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.595494\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.599539\n",
            "resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.593544\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.597608\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.601632\n",
            "resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.595616\n",
            "resetting env. episode 161.000000, reward total was -18.000000. running mean: -20.569660\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.563963\n",
            "resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.558324\n",
            "resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.552740\n",
            "resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.557213\n",
            "resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.561641\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.566024\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.570364\n",
            "resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.564661\n",
            "resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.569014\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.573324\n",
            "resetting env. episode 172.000000, reward total was -19.000000. running mean: -20.557591\n",
            "resetting env. episode 173.000000, reward total was -19.000000. running mean: -20.542015\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.546595\n",
            "resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.541129\n",
            "resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.525717\n",
            "resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.530460\n",
            "resetting env. episode 178.000000, reward total was -20.000000. running mean: -20.525156\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.529904\n",
            "resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.534605\n",
            "resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.529259\n",
            "resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.533966\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.538627\n",
            "resetting env. episode 184.000000, reward total was -19.000000. running mean: -20.523240\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.528008\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.522728\n",
            "resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.527501\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.532226\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.526903\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.531634\n",
            "resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.536318\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.540955\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.535545\n",
            "resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.540190\n",
            "resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.544788\n",
            "resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.539340\n",
            "resetting env. episode 197.000000, reward total was -17.000000. running mean: -20.503947\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.508907\n",
            "resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.503818\n",
            "resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.508780\n",
            "resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.503692\n",
            "resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.498655\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.503669\n",
            "resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.508632\n",
            "resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.503546\n",
            "resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.498510\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.503525\n",
            "resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.498490\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.503505\n",
            "resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.498470\n",
            "resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.503485\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.508450\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.513366\n",
            "resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.518232\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.513050\n",
            "resetting env. episode 216.000000, reward total was -18.000000. running mean: -20.487919\n",
            "resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.493040\n",
            "resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.498110\n",
            "resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.503129\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.508097\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.513016\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.517886\n",
            "resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.522707\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.527480\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.532205\n",
            "resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.536883\n",
            "resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.541515\n",
            "resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.546099\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.550638\n",
            "resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.555132\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.559581\n",
            "resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.563985\n",
            "resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.558345\n",
            "resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.552762\n",
            "resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.547234\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.551762\n",
            "resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.536244\n",
            "resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.530882\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.535573\n",
            "resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.530217\n",
            "resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.534915\n",
            "resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.529566\n",
            "resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.534270\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.538927\n",
            "resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.543538\n",
            "resetting env. episode 246.000000, reward total was -19.000000. running mean: -20.528103\n",
            "resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.532822\n",
            "resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.537493\n",
            "resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.532119\n",
            "resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.536797\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.541429\n",
            "resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.536015\n",
            "resetting env. episode 253.000000, reward total was -19.000000. running mean: -20.520655\n",
            "resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.505448\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.510394\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.515290\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.520137\n",
            "resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.514936\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.519786\n",
            "resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.524588\n",
            "resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.519343\n",
            "resetting env. episode 262.000000, reward total was -19.000000. running mean: -20.504149\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.509108\n",
            "resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.514017\n",
            "resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.508876\n",
            "resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.513788\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.518650\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.523463\n",
            "resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.518229\n",
            "resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.523046\n",
            "resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.517816\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.522638\n",
            "resetting env. episode 273.000000, reward total was -19.000000. running mean: -20.507411\n",
            "resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.502337\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.507314\n",
            "resetting env. episode 276.000000, reward total was -19.000000. running mean: -20.492241\n",
            "resetting env. episode 277.000000, reward total was -18.000000. running mean: -20.467318\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.472645\n",
            "resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.477919\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.483140\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.488308\n",
            "resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.493425\n",
            "resetting env. episode 283.000000, reward total was -19.000000. running mean: -20.478491\n",
            "resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.483706\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.488869\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.493980\n",
            "resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.499040\n",
            "resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.494050\n",
            "resetting env. episode 289.000000, reward total was -19.000000. running mean: -20.479109\n",
            "resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.474318\n",
            "resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.469575\n",
            "resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.474879\n",
            "resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.470131\n",
            "resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.475429\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.480675\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.485868\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.491010\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.496099\n",
            "resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.491138\n",
            "resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.496227\n",
            "resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.501265\n",
            "resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.496252\n",
            "resetting env. episode 303.000000, reward total was -18.000000. running mean: -20.471290\n",
            "resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.466577\n",
            "resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.461911\n",
            "resetting env. episode 306.000000, reward total was -19.000000. running mean: -20.447292\n",
            "resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.452819\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.458291\n",
            "resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.463708\n",
            "resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.469071\n",
            "resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.474380\n",
            "resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.479636\n",
            "resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.484840\n",
            "resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.489992\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.495092\n",
            "resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.500141\n",
            "resetting env. episode 317.000000, reward total was -19.000000. running mean: -20.485139\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.490288\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.485385\n",
            "resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.490531\n",
            "resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.495626\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.500670\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.505663\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.510606\n",
            "resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.505500\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.510445\n",
            "resetting env. episode 327.000000, reward total was -19.000000. running mean: -20.495341\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.500387\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.505383\n",
            "resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.500330\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.505326\n",
            "resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.510273\n",
            "resetting env. episode 333.000000, reward total was -19.000000. running mean: -20.495170\n",
            "resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.500219\n",
            "resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.495216\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.490264\n",
            "resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.495362\n",
            "resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.490408\n",
            "resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.485504\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.490649\n",
            "resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.485742\n",
            "resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.490885\n",
            "resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.495976\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.501016\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.506006\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.510946\n",
            "resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.515837\n",
            "resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.520678\n",
            "resetting env. episode 349.000000, reward total was -19.000000. running mean: -20.505472\n",
            "resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.510417\n",
            "resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.505313\n",
            "resetting env. episode 352.000000, reward total was -19.000000. running mean: -20.490260\n",
            "resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.485357\n",
            "resetting env. episode 354.000000, reward total was -19.000000. running mean: -20.470503\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.475798\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.481040\n",
            "resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.476230\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.481468\n",
            "resetting env. episode 359.000000, reward total was -16.000000. running mean: -20.436653\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.442286\n",
            "resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.437864\n",
            "resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.443485\n",
            "resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.449050\n",
            "resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.454560\n",
            "resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.460014\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.465414\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.470760\n",
            "resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.476052\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.481292\n",
            "resetting env. episode 370.000000, reward total was -18.000000. running mean: -20.456479\n",
            "resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.451914\n",
            "resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.447395\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.452921\n",
            "resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.448392\n",
            "resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.443908\n",
            "resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.449469\n",
            "resetting env. episode 377.000000, reward total was -19.000000. running mean: -20.434974\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.440624\n",
            "resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.446218\n",
            "resetting env. episode 380.000000, reward total was -19.000000. running mean: -20.431756\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.437438\n",
            "resetting env. episode 382.000000, reward total was -18.000000. running mean: -20.413064\n",
            "resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.418933\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.414744\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.420596\n",
            "resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.426390\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.432127\n",
            "resetting env. episode 388.000000, reward total was -19.000000. running mean: -20.417805\n",
            "resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.413627\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.419491\n",
            "resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.425296\n",
            "resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.431043\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.436733\n",
            "resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.442365\n",
            "resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.437942\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.443562\n",
            "resetting env. episode 397.000000, reward total was -19.000000. running mean: -20.429127\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.434835\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.440487\n",
            "resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.446082\n",
            "resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.451621\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.457105\n",
            "resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.452534\n",
            "resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.458009\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.463429\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.458794\n",
            "resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.464206\n",
            "resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.469564\n",
            "resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.464869\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.470220\n",
            "resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.475518\n",
            "resetting env. episode 412.000000, reward total was -19.000000. running mean: -20.460763\n",
            "resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.466155\n",
            "resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.461493\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.466879\n",
            "resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.462210\n",
            "resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.467588\n",
            "resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.472912\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.478183\n",
            "resetting env. episode 420.000000, reward total was -19.000000. running mean: -20.463401\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.468767\n",
            "resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.464079\n",
            "resetting env. episode 423.000000, reward total was -19.000000. running mean: -20.449438\n",
            "resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.454944\n",
            "resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.450395\n",
            "resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.445891\n",
            "resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.441432\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.447017\n",
            "resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.442547\n",
            "resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.448122\n",
            "resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.433640\n",
            "resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.429304\n",
            "resetting env. episode 433.000000, reward total was -19.000000. running mean: -20.415011\n",
            "resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.420861\n",
            "resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.426652\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.432386\n",
            "resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.438062\n",
            "resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.443681\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.449245\n",
            "resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.454752\n",
            "resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.460205\n",
            "resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.465603\n",
            "resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.470946\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.476237\n",
            "resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.481475\n",
            "resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.476660\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.481893\n",
            "resetting env. episode 448.000000, reward total was -19.000000. running mean: -20.467074\n",
            "resetting env. episode 449.000000, reward total was -19.000000. running mean: -20.452404\n",
            "resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.457880\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.463301\n",
            "resetting env. episode 452.000000, reward total was -19.000000. running mean: -20.448668\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.454181\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.459639\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.465043\n",
            "resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.470392\n",
            "resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.475689\n",
            "resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.480932\n",
            "resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.486122\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.491261\n",
            "resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.486349\n",
            "resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.481485\n",
            "resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.476670\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.481903\n",
            "resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.467084\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.472414\n",
            "resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.477689\n",
            "resetting env. episode 468.000000, reward total was -20.000000. running mean: -20.472913\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.478183\n",
            "resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.473402\n",
            "resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.468668\n",
            "resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.463981\n",
            "resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.459341\n",
            "resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.464748\n",
            "resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.470100\n",
            "resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.475399\n",
            "resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.470645\n",
            "resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.475939\n",
            "resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.471179\n",
            "resetting env. episode 480.000000, reward total was -18.000000. running mean: -20.446468\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.452003\n",
            "resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.457483\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.462908\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.468279\n",
            "resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.463596\n",
            "resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.468960\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.474271\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.479528\n",
            "resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.474733\n",
            "resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.469985\n",
            "resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.465285\n",
            "resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.470633\n",
            "resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.465926\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.471267\n",
            "resetting env. episode 495.000000, reward total was -19.000000. running mean: -20.456554\n",
            "resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.461989\n",
            "resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.467369\n",
            "resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.462695\n",
            "resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.458068\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.463488\n",
            "resetting env. episode 501.000000, reward total was -20.000000. running mean: -20.458853\n",
            "resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.464264\n",
            "resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.469622\n",
            "resetting env. episode 504.000000, reward total was -19.000000. running mean: -20.454925\n",
            "resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.460376\n",
            "resetting env. episode 506.000000, reward total was -20.000000. running mean: -20.455772\n",
            "resetting env. episode 507.000000, reward total was -21.000000. running mean: -20.461215\n",
            "resetting env. episode 508.000000, reward total was -21.000000. running mean: -20.466602\n",
            "resetting env. episode 509.000000, reward total was -19.000000. running mean: -20.451936\n",
            "resetting env. episode 510.000000, reward total was -21.000000. running mean: -20.457417\n",
            "resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.462843\n",
            "resetting env. episode 512.000000, reward total was -20.000000. running mean: -20.458214\n",
            "resetting env. episode 513.000000, reward total was -21.000000. running mean: -20.463632\n",
            "resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.468996\n",
            "resetting env. episode 515.000000, reward total was -21.000000. running mean: -20.474306\n",
            "resetting env. episode 516.000000, reward total was -21.000000. running mean: -20.479563\n",
            "resetting env. episode 517.000000, reward total was -21.000000. running mean: -20.484767\n",
            "resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.489920\n",
            "resetting env. episode 519.000000, reward total was -21.000000. running mean: -20.495020\n",
            "resetting env. episode 520.000000, reward total was -19.000000. running mean: -20.480070\n",
            "resetting env. episode 521.000000, reward total was -21.000000. running mean: -20.485270\n",
            "resetting env. episode 522.000000, reward total was -20.000000. running mean: -20.480417\n",
            "resetting env. episode 523.000000, reward total was -19.000000. running mean: -20.465613\n",
            "resetting env. episode 524.000000, reward total was -18.000000. running mean: -20.440957\n",
            "resetting env. episode 525.000000, reward total was -20.000000. running mean: -20.436547\n",
            "resetting env. episode 526.000000, reward total was -19.000000. running mean: -20.422182\n",
            "resetting env. episode 527.000000, reward total was -20.000000. running mean: -20.417960\n",
            "resetting env. episode 528.000000, reward total was -20.000000. running mean: -20.413780\n",
            "resetting env. episode 529.000000, reward total was -21.000000. running mean: -20.419642\n",
            "resetting env. episode 530.000000, reward total was -20.000000. running mean: -20.415446\n",
            "resetting env. episode 531.000000, reward total was -21.000000. running mean: -20.421291\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.427079\n",
            "resetting env. episode 533.000000, reward total was -20.000000. running mean: -20.422808\n",
            "resetting env. episode 534.000000, reward total was -21.000000. running mean: -20.428580\n",
            "resetting env. episode 535.000000, reward total was -18.000000. running mean: -20.404294\n",
            "resetting env. episode 536.000000, reward total was -20.000000. running mean: -20.400251\n",
            "resetting env. episode 537.000000, reward total was -20.000000. running mean: -20.396248\n",
            "resetting env. episode 538.000000, reward total was -21.000000. running mean: -20.402286\n",
            "resetting env. episode 539.000000, reward total was -20.000000. running mean: -20.398263\n",
            "resetting env. episode 540.000000, reward total was -20.000000. running mean: -20.394280\n",
            "resetting env. episode 541.000000, reward total was -20.000000. running mean: -20.390338\n",
            "resetting env. episode 542.000000, reward total was -21.000000. running mean: -20.396434\n",
            "resetting env. episode 543.000000, reward total was -19.000000. running mean: -20.382470\n",
            "resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.388645\n",
            "resetting env. episode 545.000000, reward total was -20.000000. running mean: -20.384759\n",
            "resetting env. episode 546.000000, reward total was -18.000000. running mean: -20.360911\n",
            "resetting env. episode 547.000000, reward total was -20.000000. running mean: -20.357302\n",
            "resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.363729\n",
            "resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.370092\n",
            "resetting env. episode 550.000000, reward total was -20.000000. running mean: -20.366391\n",
            "resetting env. episode 551.000000, reward total was -21.000000. running mean: -20.372727\n",
            "resetting env. episode 552.000000, reward total was -21.000000. running mean: -20.379000\n",
            "resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.385210\n",
            "resetting env. episode 554.000000, reward total was -19.000000. running mean: -20.371358\n",
            "resetting env. episode 555.000000, reward total was -19.000000. running mean: -20.357644\n",
            "resetting env. episode 556.000000, reward total was -21.000000. running mean: -20.364068\n",
            "resetting env. episode 557.000000, reward total was -21.000000. running mean: -20.370427\n",
            "resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.376723\n",
            "resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.382955\n",
            "resetting env. episode 560.000000, reward total was -20.000000. running mean: -20.379126\n",
            "resetting env. episode 561.000000, reward total was -20.000000. running mean: -20.375335\n",
            "resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.381581\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.387765\n",
            "resetting env. episode 564.000000, reward total was -21.000000. running mean: -20.393888\n",
            "resetting env. episode 565.000000, reward total was -18.000000. running mean: -20.369949\n",
            "resetting env. episode 566.000000, reward total was -21.000000. running mean: -20.376249\n",
            "resetting env. episode 567.000000, reward total was -21.000000. running mean: -20.382487\n",
            "resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.388662\n",
            "resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.394775\n",
            "resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.400828\n",
            "resetting env. episode 571.000000, reward total was -21.000000. running mean: -20.406819\n",
            "resetting env. episode 572.000000, reward total was -21.000000. running mean: -20.412751\n",
            "resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.418624\n",
            "resetting env. episode 574.000000, reward total was -20.000000. running mean: -20.414437\n",
            "resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.420293\n",
            "resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.426090\n",
            "resetting env. episode 577.000000, reward total was -20.000000. running mean: -20.421829\n",
            "resetting env. episode 578.000000, reward total was -21.000000. running mean: -20.427611\n",
            "resetting env. episode 579.000000, reward total was -21.000000. running mean: -20.433335\n",
            "resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.439001\n",
            "resetting env. episode 581.000000, reward total was -20.000000. running mean: -20.434611\n",
            "resetting env. episode 582.000000, reward total was -20.000000. running mean: -20.430265\n",
            "resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.435963\n",
            "resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.441603\n",
            "resetting env. episode 585.000000, reward total was -20.000000. running mean: -20.437187\n",
            "resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.442815\n",
            "resetting env. episode 587.000000, reward total was -19.000000. running mean: -20.428387\n",
            "resetting env. episode 588.000000, reward total was -21.000000. running mean: -20.434103\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.439762\n",
            "resetting env. episode 590.000000, reward total was -21.000000. running mean: -20.445364\n",
            "resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.450911\n",
            "resetting env. episode 592.000000, reward total was -20.000000. running mean: -20.446402\n",
            "resetting env. episode 593.000000, reward total was -20.000000. running mean: -20.441938\n",
            "resetting env. episode 594.000000, reward total was -20.000000. running mean: -20.437518\n",
            "resetting env. episode 595.000000, reward total was -20.000000. running mean: -20.433143\n",
            "resetting env. episode 596.000000, reward total was -20.000000. running mean: -20.428812\n",
            "resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.434524\n",
            "resetting env. episode 598.000000, reward total was -21.000000. running mean: -20.440178\n",
            "resetting env. episode 599.000000, reward total was -20.000000. running mean: -20.435777\n",
            "resetting env. episode 600.000000, reward total was -20.000000. running mean: -20.431419\n",
            "resetting env. episode 601.000000, reward total was -21.000000. running mean: -20.437105\n",
            "resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.442734\n",
            "resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.448306\n",
            "resetting env. episode 604.000000, reward total was -20.000000. running mean: -20.443823\n",
            "resetting env. episode 605.000000, reward total was -21.000000. running mean: -20.449385\n",
            "resetting env. episode 606.000000, reward total was -20.000000. running mean: -20.444891\n",
            "resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.450442\n",
            "resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.445938\n",
            "resetting env. episode 609.000000, reward total was -21.000000. running mean: -20.451478\n",
            "resetting env. episode 610.000000, reward total was -21.000000. running mean: -20.456964\n",
            "resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.462394\n",
            "resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.467770\n",
            "resetting env. episode 613.000000, reward total was -21.000000. running mean: -20.473092\n",
            "resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.478361\n",
            "resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.483578\n",
            "resetting env. episode 616.000000, reward total was -18.000000. running mean: -20.458742\n",
            "resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.464155\n",
            "resetting env. episode 618.000000, reward total was -21.000000. running mean: -20.469513\n",
            "resetting env. episode 619.000000, reward total was -20.000000. running mean: -20.464818\n",
            "resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.460170\n",
            "resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.465568\n",
            "resetting env. episode 622.000000, reward total was -21.000000. running mean: -20.470912\n",
            "resetting env. episode 623.000000, reward total was -21.000000. running mean: -20.476203\n",
            "resetting env. episode 624.000000, reward total was -18.000000. running mean: -20.451441\n",
            "resetting env. episode 625.000000, reward total was -21.000000. running mean: -20.456927\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.462358\n",
            "resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.467734\n",
            "resetting env. episode 628.000000, reward total was -20.000000. running mean: -20.463057\n",
            "resetting env. episode 629.000000, reward total was -21.000000. running mean: -20.468426\n",
            "resetting env. episode 630.000000, reward total was -18.000000. running mean: -20.443742\n",
            "resetting env. episode 631.000000, reward total was -21.000000. running mean: -20.449304\n",
            "resetting env. episode 632.000000, reward total was -21.000000. running mean: -20.454811\n",
            "resetting env. episode 633.000000, reward total was -19.000000. running mean: -20.440263\n",
            "resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.435861\n",
            "resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.441502\n",
            "resetting env. episode 636.000000, reward total was -21.000000. running mean: -20.447087\n",
            "resetting env. episode 637.000000, reward total was -19.000000. running mean: -20.432616\n",
            "resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.438290\n",
            "resetting env. episode 639.000000, reward total was -19.000000. running mean: -20.423907\n",
            "resetting env. episode 640.000000, reward total was -19.000000. running mean: -20.409668\n",
            "resetting env. episode 641.000000, reward total was -21.000000. running mean: -20.415571\n",
            "resetting env. episode 642.000000, reward total was -19.000000. running mean: -20.401416\n",
            "resetting env. episode 643.000000, reward total was -21.000000. running mean: -20.407401\n",
            "resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.413327\n",
            "resetting env. episode 645.000000, reward total was -20.000000. running mean: -20.409194\n",
            "resetting env. episode 646.000000, reward total was -21.000000. running mean: -20.415102\n",
            "resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.420951\n",
            "resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.426742\n",
            "resetting env. episode 649.000000, reward total was -20.000000. running mean: -20.422474\n",
            "resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.428249\n",
            "resetting env. episode 651.000000, reward total was -21.000000. running mean: -20.433967\n",
            "resetting env. episode 652.000000, reward total was -20.000000. running mean: -20.429627\n",
            "resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.435331\n",
            "resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.440978\n",
            "resetting env. episode 655.000000, reward total was -21.000000. running mean: -20.446568\n",
            "resetting env. episode 656.000000, reward total was -20.000000. running mean: -20.442102\n",
            "resetting env. episode 657.000000, reward total was -20.000000. running mean: -20.437681\n",
            "resetting env. episode 658.000000, reward total was -20.000000. running mean: -20.433304\n",
            "resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.438971\n",
            "resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.444582\n",
            "resetting env. episode 661.000000, reward total was -20.000000. running mean: -20.440136\n",
            "resetting env. episode 662.000000, reward total was -20.000000. running mean: -20.435735\n",
            "resetting env. episode 663.000000, reward total was -20.000000. running mean: -20.431377\n",
            "resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.437063\n",
            "resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.442693\n",
            "resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.448266\n",
            "resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.453783\n",
            "resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.449245\n",
            "resetting env. episode 669.000000, reward total was -20.000000. running mean: -20.444753\n",
            "resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.450305\n",
            "resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.455802\n",
            "resetting env. episode 672.000000, reward total was -21.000000. running mean: -20.461244\n",
            "resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.466632\n",
            "resetting env. episode 674.000000, reward total was -20.000000. running mean: -20.461966\n",
            "resetting env. episode 675.000000, reward total was -20.000000. running mean: -20.457346\n",
            "resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.462772\n",
            "resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.468145\n",
            "resetting env. episode 678.000000, reward total was -21.000000. running mean: -20.473463\n",
            "resetting env. episode 679.000000, reward total was -21.000000. running mean: -20.478729\n",
            "resetting env. episode 680.000000, reward total was -18.000000. running mean: -20.453941\n",
            "resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.459402\n",
            "resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.464808\n",
            "resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.470160\n",
            "resetting env. episode 684.000000, reward total was -20.000000. running mean: -20.465458\n",
            "resetting env. episode 685.000000, reward total was -19.000000. running mean: -20.450804\n",
            "resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.456296\n",
            "resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.461733\n",
            "resetting env. episode 688.000000, reward total was -21.000000. running mean: -20.467115\n",
            "resetting env. episode 689.000000, reward total was -19.000000. running mean: -20.452444\n",
            "resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.457920\n",
            "resetting env. episode 691.000000, reward total was -20.000000. running mean: -20.453341\n",
            "resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.458807\n",
            "resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.464219\n",
            "resetting env. episode 694.000000, reward total was -20.000000. running mean: -20.459577\n",
            "resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.464981\n",
            "resetting env. episode 696.000000, reward total was -19.000000. running mean: -20.450331\n",
            "resetting env. episode 697.000000, reward total was -21.000000. running mean: -20.455828\n",
            "resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.461270\n",
            "resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.466657\n",
            "resetting env. episode 700.000000, reward total was -21.000000. running mean: -20.471990\n",
            "resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.477271\n",
            "resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.482498\n",
            "resetting env. episode 703.000000, reward total was -19.000000. running mean: -20.467673\n",
            "resetting env. episode 704.000000, reward total was -19.000000. running mean: -20.452996\n",
            "resetting env. episode 705.000000, reward total was -21.000000. running mean: -20.458466\n",
            "resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.463881\n",
            "resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.469243\n",
            "resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.474550\n",
            "resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.479805\n",
            "resetting env. episode 710.000000, reward total was -20.000000. running mean: -20.475007\n",
            "resetting env. episode 711.000000, reward total was -20.000000. running mean: -20.470257\n",
            "resetting env. episode 712.000000, reward total was -20.000000. running mean: -20.465554\n",
            "resetting env. episode 713.000000, reward total was -20.000000. running mean: -20.460899\n",
            "resetting env. episode 714.000000, reward total was -20.000000. running mean: -20.456290\n",
            "resetting env. episode 715.000000, reward total was -20.000000. running mean: -20.451727\n",
            "resetting env. episode 716.000000, reward total was -20.000000. running mean: -20.447209\n",
            "resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.452737\n",
            "resetting env. episode 718.000000, reward total was -21.000000. running mean: -20.458210\n",
            "resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.463628\n",
            "resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.468992\n",
            "resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.474302\n",
            "resetting env. episode 722.000000, reward total was -20.000000. running mean: -20.469559\n",
            "resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.474863\n",
            "resetting env. episode 724.000000, reward total was -20.000000. running mean: -20.470114\n",
            "resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.475413\n",
            "resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.480659\n",
            "resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.485853\n",
            "resetting env. episode 728.000000, reward total was -20.000000. running mean: -20.480994\n",
            "resetting env. episode 729.000000, reward total was -19.000000. running mean: -20.466184\n",
            "resetting env. episode 730.000000, reward total was -21.000000. running mean: -20.471522\n",
            "resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.476807\n",
            "resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.482039\n",
            "resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.487219\n",
            "resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.492346\n",
            "resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.497423\n",
            "resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.502449\n",
            "resetting env. episode 737.000000, reward total was -21.000000. running mean: -20.507424\n",
            "resetting env. episode 738.000000, reward total was -21.000000. running mean: -20.512350\n",
            "resetting env. episode 739.000000, reward total was -21.000000. running mean: -20.517226\n",
            "resetting env. episode 740.000000, reward total was -18.000000. running mean: -20.492054\n",
            "resetting env. episode 741.000000, reward total was -21.000000. running mean: -20.497134\n",
            "resetting env. episode 742.000000, reward total was -20.000000. running mean: -20.492162\n",
            "resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.497241\n",
            "resetting env. episode 744.000000, reward total was -21.000000. running mean: -20.502268\n",
            "resetting env. episode 745.000000, reward total was -21.000000. running mean: -20.507246\n",
            "resetting env. episode 746.000000, reward total was -21.000000. running mean: -20.512173\n",
            "resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.517051\n",
            "resetting env. episode 748.000000, reward total was -21.000000. running mean: -20.521881\n",
            "resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.526662\n",
            "resetting env. episode 750.000000, reward total was -20.000000. running mean: -20.521395\n",
            "resetting env. episode 751.000000, reward total was -21.000000. running mean: -20.526181\n",
            "resetting env. episode 752.000000, reward total was -21.000000. running mean: -20.530920\n",
            "resetting env. episode 753.000000, reward total was -20.000000. running mean: -20.525610\n",
            "resetting env. episode 754.000000, reward total was -21.000000. running mean: -20.530354\n",
            "resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.535051\n",
            "resetting env. episode 756.000000, reward total was -21.000000. running mean: -20.539700\n",
            "resetting env. episode 757.000000, reward total was -21.000000. running mean: -20.544303\n",
            "resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.548860\n",
            "resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.553372\n",
            "resetting env. episode 760.000000, reward total was -21.000000. running mean: -20.557838\n",
            "resetting env. episode 761.000000, reward total was -21.000000. running mean: -20.562260\n",
            "resetting env. episode 762.000000, reward total was -21.000000. running mean: -20.566637\n",
            "resetting env. episode 763.000000, reward total was -20.000000. running mean: -20.560971\n",
            "resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.565361\n",
            "resetting env. episode 765.000000, reward total was -21.000000. running mean: -20.569707\n",
            "resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.564010\n",
            "resetting env. episode 767.000000, reward total was -21.000000. running mean: -20.568370\n",
            "resetting env. episode 768.000000, reward total was -20.000000. running mean: -20.562686\n",
            "resetting env. episode 769.000000, reward total was -20.000000. running mean: -20.557060\n",
            "resetting env. episode 770.000000, reward total was -21.000000. running mean: -20.561489\n",
            "resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.565874\n",
            "resetting env. episode 772.000000, reward total was -21.000000. running mean: -20.570215\n",
            "resetting env. episode 773.000000, reward total was -21.000000. running mean: -20.574513\n",
            "resetting env. episode 774.000000, reward total was -21.000000. running mean: -20.578768\n",
            "resetting env. episode 775.000000, reward total was -19.000000. running mean: -20.562980\n",
            "resetting env. episode 776.000000, reward total was -21.000000. running mean: -20.567351\n",
            "resetting env. episode 777.000000, reward total was -20.000000. running mean: -20.561677\n",
            "resetting env. episode 778.000000, reward total was -20.000000. running mean: -20.556060\n",
            "resetting env. episode 779.000000, reward total was -20.000000. running mean: -20.550500\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.554995\n",
            "resetting env. episode 781.000000, reward total was -21.000000. running mean: -20.559445\n",
            "resetting env. episode 782.000000, reward total was -21.000000. running mean: -20.563850\n",
            "resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.568212\n",
            "resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.572530\n",
            "resetting env. episode 785.000000, reward total was -20.000000. running mean: -20.566804\n",
            "resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.571136\n",
            "resetting env. episode 787.000000, reward total was -21.000000. running mean: -20.575425\n",
            "resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.579671\n",
            "resetting env. episode 789.000000, reward total was -21.000000. running mean: -20.583874\n",
            "resetting env. episode 790.000000, reward total was -20.000000. running mean: -20.578035\n",
            "resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.582255\n",
            "resetting env. episode 792.000000, reward total was -21.000000. running mean: -20.586432\n",
            "resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.590568\n",
            "resetting env. episode 794.000000, reward total was -18.000000. running mean: -20.564662\n",
            "resetting env. episode 795.000000, reward total was -21.000000. running mean: -20.569016\n",
            "resetting env. episode 796.000000, reward total was -20.000000. running mean: -20.563326\n",
            "resetting env. episode 797.000000, reward total was -21.000000. running mean: -20.567692\n",
            "resetting env. episode 798.000000, reward total was -21.000000. running mean: -20.572015\n",
            "resetting env. episode 799.000000, reward total was -21.000000. running mean: -20.576295\n",
            "resetting env. episode 800.000000, reward total was -21.000000. running mean: -20.580532\n",
            "resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.584727\n",
            "resetting env. episode 802.000000, reward total was -21.000000. running mean: -20.588880\n",
            "resetting env. episode 803.000000, reward total was -20.000000. running mean: -20.582991\n",
            "resetting env. episode 804.000000, reward total was -21.000000. running mean: -20.587161\n",
            "resetting env. episode 805.000000, reward total was -18.000000. running mean: -20.561289\n",
            "resetting env. episode 806.000000, reward total was -21.000000. running mean: -20.565676\n",
            "resetting env. episode 807.000000, reward total was -21.000000. running mean: -20.570020\n",
            "resetting env. episode 808.000000, reward total was -21.000000. running mean: -20.574320\n",
            "resetting env. episode 809.000000, reward total was -21.000000. running mean: -20.578576\n",
            "resetting env. episode 810.000000, reward total was -19.000000. running mean: -20.562791\n",
            "resetting env. episode 811.000000, reward total was -21.000000. running mean: -20.567163\n",
            "resetting env. episode 812.000000, reward total was -20.000000. running mean: -20.561491\n",
            "resetting env. episode 813.000000, reward total was -20.000000. running mean: -20.555876\n",
            "resetting env. episode 814.000000, reward total was -20.000000. running mean: -20.550317\n",
            "resetting env. episode 815.000000, reward total was -20.000000. running mean: -20.544814\n",
            "resetting env. episode 816.000000, reward total was -21.000000. running mean: -20.549366\n",
            "resetting env. episode 817.000000, reward total was -20.000000. running mean: -20.543872\n",
            "resetting env. episode 818.000000, reward total was -21.000000. running mean: -20.548434\n",
            "resetting env. episode 819.000000, reward total was -21.000000. running mean: -20.552949\n",
            "resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.557420\n",
            "resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.561846\n",
            "resetting env. episode 822.000000, reward total was -21.000000. running mean: -20.566227\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.570565\n",
            "resetting env. episode 824.000000, reward total was -21.000000. running mean: -20.574859\n",
            "resetting env. episode 825.000000, reward total was -20.000000. running mean: -20.569111\n",
            "resetting env. episode 826.000000, reward total was -20.000000. running mean: -20.563420\n",
            "resetting env. episode 827.000000, reward total was -21.000000. running mean: -20.567785\n",
            "resetting env. episode 828.000000, reward total was -20.000000. running mean: -20.562108\n",
            "resetting env. episode 829.000000, reward total was -21.000000. running mean: -20.566486\n",
            "resetting env. episode 830.000000, reward total was -21.000000. running mean: -20.570822\n",
            "resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.575113\n",
            "resetting env. episode 832.000000, reward total was -20.000000. running mean: -20.569362\n",
            "resetting env. episode 833.000000, reward total was -20.000000. running mean: -20.563669\n",
            "resetting env. episode 834.000000, reward total was -20.000000. running mean: -20.558032\n",
            "resetting env. episode 835.000000, reward total was -20.000000. running mean: -20.552452\n",
            "resetting env. episode 836.000000, reward total was -21.000000. running mean: -20.556927\n",
            "resetting env. episode 837.000000, reward total was -21.000000. running mean: -20.561358\n",
            "resetting env. episode 838.000000, reward total was -19.000000. running mean: -20.545744\n",
            "resetting env. episode 839.000000, reward total was -21.000000. running mean: -20.550287\n",
            "resetting env. episode 840.000000, reward total was -21.000000. running mean: -20.554784\n",
            "resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.559236\n",
            "resetting env. episode 842.000000, reward total was -21.000000. running mean: -20.563644\n",
            "resetting env. episode 843.000000, reward total was -21.000000. running mean: -20.568007\n",
            "resetting env. episode 844.000000, reward total was -20.000000. running mean: -20.562327\n",
            "resetting env. episode 845.000000, reward total was -20.000000. running mean: -20.556704\n",
            "resetting env. episode 846.000000, reward total was -21.000000. running mean: -20.561137\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.565526\n",
            "resetting env. episode 848.000000, reward total was -21.000000. running mean: -20.569870\n",
            "resetting env. episode 849.000000, reward total was -18.000000. running mean: -20.544172\n",
            "resetting env. episode 850.000000, reward total was -21.000000. running mean: -20.548730\n",
            "resetting env. episode 851.000000, reward total was -21.000000. running mean: -20.553243\n",
            "resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.557710\n",
            "resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.562133\n",
            "resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.566512\n",
            "resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.570847\n",
            "resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.575138\n",
            "resetting env. episode 857.000000, reward total was -21.000000. running mean: -20.579387\n",
            "resetting env. episode 858.000000, reward total was -21.000000. running mean: -20.583593\n",
            "resetting env. episode 859.000000, reward total was -21.000000. running mean: -20.587757\n",
            "resetting env. episode 860.000000, reward total was -20.000000. running mean: -20.581879\n",
            "resetting env. episode 861.000000, reward total was -20.000000. running mean: -20.576061\n",
            "resetting env. episode 862.000000, reward total was -20.000000. running mean: -20.570300\n",
            "resetting env. episode 863.000000, reward total was -20.000000. running mean: -20.564597\n",
            "resetting env. episode 864.000000, reward total was -20.000000. running mean: -20.558951\n",
            "resetting env. episode 865.000000, reward total was -19.000000. running mean: -20.543361\n",
            "resetting env. episode 866.000000, reward total was -21.000000. running mean: -20.547928\n",
            "resetting env. episode 867.000000, reward total was -20.000000. running mean: -20.542449\n",
            "resetting env. episode 868.000000, reward total was -19.000000. running mean: -20.527024\n",
            "resetting env. episode 869.000000, reward total was -21.000000. running mean: -20.531754\n",
            "resetting env. episode 870.000000, reward total was -21.000000. running mean: -20.536436\n",
            "resetting env. episode 871.000000, reward total was -20.000000. running mean: -20.531072\n",
            "resetting env. episode 872.000000, reward total was -21.000000. running mean: -20.535761\n",
            "resetting env. episode 873.000000, reward total was -21.000000. running mean: -20.540404\n",
            "resetting env. episode 874.000000, reward total was -18.000000. running mean: -20.515000\n",
            "resetting env. episode 875.000000, reward total was -20.000000. running mean: -20.509850\n",
            "resetting env. episode 876.000000, reward total was -21.000000. running mean: -20.514751\n",
            "resetting env. episode 877.000000, reward total was -20.000000. running mean: -20.509604\n",
            "resetting env. episode 878.000000, reward total was -20.000000. running mean: -20.504508\n",
            "resetting env. episode 879.000000, reward total was -21.000000. running mean: -20.509462\n",
            "resetting env. episode 880.000000, reward total was -20.000000. running mean: -20.504368\n",
            "resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.499324\n",
            "resetting env. episode 882.000000, reward total was -21.000000. running mean: -20.504331\n",
            "resetting env. episode 883.000000, reward total was -21.000000. running mean: -20.509288\n",
            "resetting env. episode 884.000000, reward total was -21.000000. running mean: -20.514195\n",
            "resetting env. episode 885.000000, reward total was -20.000000. running mean: -20.509053\n",
            "resetting env. episode 886.000000, reward total was -21.000000. running mean: -20.513962\n",
            "resetting env. episode 887.000000, reward total was -21.000000. running mean: -20.518823\n",
            "resetting env. episode 888.000000, reward total was -21.000000. running mean: -20.523634\n",
            "resetting env. episode 889.000000, reward total was -17.000000. running mean: -20.488398\n",
            "resetting env. episode 890.000000, reward total was -21.000000. running mean: -20.493514\n",
            "resetting env. episode 891.000000, reward total was -20.000000. running mean: -20.488579\n",
            "resetting env. episode 892.000000, reward total was -20.000000. running mean: -20.483693\n",
            "resetting env. episode 893.000000, reward total was -21.000000. running mean: -20.488856\n",
            "resetting env. episode 894.000000, reward total was -20.000000. running mean: -20.483968\n",
            "resetting env. episode 895.000000, reward total was -20.000000. running mean: -20.479128\n",
            "resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.484337\n",
            "resetting env. episode 897.000000, reward total was -20.000000. running mean: -20.479493\n",
            "resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.484698\n",
            "resetting env. episode 899.000000, reward total was -21.000000. running mean: -20.489851\n",
            "resetting env. episode 900.000000, reward total was -21.000000. running mean: -20.494953\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.500003\n",
            "resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.505003\n",
            "resetting env. episode 903.000000, reward total was -21.000000. running mean: -20.509953\n",
            "resetting env. episode 904.000000, reward total was -20.000000. running mean: -20.504854\n",
            "resetting env. episode 905.000000, reward total was -21.000000. running mean: -20.509805\n",
            "resetting env. episode 906.000000, reward total was -18.000000. running mean: -20.484707\n",
            "resetting env. episode 907.000000, reward total was -21.000000. running mean: -20.489860\n",
            "resetting env. episode 908.000000, reward total was -19.000000. running mean: -20.474962\n",
            "resetting env. episode 909.000000, reward total was -21.000000. running mean: -20.480212\n",
            "resetting env. episode 910.000000, reward total was -20.000000. running mean: -20.475410\n",
            "resetting env. episode 911.000000, reward total was -21.000000. running mean: -20.480656\n",
            "resetting env. episode 912.000000, reward total was -21.000000. running mean: -20.485849\n",
            "resetting env. episode 913.000000, reward total was -21.000000. running mean: -20.490991\n",
            "resetting env. episode 914.000000, reward total was -19.000000. running mean: -20.476081\n",
            "resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.481320\n",
            "resetting env. episode 916.000000, reward total was -20.000000. running mean: -20.476507\n",
            "resetting env. episode 917.000000, reward total was -21.000000. running mean: -20.481742\n",
            "resetting env. episode 918.000000, reward total was -21.000000. running mean: -20.486924\n",
            "resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.492055\n",
            "resetting env. episode 920.000000, reward total was -20.000000. running mean: -20.487134\n",
            "resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.492263\n",
            "resetting env. episode 922.000000, reward total was -21.000000. running mean: -20.497340\n",
            "resetting env. episode 923.000000, reward total was -19.000000. running mean: -20.482367\n",
            "resetting env. episode 924.000000, reward total was -21.000000. running mean: -20.487543\n",
            "resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.492668\n",
            "resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.497741\n",
            "resetting env. episode 927.000000, reward total was -21.000000. running mean: -20.502764\n",
            "resetting env. episode 928.000000, reward total was -18.000000. running mean: -20.477736\n",
            "resetting env. episode 929.000000, reward total was -21.000000. running mean: -20.482959\n",
            "resetting env. episode 930.000000, reward total was -20.000000. running mean: -20.478129\n",
            "resetting env. episode 931.000000, reward total was -21.000000. running mean: -20.483348\n",
            "resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.488515\n",
            "resetting env. episode 933.000000, reward total was -20.000000. running mean: -20.483629\n",
            "resetting env. episode 934.000000, reward total was -20.000000. running mean: -20.478793\n",
            "resetting env. episode 935.000000, reward total was -19.000000. running mean: -20.464005\n",
            "resetting env. episode 936.000000, reward total was -20.000000. running mean: -20.459365\n",
            "resetting env. episode 937.000000, reward total was -21.000000. running mean: -20.464771\n",
            "resetting env. episode 938.000000, reward total was -20.000000. running mean: -20.460124\n",
            "resetting env. episode 939.000000, reward total was -20.000000. running mean: -20.455522\n",
            "resetting env. episode 940.000000, reward total was -21.000000. running mean: -20.460967\n",
            "resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.456358\n",
            "resetting env. episode 942.000000, reward total was -21.000000. running mean: -20.461794\n",
            "resetting env. episode 943.000000, reward total was -20.000000. running mean: -20.457176\n",
            "resetting env. episode 944.000000, reward total was -21.000000. running mean: -20.462604\n",
            "resetting env. episode 945.000000, reward total was -21.000000. running mean: -20.467978\n",
            "resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.473298\n",
            "resetting env. episode 947.000000, reward total was -21.000000. running mean: -20.478566\n",
            "resetting env. episode 948.000000, reward total was -20.000000. running mean: -20.473780\n",
            "resetting env. episode 949.000000, reward total was -20.000000. running mean: -20.469042\n",
            "resetting env. episode 950.000000, reward total was -21.000000. running mean: -20.474352\n",
            "resetting env. episode 951.000000, reward total was -20.000000. running mean: -20.469608\n",
            "resetting env. episode 952.000000, reward total was -20.000000. running mean: -20.464912\n",
            "resetting env. episode 953.000000, reward total was -21.000000. running mean: -20.470263\n",
            "resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.475560\n",
            "resetting env. episode 955.000000, reward total was -21.000000. running mean: -20.480805\n",
            "resetting env. episode 956.000000, reward total was -20.000000. running mean: -20.475997\n",
            "resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.481237\n",
            "resetting env. episode 958.000000, reward total was -21.000000. running mean: -20.486424\n",
            "resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.491560\n",
            "resetting env. episode 960.000000, reward total was -19.000000. running mean: -20.476644\n",
            "resetting env. episode 961.000000, reward total was -21.000000. running mean: -20.481878\n",
            "resetting env. episode 962.000000, reward total was -21.000000. running mean: -20.487059\n",
            "resetting env. episode 963.000000, reward total was -20.000000. running mean: -20.482189\n",
            "resetting env. episode 964.000000, reward total was -20.000000. running mean: -20.477367\n",
            "resetting env. episode 965.000000, reward total was -21.000000. running mean: -20.482593\n",
            "resetting env. episode 966.000000, reward total was -20.000000. running mean: -20.477767\n",
            "resetting env. episode 967.000000, reward total was -21.000000. running mean: -20.482989\n",
            "resetting env. episode 968.000000, reward total was -21.000000. running mean: -20.488160\n",
            "resetting env. episode 969.000000, reward total was -20.000000. running mean: -20.483278\n",
            "resetting env. episode 970.000000, reward total was -21.000000. running mean: -20.488445\n",
            "resetting env. episode 971.000000, reward total was -19.000000. running mean: -20.473561\n",
            "resetting env. episode 972.000000, reward total was -20.000000. running mean: -20.468825\n",
            "resetting env. episode 973.000000, reward total was -21.000000. running mean: -20.474137\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -20.469396\n",
            "resetting env. episode 975.000000, reward total was -20.000000. running mean: -20.464702\n",
            "resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.470055\n",
            "resetting env. episode 977.000000, reward total was -20.000000. running mean: -20.465354\n",
            "resetting env. episode 978.000000, reward total was -21.000000. running mean: -20.470700\n",
            "resetting env. episode 979.000000, reward total was -20.000000. running mean: -20.465993\n",
            "resetting env. episode 980.000000, reward total was -21.000000. running mean: -20.471334\n",
            "resetting env. episode 981.000000, reward total was -21.000000. running mean: -20.476620\n",
            "resetting env. episode 982.000000, reward total was -21.000000. running mean: -20.481854\n",
            "resetting env. episode 983.000000, reward total was -21.000000. running mean: -20.487035\n",
            "resetting env. episode 984.000000, reward total was -21.000000. running mean: -20.492165\n",
            "resetting env. episode 985.000000, reward total was -20.000000. running mean: -20.487243\n",
            "resetting env. episode 986.000000, reward total was -20.000000. running mean: -20.482371\n",
            "resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.487547\n",
            "resetting env. episode 988.000000, reward total was -20.000000. running mean: -20.482672\n",
            "resetting env. episode 989.000000, reward total was -20.000000. running mean: -20.477845\n",
            "resetting env. episode 990.000000, reward total was -21.000000. running mean: -20.483067\n",
            "resetting env. episode 991.000000, reward total was -21.000000. running mean: -20.488236\n",
            "resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.493354\n",
            "resetting env. episode 993.000000, reward total was -17.000000. running mean: -20.458420\n",
            "resetting env. episode 994.000000, reward total was -20.000000. running mean: -20.453836\n",
            "resetting env. episode 995.000000, reward total was -21.000000. running mean: -20.459298\n",
            "resetting env. episode 996.000000, reward total was -21.000000. running mean: -20.464705\n",
            "resetting env. episode 997.000000, reward total was -20.000000. running mean: -20.460058\n",
            "resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.465457\n",
            "resetting env. episode 999.000000, reward total was -20.000000. running mean: -20.460802\n",
            "resetting env. episode 1000.000000, reward total was -19.000000. running mean: -20.446194\n",
            "resetting env. episode 1001.000000, reward total was -21.000000. running mean: -20.451732\n",
            "resetting env. episode 1002.000000, reward total was -20.000000. running mean: -20.447215\n",
            "resetting env. episode 1003.000000, reward total was -21.000000. running mean: -20.452743\n",
            "resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.458216\n",
            "resetting env. episode 1005.000000, reward total was -21.000000. running mean: -20.463633\n",
            "resetting env. episode 1006.000000, reward total was -19.000000. running mean: -20.448997\n",
            "resetting env. episode 1007.000000, reward total was -19.000000. running mean: -20.434507\n",
            "resetting env. episode 1008.000000, reward total was -21.000000. running mean: -20.440162\n",
            "resetting env. episode 1009.000000, reward total was -21.000000. running mean: -20.445760\n",
            "resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.451303\n",
            "resetting env. episode 1011.000000, reward total was -21.000000. running mean: -20.456790\n",
            "resetting env. episode 1012.000000, reward total was -21.000000. running mean: -20.462222\n",
            "resetting env. episode 1013.000000, reward total was -21.000000. running mean: -20.467600\n",
            "resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.472924\n",
            "resetting env. episode 1015.000000, reward total was -19.000000. running mean: -20.458194\n",
            "resetting env. episode 1016.000000, reward total was -21.000000. running mean: -20.463612\n",
            "resetting env. episode 1017.000000, reward total was -21.000000. running mean: -20.468976\n",
            "resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.474287\n",
            "resetting env. episode 1019.000000, reward total was -21.000000. running mean: -20.479544\n",
            "resetting env. episode 1020.000000, reward total was -19.000000. running mean: -20.464748\n",
            "resetting env. episode 1021.000000, reward total was -20.000000. running mean: -20.460101\n",
            "resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.465500\n",
            "resetting env. episode 1023.000000, reward total was -21.000000. running mean: -20.470845\n",
            "resetting env. episode 1024.000000, reward total was -20.000000. running mean: -20.466136\n",
            "resetting env. episode 1025.000000, reward total was -19.000000. running mean: -20.451475\n",
            "resetting env. episode 1026.000000, reward total was -21.000000. running mean: -20.456960\n",
            "resetting env. episode 1027.000000, reward total was -21.000000. running mean: -20.462391\n",
            "resetting env. episode 1028.000000, reward total was -21.000000. running mean: -20.467767\n",
            "resetting env. episode 1029.000000, reward total was -20.000000. running mean: -20.463089\n",
            "resetting env. episode 1030.000000, reward total was -21.000000. running mean: -20.468458\n",
            "resetting env. episode 1031.000000, reward total was -19.000000. running mean: -20.453774\n",
            "resetting env. episode 1032.000000, reward total was -18.000000. running mean: -20.429236\n",
            "resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.434943\n",
            "resetting env. episode 1034.000000, reward total was -20.000000. running mean: -20.430594\n",
            "resetting env. episode 1035.000000, reward total was -21.000000. running mean: -20.436288\n",
            "resetting env. episode 1036.000000, reward total was -21.000000. running mean: -20.441925\n",
            "resetting env. episode 1037.000000, reward total was -20.000000. running mean: -20.437506\n",
            "resetting env. episode 1038.000000, reward total was -20.000000. running mean: -20.433131\n",
            "resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.438800\n",
            "resetting env. episode 1040.000000, reward total was -18.000000. running mean: -20.414412\n",
            "resetting env. episode 1041.000000, reward total was -20.000000. running mean: -20.410267\n",
            "resetting env. episode 1042.000000, reward total was -21.000000. running mean: -20.416165\n",
            "resetting env. episode 1043.000000, reward total was -20.000000. running mean: -20.412003\n",
            "resetting env. episode 1044.000000, reward total was -20.000000. running mean: -20.407883\n",
            "resetting env. episode 1045.000000, reward total was -19.000000. running mean: -20.393804\n",
            "resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.399866\n",
            "resetting env. episode 1047.000000, reward total was -20.000000. running mean: -20.395868\n",
            "resetting env. episode 1048.000000, reward total was -21.000000. running mean: -20.401909\n",
            "resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.407890\n",
            "resetting env. episode 1050.000000, reward total was -21.000000. running mean: -20.413811\n",
            "resetting env. episode 1051.000000, reward total was -20.000000. running mean: -20.409673\n",
            "resetting env. episode 1052.000000, reward total was -21.000000. running mean: -20.415576\n",
            "resetting env. episode 1053.000000, reward total was -20.000000. running mean: -20.411420\n",
            "resetting env. episode 1054.000000, reward total was -21.000000. running mean: -20.417306\n",
            "resetting env. episode 1055.000000, reward total was -21.000000. running mean: -20.423133\n",
            "resetting env. episode 1056.000000, reward total was -20.000000. running mean: -20.418902\n",
            "resetting env. episode 1057.000000, reward total was -21.000000. running mean: -20.424713\n",
            "resetting env. episode 1058.000000, reward total was -21.000000. running mean: -20.430466\n",
            "resetting env. episode 1059.000000, reward total was -20.000000. running mean: -20.426161\n",
            "resetting env. episode 1060.000000, reward total was -20.000000. running mean: -20.421899\n",
            "resetting env. episode 1061.000000, reward total was -20.000000. running mean: -20.417680\n",
            "resetting env. episode 1062.000000, reward total was -21.000000. running mean: -20.423504\n",
            "resetting env. episode 1063.000000, reward total was -21.000000. running mean: -20.429268\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.434976\n",
            "resetting env. episode 1065.000000, reward total was -21.000000. running mean: -20.440626\n",
            "resetting env. episode 1066.000000, reward total was -20.000000. running mean: -20.436220\n",
            "resetting env. episode 1067.000000, reward total was -20.000000. running mean: -20.431858\n",
            "resetting env. episode 1068.000000, reward total was -19.000000. running mean: -20.417539\n",
            "resetting env. episode 1069.000000, reward total was -21.000000. running mean: -20.423364\n",
            "resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.429130\n",
            "resetting env. episode 1071.000000, reward total was -21.000000. running mean: -20.434839\n",
            "resetting env. episode 1072.000000, reward total was -21.000000. running mean: -20.440490\n",
            "resetting env. episode 1073.000000, reward total was -21.000000. running mean: -20.446085\n",
            "resetting env. episode 1074.000000, reward total was -21.000000. running mean: -20.451625\n",
            "resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.457108\n",
            "resetting env. episode 1076.000000, reward total was -21.000000. running mean: -20.462537\n",
            "resetting env. episode 1077.000000, reward total was -20.000000. running mean: -20.457912\n",
            "resetting env. episode 1078.000000, reward total was -20.000000. running mean: -20.453333\n",
            "resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.458799\n",
            "resetting env. episode 1080.000000, reward total was -20.000000. running mean: -20.454211\n",
            "resetting env. episode 1081.000000, reward total was -20.000000. running mean: -20.449669\n",
            "resetting env. episode 1082.000000, reward total was -21.000000. running mean: -20.455173\n",
            "resetting env. episode 1083.000000, reward total was -20.000000. running mean: -20.450621\n",
            "resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.456115\n",
            "resetting env. episode 1085.000000, reward total was -21.000000. running mean: -20.461554\n",
            "resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.466938\n",
            "resetting env. episode 1087.000000, reward total was -21.000000. running mean: -20.472269\n",
            "resetting env. episode 1088.000000, reward total was -21.000000. running mean: -20.477546\n",
            "resetting env. episode 1089.000000, reward total was -20.000000. running mean: -20.472770\n",
            "resetting env. episode 1090.000000, reward total was -21.000000. running mean: -20.478043\n",
            "resetting env. episode 1091.000000, reward total was -18.000000. running mean: -20.453262\n",
            "resetting env. episode 1092.000000, reward total was -19.000000. running mean: -20.438730\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.444342\n",
            "resetting env. episode 1094.000000, reward total was -20.000000. running mean: -20.439899\n",
            "resetting env. episode 1095.000000, reward total was -21.000000. running mean: -20.445500\n",
            "resetting env. episode 1096.000000, reward total was -20.000000. running mean: -20.441045\n",
            "resetting env. episode 1097.000000, reward total was -21.000000. running mean: -20.446635\n",
            "resetting env. episode 1098.000000, reward total was -21.000000. running mean: -20.452168\n",
            "resetting env. episode 1099.000000, reward total was -21.000000. running mean: -20.457647\n",
            "resetting env. episode 1100.000000, reward total was -21.000000. running mean: -20.463070\n",
            "resetting env. episode 1101.000000, reward total was -21.000000. running mean: -20.468439\n",
            "resetting env. episode 1102.000000, reward total was -20.000000. running mean: -20.463755\n",
            "resetting env. episode 1103.000000, reward total was -18.000000. running mean: -20.439117\n",
            "resetting env. episode 1104.000000, reward total was -21.000000. running mean: -20.444726\n",
            "resetting env. episode 1105.000000, reward total was -21.000000. running mean: -20.450279\n",
            "resetting env. episode 1106.000000, reward total was -19.000000. running mean: -20.435776\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.441418\n",
            "resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.447004\n",
            "resetting env. episode 1109.000000, reward total was -21.000000. running mean: -20.452534\n",
            "resetting env. episode 1110.000000, reward total was -19.000000. running mean: -20.438009\n",
            "resetting env. episode 1111.000000, reward total was -19.000000. running mean: -20.423629\n",
            "resetting env. episode 1112.000000, reward total was -21.000000. running mean: -20.429392\n",
            "resetting env. episode 1113.000000, reward total was -19.000000. running mean: -20.415099\n",
            "resetting env. episode 1114.000000, reward total was -21.000000. running mean: -20.420948\n",
            "resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.426738\n",
            "resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.432471\n",
            "resetting env. episode 1117.000000, reward total was -19.000000. running mean: -20.418146\n",
            "resetting env. episode 1118.000000, reward total was -21.000000. running mean: -20.423965\n",
            "resetting env. episode 1119.000000, reward total was -21.000000. running mean: -20.429725\n",
            "resetting env. episode 1120.000000, reward total was -20.000000. running mean: -20.425428\n",
            "resetting env. episode 1121.000000, reward total was -21.000000. running mean: -20.431173\n",
            "resetting env. episode 1122.000000, reward total was -19.000000. running mean: -20.416862\n",
            "resetting env. episode 1123.000000, reward total was -20.000000. running mean: -20.412693\n",
            "resetting env. episode 1124.000000, reward total was -21.000000. running mean: -20.418566\n",
            "resetting env. episode 1125.000000, reward total was -21.000000. running mean: -20.424380\n",
            "resetting env. episode 1126.000000, reward total was -19.000000. running mean: -20.410137\n",
            "resetting env. episode 1127.000000, reward total was -21.000000. running mean: -20.416035\n",
            "resetting env. episode 1128.000000, reward total was -20.000000. running mean: -20.411875\n",
            "resetting env. episode 1129.000000, reward total was -21.000000. running mean: -20.417756\n",
            "resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.423579\n",
            "resetting env. episode 1131.000000, reward total was -20.000000. running mean: -20.419343\n",
            "resetting env. episode 1132.000000, reward total was -19.000000. running mean: -20.405149\n",
            "resetting env. episode 1133.000000, reward total was -19.000000. running mean: -20.391098\n",
            "resetting env. episode 1134.000000, reward total was -20.000000. running mean: -20.387187\n",
            "resetting env. episode 1135.000000, reward total was -20.000000. running mean: -20.383315\n",
            "resetting env. episode 1136.000000, reward total was -20.000000. running mean: -20.379482\n",
            "resetting env. episode 1137.000000, reward total was -19.000000. running mean: -20.365687\n",
            "resetting env. episode 1138.000000, reward total was -21.000000. running mean: -20.372030\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.378310\n",
            "resetting env. episode 1140.000000, reward total was -21.000000. running mean: -20.384527\n",
            "resetting env. episode 1141.000000, reward total was -21.000000. running mean: -20.390682\n",
            "resetting env. episode 1142.000000, reward total was -21.000000. running mean: -20.396775\n",
            "resetting env. episode 1143.000000, reward total was -19.000000. running mean: -20.382807\n",
            "resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.388979\n",
            "resetting env. episode 1145.000000, reward total was -20.000000. running mean: -20.385089\n",
            "resetting env. episode 1146.000000, reward total was -21.000000. running mean: -20.391238\n",
            "resetting env. episode 1147.000000, reward total was -18.000000. running mean: -20.367326\n",
            "resetting env. episode 1148.000000, reward total was -21.000000. running mean: -20.373653\n",
            "resetting env. episode 1149.000000, reward total was -21.000000. running mean: -20.379916\n",
            "resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.386117\n",
            "resetting env. episode 1151.000000, reward total was -20.000000. running mean: -20.382256\n",
            "resetting env. episode 1152.000000, reward total was -18.000000. running mean: -20.358433\n",
            "resetting env. episode 1153.000000, reward total was -19.000000. running mean: -20.344849\n",
            "resetting env. episode 1154.000000, reward total was -20.000000. running mean: -20.341400\n",
            "resetting env. episode 1155.000000, reward total was -21.000000. running mean: -20.347986\n",
            "resetting env. episode 1156.000000, reward total was -18.000000. running mean: -20.324506\n",
            "resetting env. episode 1157.000000, reward total was -21.000000. running mean: -20.331261\n",
            "resetting env. episode 1158.000000, reward total was -20.000000. running mean: -20.327949\n",
            "resetting env. episode 1159.000000, reward total was -20.000000. running mean: -20.324669\n",
            "resetting env. episode 1160.000000, reward total was -20.000000. running mean: -20.321423\n",
            "resetting env. episode 1161.000000, reward total was -21.000000. running mean: -20.328208\n",
            "resetting env. episode 1162.000000, reward total was -21.000000. running mean: -20.334926\n",
            "resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.341577\n",
            "resetting env. episode 1164.000000, reward total was -20.000000. running mean: -20.338161\n",
            "resetting env. episode 1165.000000, reward total was -21.000000. running mean: -20.344780\n",
            "resetting env. episode 1166.000000, reward total was -18.000000. running mean: -20.321332\n",
            "resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.328119\n",
            "resetting env. episode 1168.000000, reward total was -18.000000. running mean: -20.304837\n",
            "resetting env. episode 1169.000000, reward total was -20.000000. running mean: -20.301789\n",
            "resetting env. episode 1170.000000, reward total was -21.000000. running mean: -20.308771\n",
            "resetting env. episode 1171.000000, reward total was -21.000000. running mean: -20.315683\n",
            "resetting env. episode 1172.000000, reward total was -20.000000. running mean: -20.312527\n",
            "resetting env. episode 1173.000000, reward total was -21.000000. running mean: -20.319401\n",
            "resetting env. episode 1174.000000, reward total was -20.000000. running mean: -20.316207\n",
            "resetting env. episode 1175.000000, reward total was -21.000000. running mean: -20.323045\n",
            "resetting env. episode 1176.000000, reward total was -20.000000. running mean: -20.319815\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.326617\n",
            "resetting env. episode 1178.000000, reward total was -17.000000. running mean: -20.293350\n",
            "resetting env. episode 1179.000000, reward total was -19.000000. running mean: -20.280417\n",
            "resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.287613\n",
            "resetting env. episode 1181.000000, reward total was -21.000000. running mean: -20.294737\n",
            "resetting env. episode 1182.000000, reward total was -21.000000. running mean: -20.301789\n",
            "resetting env. episode 1183.000000, reward total was -21.000000. running mean: -20.308771\n",
            "resetting env. episode 1184.000000, reward total was -20.000000. running mean: -20.305684\n",
            "resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.312627\n",
            "resetting env. episode 1186.000000, reward total was -20.000000. running mean: -20.309501\n",
            "resetting env. episode 1187.000000, reward total was -21.000000. running mean: -20.316406\n",
            "resetting env. episode 1188.000000, reward total was -21.000000. running mean: -20.323241\n",
            "resetting env. episode 1189.000000, reward total was -21.000000. running mean: -20.330009\n",
            "resetting env. episode 1190.000000, reward total was -20.000000. running mean: -20.326709\n",
            "resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.333442\n",
            "resetting env. episode 1192.000000, reward total was -21.000000. running mean: -20.340107\n",
            "resetting env. episode 1193.000000, reward total was -21.000000. running mean: -20.346706\n",
            "resetting env. episode 1194.000000, reward total was -20.000000. running mean: -20.343239\n",
            "resetting env. episode 1195.000000, reward total was -19.000000. running mean: -20.329807\n",
            "resetting env. episode 1196.000000, reward total was -21.000000. running mean: -20.336509\n",
            "resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.343144\n",
            "resetting env. episode 1198.000000, reward total was -21.000000. running mean: -20.349712\n",
            "resetting env. episode 1199.000000, reward total was -20.000000. running mean: -20.346215\n",
            "resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.352753\n",
            "resetting env. episode 1201.000000, reward total was -20.000000. running mean: -20.349226\n",
            "resetting env. episode 1202.000000, reward total was -21.000000. running mean: -20.355733\n",
            "resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.362176\n",
            "resetting env. episode 1204.000000, reward total was -21.000000. running mean: -20.368554\n",
            "resetting env. episode 1205.000000, reward total was -21.000000. running mean: -20.374869\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.381120\n",
            "resetting env. episode 1207.000000, reward total was -19.000000. running mean: -20.367309\n",
            "resetting env. episode 1208.000000, reward total was -20.000000. running mean: -20.363636\n",
            "resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.369999\n",
            "resetting env. episode 1210.000000, reward total was -21.000000. running mean: -20.376299\n",
            "resetting env. episode 1211.000000, reward total was -18.000000. running mean: -20.352536\n",
            "resetting env. episode 1212.000000, reward total was -21.000000. running mean: -20.359011\n",
            "resetting env. episode 1213.000000, reward total was -21.000000. running mean: -20.365421\n",
            "resetting env. episode 1214.000000, reward total was -21.000000. running mean: -20.371767\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.378049\n",
            "resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.384268\n",
            "resetting env. episode 1217.000000, reward total was -21.000000. running mean: -20.390426\n",
            "resetting env. episode 1218.000000, reward total was -21.000000. running mean: -20.396522\n",
            "resetting env. episode 1219.000000, reward total was -21.000000. running mean: -20.402556\n",
            "resetting env. episode 1220.000000, reward total was -21.000000. running mean: -20.408531\n",
            "resetting env. episode 1221.000000, reward total was -20.000000. running mean: -20.404445\n",
            "resetting env. episode 1222.000000, reward total was -20.000000. running mean: -20.400401\n",
            "resetting env. episode 1223.000000, reward total was -21.000000. running mean: -20.406397\n",
            "resetting env. episode 1224.000000, reward total was -21.000000. running mean: -20.412333\n",
            "resetting env. episode 1225.000000, reward total was -18.000000. running mean: -20.388210\n",
            "resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.394328\n",
            "resetting env. episode 1227.000000, reward total was -20.000000. running mean: -20.390384\n",
            "resetting env. episode 1228.000000, reward total was -21.000000. running mean: -20.396480\n",
            "resetting env. episode 1229.000000, reward total was -19.000000. running mean: -20.382516\n",
            "resetting env. episode 1230.000000, reward total was -19.000000. running mean: -20.368691\n",
            "resetting env. episode 1231.000000, reward total was -20.000000. running mean: -20.365004\n",
            "resetting env. episode 1232.000000, reward total was -18.000000. running mean: -20.341354\n",
            "resetting env. episode 1233.000000, reward total was -20.000000. running mean: -20.337940\n",
            "resetting env. episode 1234.000000, reward total was -21.000000. running mean: -20.344561\n",
            "resetting env. episode 1235.000000, reward total was -21.000000. running mean: -20.351115\n",
            "resetting env. episode 1236.000000, reward total was -20.000000. running mean: -20.347604\n",
            "resetting env. episode 1237.000000, reward total was -21.000000. running mean: -20.354128\n",
            "resetting env. episode 1238.000000, reward total was -21.000000. running mean: -20.360587\n",
            "resetting env. episode 1239.000000, reward total was -21.000000. running mean: -20.366981\n",
            "resetting env. episode 1240.000000, reward total was -21.000000. running mean: -20.373311\n",
            "resetting env. episode 1241.000000, reward total was -21.000000. running mean: -20.379578\n",
            "resetting env. episode 1242.000000, reward total was -21.000000. running mean: -20.385782\n",
            "resetting env. episode 1243.000000, reward total was -21.000000. running mean: -20.391924\n",
            "resetting env. episode 1244.000000, reward total was -19.000000. running mean: -20.378005\n",
            "resetting env. episode 1245.000000, reward total was -21.000000. running mean: -20.384225\n",
            "resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.390383\n",
            "resetting env. episode 1247.000000, reward total was -21.000000. running mean: -20.396479\n",
            "resetting env. episode 1248.000000, reward total was -21.000000. running mean: -20.402514\n",
            "resetting env. episode 1249.000000, reward total was -21.000000. running mean: -20.408489\n",
            "resetting env. episode 1250.000000, reward total was -20.000000. running mean: -20.404404\n",
            "resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.410360\n",
            "resetting env. episode 1252.000000, reward total was -21.000000. running mean: -20.416256\n",
            "resetting env. episode 1253.000000, reward total was -21.000000. running mean: -20.422094\n",
            "resetting env. episode 1254.000000, reward total was -21.000000. running mean: -20.427873\n",
            "resetting env. episode 1255.000000, reward total was -21.000000. running mean: -20.433594\n",
            "resetting env. episode 1256.000000, reward total was -21.000000. running mean: -20.439258\n",
            "resetting env. episode 1257.000000, reward total was -21.000000. running mean: -20.444866\n",
            "resetting env. episode 1258.000000, reward total was -20.000000. running mean: -20.440417\n",
            "resetting env. episode 1259.000000, reward total was -21.000000. running mean: -20.446013\n",
            "resetting env. episode 1260.000000, reward total was -21.000000. running mean: -20.451553\n",
            "resetting env. episode 1261.000000, reward total was -21.000000. running mean: -20.457037\n",
            "resetting env. episode 1262.000000, reward total was -21.000000. running mean: -20.462467\n",
            "resetting env. episode 1263.000000, reward total was -21.000000. running mean: -20.467842\n",
            "resetting env. episode 1264.000000, reward total was -21.000000. running mean: -20.473164\n",
            "resetting env. episode 1265.000000, reward total was -20.000000. running mean: -20.468432\n",
            "resetting env. episode 1266.000000, reward total was -21.000000. running mean: -20.473748\n",
            "resetting env. episode 1267.000000, reward total was -20.000000. running mean: -20.469010\n",
            "resetting env. episode 1268.000000, reward total was -21.000000. running mean: -20.474320\n",
            "resetting env. episode 1269.000000, reward total was -21.000000. running mean: -20.479577\n",
            "resetting env. episode 1270.000000, reward total was -21.000000. running mean: -20.484781\n",
            "resetting env. episode 1271.000000, reward total was -21.000000. running mean: -20.489933\n",
            "resetting env. episode 1272.000000, reward total was -21.000000. running mean: -20.495034\n",
            "resetting env. episode 1273.000000, reward total was -21.000000. running mean: -20.500084\n",
            "resetting env. episode 1274.000000, reward total was -19.000000. running mean: -20.485083\n",
            "resetting env. episode 1275.000000, reward total was -21.000000. running mean: -20.490232\n",
            "resetting env. episode 1276.000000, reward total was -20.000000. running mean: -20.485330\n",
            "resetting env. episode 1277.000000, reward total was -21.000000. running mean: -20.490476\n",
            "resetting env. episode 1278.000000, reward total was -20.000000. running mean: -20.485572\n",
            "resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.490716\n",
            "resetting env. episode 1280.000000, reward total was -19.000000. running mean: -20.475809\n",
            "resetting env. episode 1281.000000, reward total was -19.000000. running mean: -20.461051\n",
            "resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.466440\n",
            "resetting env. episode 1283.000000, reward total was -21.000000. running mean: -20.471776\n",
            "resetting env. episode 1284.000000, reward total was -20.000000. running mean: -20.467058\n",
            "resetting env. episode 1285.000000, reward total was -20.000000. running mean: -20.462387\n",
            "resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.467764\n",
            "resetting env. episode 1287.000000, reward total was -21.000000. running mean: -20.473086\n",
            "resetting env. episode 1288.000000, reward total was -21.000000. running mean: -20.478355\n",
            "resetting env. episode 1289.000000, reward total was -19.000000. running mean: -20.463572\n",
            "resetting env. episode 1290.000000, reward total was -21.000000. running mean: -20.468936\n",
            "resetting env. episode 1291.000000, reward total was -20.000000. running mean: -20.464246\n",
            "resetting env. episode 1292.000000, reward total was -21.000000. running mean: -20.469604\n",
            "resetting env. episode 1293.000000, reward total was -20.000000. running mean: -20.464908\n",
            "resetting env. episode 1294.000000, reward total was -21.000000. running mean: -20.470259\n",
            "resetting env. episode 1295.000000, reward total was -20.000000. running mean: -20.465556\n",
            "resetting env. episode 1296.000000, reward total was -20.000000. running mean: -20.460901\n",
            "resetting env. episode 1297.000000, reward total was -21.000000. running mean: -20.466292\n",
            "resetting env. episode 1298.000000, reward total was -21.000000. running mean: -20.471629\n",
            "resetting env. episode 1299.000000, reward total was -21.000000. running mean: -20.476912\n",
            "resetting env. episode 1300.000000, reward total was -19.000000. running mean: -20.462143\n",
            "resetting env. episode 1301.000000, reward total was -21.000000. running mean: -20.467522\n",
            "resetting env. episode 1302.000000, reward total was -21.000000. running mean: -20.472847\n",
            "resetting env. episode 1303.000000, reward total was -21.000000. running mean: -20.478118\n",
            "resetting env. episode 1304.000000, reward total was -18.000000. running mean: -20.453337\n",
            "resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.458804\n",
            "resetting env. episode 1306.000000, reward total was -20.000000. running mean: -20.454216\n",
            "resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.459673\n",
            "resetting env. episode 1308.000000, reward total was -21.000000. running mean: -20.465077\n",
            "resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.470426\n",
            "resetting env. episode 1310.000000, reward total was -21.000000. running mean: -20.475722\n",
            "resetting env. episode 1311.000000, reward total was -20.000000. running mean: -20.470965\n",
            "resetting env. episode 1312.000000, reward total was -20.000000. running mean: -20.466255\n",
            "resetting env. episode 1313.000000, reward total was -20.000000. running mean: -20.461592\n",
            "resetting env. episode 1314.000000, reward total was -21.000000. running mean: -20.466976\n",
            "resetting env. episode 1315.000000, reward total was -21.000000. running mean: -20.472307\n",
            "resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.477584\n",
            "resetting env. episode 1317.000000, reward total was -21.000000. running mean: -20.482808\n",
            "resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.487980\n",
            "resetting env. episode 1319.000000, reward total was -20.000000. running mean: -20.483100\n",
            "resetting env. episode 1320.000000, reward total was -20.000000. running mean: -20.478269\n",
            "resetting env. episode 1321.000000, reward total was -21.000000. running mean: -20.483486\n",
            "resetting env. episode 1322.000000, reward total was -20.000000. running mean: -20.478651\n",
            "resetting env. episode 1323.000000, reward total was -19.000000. running mean: -20.463865\n",
            "resetting env. episode 1324.000000, reward total was -20.000000. running mean: -20.459226\n",
            "resetting env. episode 1325.000000, reward total was -20.000000. running mean: -20.454634\n",
            "resetting env. episode 1326.000000, reward total was -20.000000. running mean: -20.450088\n",
            "resetting env. episode 1327.000000, reward total was -20.000000. running mean: -20.445587\n",
            "resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.451131\n",
            "resetting env. episode 1329.000000, reward total was -21.000000. running mean: -20.456619\n",
            "resetting env. episode 1330.000000, reward total was -21.000000. running mean: -20.462053\n",
            "resetting env. episode 1331.000000, reward total was -20.000000. running mean: -20.457433\n",
            "resetting env. episode 1332.000000, reward total was -21.000000. running mean: -20.462858\n",
            "resetting env. episode 1333.000000, reward total was -21.000000. running mean: -20.468230\n",
            "resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.473548\n",
            "resetting env. episode 1335.000000, reward total was -19.000000. running mean: -20.458812\n",
            "resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.464224\n",
            "resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.469582\n",
            "resetting env. episode 1338.000000, reward total was -20.000000. running mean: -20.464886\n",
            "resetting env. episode 1339.000000, reward total was -21.000000. running mean: -20.470237\n",
            "resetting env. episode 1340.000000, reward total was -21.000000. running mean: -20.475535\n",
            "resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.480779\n",
            "resetting env. episode 1342.000000, reward total was -21.000000. running mean: -20.485972\n",
            "resetting env. episode 1343.000000, reward total was -21.000000. running mean: -20.491112\n",
            "resetting env. episode 1344.000000, reward total was -21.000000. running mean: -20.496201\n",
            "resetting env. episode 1345.000000, reward total was -20.000000. running mean: -20.491239\n",
            "resetting env. episode 1346.000000, reward total was -21.000000. running mean: -20.496326\n",
            "resetting env. episode 1347.000000, reward total was -21.000000. running mean: -20.501363\n",
            "resetting env. episode 1348.000000, reward total was -20.000000. running mean: -20.496349\n",
            "resetting env. episode 1349.000000, reward total was -21.000000. running mean: -20.501386\n",
            "resetting env. episode 1350.000000, reward total was -20.000000. running mean: -20.496372\n",
            "resetting env. episode 1351.000000, reward total was -20.000000. running mean: -20.491408\n",
            "resetting env. episode 1352.000000, reward total was -20.000000. running mean: -20.486494\n",
            "resetting env. episode 1353.000000, reward total was -20.000000. running mean: -20.481629\n",
            "resetting env. episode 1354.000000, reward total was -21.000000. running mean: -20.486813\n",
            "resetting env. episode 1355.000000, reward total was -20.000000. running mean: -20.481945\n",
            "resetting env. episode 1356.000000, reward total was -21.000000. running mean: -20.487125\n",
            "resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.492254\n",
            "resetting env. episode 1358.000000, reward total was -21.000000. running mean: -20.497332\n",
            "resetting env. episode 1359.000000, reward total was -20.000000. running mean: -20.492358\n",
            "resetting env. episode 1360.000000, reward total was -17.000000. running mean: -20.457435\n",
            "resetting env. episode 1361.000000, reward total was -20.000000. running mean: -20.452860\n",
            "resetting env. episode 1362.000000, reward total was -21.000000. running mean: -20.458332\n",
            "resetting env. episode 1363.000000, reward total was -21.000000. running mean: -20.463748\n",
            "resetting env. episode 1364.000000, reward total was -21.000000. running mean: -20.469111\n",
            "resetting env. episode 1365.000000, reward total was -20.000000. running mean: -20.464420\n",
            "resetting env. episode 1366.000000, reward total was -19.000000. running mean: -20.449776\n",
            "resetting env. episode 1367.000000, reward total was -21.000000. running mean: -20.455278\n",
            "resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.460725\n",
            "resetting env. episode 1369.000000, reward total was -20.000000. running mean: -20.456118\n",
            "resetting env. episode 1370.000000, reward total was -21.000000. running mean: -20.461557\n",
            "resetting env. episode 1371.000000, reward total was -21.000000. running mean: -20.466941\n",
            "resetting env. episode 1372.000000, reward total was -21.000000. running mean: -20.472272\n",
            "resetting env. episode 1373.000000, reward total was -21.000000. running mean: -20.477549\n",
            "resetting env. episode 1374.000000, reward total was -21.000000. running mean: -20.482774\n",
            "resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.487946\n",
            "resetting env. episode 1376.000000, reward total was -20.000000. running mean: -20.483066\n",
            "resetting env. episode 1377.000000, reward total was -18.000000. running mean: -20.458236\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.463653\n",
            "resetting env. episode 1379.000000, reward total was -21.000000. running mean: -20.469017\n",
            "resetting env. episode 1380.000000, reward total was -20.000000. running mean: -20.464327\n",
            "resetting env. episode 1381.000000, reward total was -20.000000. running mean: -20.459683\n",
            "resetting env. episode 1382.000000, reward total was -21.000000. running mean: -20.465087\n",
            "resetting env. episode 1383.000000, reward total was -21.000000. running mean: -20.470436\n",
            "resetting env. episode 1384.000000, reward total was -19.000000. running mean: -20.455731\n",
            "resetting env. episode 1385.000000, reward total was -21.000000. running mean: -20.461174\n",
            "resetting env. episode 1386.000000, reward total was -21.000000. running mean: -20.466562\n",
            "resetting env. episode 1387.000000, reward total was -21.000000. running mean: -20.471897\n",
            "resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.477178\n",
            "resetting env. episode 1389.000000, reward total was -21.000000. running mean: -20.482406\n",
            "resetting env. episode 1390.000000, reward total was -21.000000. running mean: -20.487582\n",
            "resetting env. episode 1391.000000, reward total was -19.000000. running mean: -20.472706\n",
            "resetting env. episode 1392.000000, reward total was -17.000000. running mean: -20.437979\n",
            "resetting env. episode 1393.000000, reward total was -19.000000. running mean: -20.423599\n",
            "resetting env. episode 1394.000000, reward total was -19.000000. running mean: -20.409363\n",
            "resetting env. episode 1395.000000, reward total was -21.000000. running mean: -20.415270\n",
            "resetting env. episode 1396.000000, reward total was -20.000000. running mean: -20.411117\n",
            "resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.417006\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.422836\n",
            "resetting env. episode 1399.000000, reward total was -20.000000. running mean: -20.418607\n",
            "resetting env. episode 1400.000000, reward total was -20.000000. running mean: -20.414421\n",
            "resetting env. episode 1401.000000, reward total was -21.000000. running mean: -20.420277\n",
            "resetting env. episode 1402.000000, reward total was -21.000000. running mean: -20.426074\n",
            "resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.431813\n",
            "resetting env. episode 1404.000000, reward total was -21.000000. running mean: -20.437495\n",
            "resetting env. episode 1405.000000, reward total was -20.000000. running mean: -20.433120\n",
            "resetting env. episode 1406.000000, reward total was -21.000000. running mean: -20.438789\n",
            "resetting env. episode 1407.000000, reward total was -21.000000. running mean: -20.444401\n",
            "resetting env. episode 1408.000000, reward total was -19.000000. running mean: -20.429957\n",
            "resetting env. episode 1409.000000, reward total was -20.000000. running mean: -20.425658\n",
            "resetting env. episode 1410.000000, reward total was -21.000000. running mean: -20.431401\n",
            "resetting env. episode 1411.000000, reward total was -21.000000. running mean: -20.437087\n",
            "resetting env. episode 1412.000000, reward total was -20.000000. running mean: -20.432716\n",
            "resetting env. episode 1413.000000, reward total was -21.000000. running mean: -20.438389\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -20.444005\n",
            "resetting env. episode 1415.000000, reward total was -21.000000. running mean: -20.449565\n",
            "resetting env. episode 1416.000000, reward total was -21.000000. running mean: -20.455069\n",
            "resetting env. episode 1417.000000, reward total was -21.000000. running mean: -20.460519\n",
            "resetting env. episode 1418.000000, reward total was -20.000000. running mean: -20.455914\n",
            "resetting env. episode 1419.000000, reward total was -20.000000. running mean: -20.451354\n",
            "resetting env. episode 1420.000000, reward total was -21.000000. running mean: -20.456841\n",
            "resetting env. episode 1421.000000, reward total was -21.000000. running mean: -20.462273\n",
            "resetting env. episode 1422.000000, reward total was -20.000000. running mean: -20.457650\n",
            "resetting env. episode 1423.000000, reward total was -20.000000. running mean: -20.453073\n",
            "resetting env. episode 1424.000000, reward total was -20.000000. running mean: -20.448543\n",
            "resetting env. episode 1425.000000, reward total was -21.000000. running mean: -20.454057\n",
            "resetting env. episode 1426.000000, reward total was -19.000000. running mean: -20.439517\n",
            "resetting env. episode 1427.000000, reward total was -21.000000. running mean: -20.445121\n",
            "resetting env. episode 1428.000000, reward total was -19.000000. running mean: -20.430670\n",
            "resetting env. episode 1429.000000, reward total was -21.000000. running mean: -20.436363\n",
            "resetting env. episode 1430.000000, reward total was -21.000000. running mean: -20.442000\n",
            "resetting env. episode 1431.000000, reward total was -19.000000. running mean: -20.427580\n",
            "resetting env. episode 1432.000000, reward total was -21.000000. running mean: -20.433304\n",
            "resetting env. episode 1433.000000, reward total was -21.000000. running mean: -20.438971\n",
            "resetting env. episode 1434.000000, reward total was -21.000000. running mean: -20.444581\n",
            "resetting env. episode 1435.000000, reward total was -20.000000. running mean: -20.440135\n",
            "resetting env. episode 1436.000000, reward total was -20.000000. running mean: -20.435734\n",
            "resetting env. episode 1437.000000, reward total was -20.000000. running mean: -20.431377\n",
            "resetting env. episode 1438.000000, reward total was -21.000000. running mean: -20.437063\n",
            "resetting env. episode 1439.000000, reward total was -21.000000. running mean: -20.442692\n",
            "resetting env. episode 1440.000000, reward total was -20.000000. running mean: -20.438265\n",
            "resetting env. episode 1441.000000, reward total was -17.000000. running mean: -20.403883\n",
            "resetting env. episode 1442.000000, reward total was -21.000000. running mean: -20.409844\n",
            "resetting env. episode 1443.000000, reward total was -21.000000. running mean: -20.415746\n",
            "resetting env. episode 1444.000000, reward total was -20.000000. running mean: -20.411588\n",
            "resetting env. episode 1445.000000, reward total was -21.000000. running mean: -20.417472\n",
            "resetting env. episode 1446.000000, reward total was -21.000000. running mean: -20.423297\n",
            "resetting env. episode 1447.000000, reward total was -21.000000. running mean: -20.429065\n",
            "resetting env. episode 1448.000000, reward total was -21.000000. running mean: -20.434774\n",
            "resetting env. episode 1449.000000, reward total was -21.000000. running mean: -20.440426\n",
            "resetting env. episode 1450.000000, reward total was -21.000000. running mean: -20.446022\n",
            "resetting env. episode 1451.000000, reward total was -21.000000. running mean: -20.451562\n",
            "resetting env. episode 1452.000000, reward total was -21.000000. running mean: -20.457046\n",
            "resetting env. episode 1453.000000, reward total was -21.000000. running mean: -20.462476\n",
            "resetting env. episode 1454.000000, reward total was -21.000000. running mean: -20.467851\n",
            "resetting env. episode 1455.000000, reward total was -20.000000. running mean: -20.463172\n",
            "resetting env. episode 1456.000000, reward total was -20.000000. running mean: -20.458541\n",
            "resetting env. episode 1457.000000, reward total was -20.000000. running mean: -20.453955\n",
            "resetting env. episode 1458.000000, reward total was -21.000000. running mean: -20.459416\n",
            "resetting env. episode 1459.000000, reward total was -20.000000. running mean: -20.454821\n",
            "resetting env. episode 1460.000000, reward total was -21.000000. running mean: -20.460273\n",
            "resetting env. episode 1461.000000, reward total was -21.000000. running mean: -20.465671\n",
            "resetting env. episode 1462.000000, reward total was -20.000000. running mean: -20.461014\n",
            "resetting env. episode 1463.000000, reward total was -21.000000. running mean: -20.466404\n",
            "resetting env. episode 1464.000000, reward total was -16.000000. running mean: -20.421740\n",
            "resetting env. episode 1465.000000, reward total was -21.000000. running mean: -20.427522\n",
            "resetting env. episode 1466.000000, reward total was -21.000000. running mean: -20.433247\n",
            "resetting env. episode 1467.000000, reward total was -21.000000. running mean: -20.438915\n",
            "resetting env. episode 1468.000000, reward total was -19.000000. running mean: -20.424525\n",
            "resetting env. episode 1469.000000, reward total was -20.000000. running mean: -20.420280\n",
            "resetting env. episode 1470.000000, reward total was -21.000000. running mean: -20.426077\n",
            "resetting env. episode 1471.000000, reward total was -21.000000. running mean: -20.431817\n",
            "resetting env. episode 1472.000000, reward total was -20.000000. running mean: -20.427498\n",
            "resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.433223\n",
            "resetting env. episode 1474.000000, reward total was -21.000000. running mean: -20.438891\n",
            "resetting env. episode 1475.000000, reward total was -21.000000. running mean: -20.444502\n",
            "resetting env. episode 1476.000000, reward total was -21.000000. running mean: -20.450057\n",
            "resetting env. episode 1477.000000, reward total was -21.000000. running mean: -20.455557\n",
            "resetting env. episode 1478.000000, reward total was -21.000000. running mean: -20.461001\n",
            "resetting env. episode 1479.000000, reward total was -19.000000. running mean: -20.446391\n",
            "resetting env. episode 1480.000000, reward total was -21.000000. running mean: -20.451927\n",
            "resetting env. episode 1481.000000, reward total was -20.000000. running mean: -20.447408\n",
            "resetting env. episode 1482.000000, reward total was -21.000000. running mean: -20.452934\n",
            "resetting env. episode 1483.000000, reward total was -19.000000. running mean: -20.438405\n",
            "resetting env. episode 1484.000000, reward total was -21.000000. running mean: -20.444020\n",
            "resetting env. episode 1485.000000, reward total was -20.000000. running mean: -20.439580\n",
            "resetting env. episode 1486.000000, reward total was -21.000000. running mean: -20.445184\n",
            "resetting env. episode 1487.000000, reward total was -21.000000. running mean: -20.450733\n",
            "resetting env. episode 1488.000000, reward total was -21.000000. running mean: -20.456225\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.461663\n",
            "resetting env. episode 1490.000000, reward total was -21.000000. running mean: -20.467046\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.472376\n",
            "resetting env. episode 1492.000000, reward total was -21.000000. running mean: -20.477652\n",
            "resetting env. episode 1493.000000, reward total was -19.000000. running mean: -20.462876\n",
            "resetting env. episode 1494.000000, reward total was -21.000000. running mean: -20.468247\n",
            "resetting env. episode 1495.000000, reward total was -21.000000. running mean: -20.473564\n",
            "resetting env. episode 1496.000000, reward total was -20.000000. running mean: -20.468829\n",
            "resetting env. episode 1497.000000, reward total was -21.000000. running mean: -20.474140\n",
            "resetting env. episode 1498.000000, reward total was -21.000000. running mean: -20.479399\n",
            "resetting env. episode 1499.000000, reward total was -21.000000. running mean: -20.484605\n",
            "resetting env. episode 1500.000000, reward total was -21.000000. running mean: -20.489759\n",
            "resetting env. episode 1501.000000, reward total was -21.000000. running mean: -20.494861\n",
            "resetting env. episode 1502.000000, reward total was -21.000000. running mean: -20.499913\n",
            "resetting env. episode 1503.000000, reward total was -21.000000. running mean: -20.504914\n",
            "resetting env. episode 1504.000000, reward total was -21.000000. running mean: -20.509865\n",
            "resetting env. episode 1505.000000, reward total was -21.000000. running mean: -20.514766\n",
            "resetting env. episode 1506.000000, reward total was -21.000000. running mean: -20.519618\n",
            "resetting env. episode 1507.000000, reward total was -21.000000. running mean: -20.524422\n",
            "resetting env. episode 1508.000000, reward total was -19.000000. running mean: -20.509178\n",
            "resetting env. episode 1509.000000, reward total was -21.000000. running mean: -20.514086\n",
            "resetting env. episode 1510.000000, reward total was -21.000000. running mean: -20.518945\n",
            "resetting env. episode 1511.000000, reward total was -21.000000. running mean: -20.523756\n",
            "resetting env. episode 1512.000000, reward total was -21.000000. running mean: -20.528518\n",
            "resetting env. episode 1513.000000, reward total was -21.000000. running mean: -20.533233\n",
            "resetting env. episode 1514.000000, reward total was -21.000000. running mean: -20.537901\n",
            "resetting env. episode 1515.000000, reward total was -21.000000. running mean: -20.542522\n",
            "resetting env. episode 1516.000000, reward total was -21.000000. running mean: -20.547096\n",
            "resetting env. episode 1517.000000, reward total was -21.000000. running mean: -20.551626\n",
            "resetting env. episode 1518.000000, reward total was -20.000000. running mean: -20.546109\n",
            "resetting env. episode 1519.000000, reward total was -20.000000. running mean: -20.540648\n",
            "resetting env. episode 1520.000000, reward total was -21.000000. running mean: -20.545242\n",
            "resetting env. episode 1521.000000, reward total was -21.000000. running mean: -20.549789\n",
            "resetting env. episode 1522.000000, reward total was -21.000000. running mean: -20.554291\n",
            "resetting env. episode 1523.000000, reward total was -21.000000. running mean: -20.558748\n",
            "resetting env. episode 1524.000000, reward total was -21.000000. running mean: -20.563161\n",
            "resetting env. episode 1525.000000, reward total was -20.000000. running mean: -20.557529\n",
            "resetting env. episode 1526.000000, reward total was -20.000000. running mean: -20.551954\n",
            "resetting env. episode 1527.000000, reward total was -21.000000. running mean: -20.556435\n",
            "resetting env. episode 1528.000000, reward total was -20.000000. running mean: -20.550870\n",
            "resetting env. episode 1529.000000, reward total was -20.000000. running mean: -20.545361\n",
            "resetting env. episode 1530.000000, reward total was -18.000000. running mean: -20.519908\n",
            "resetting env. episode 1531.000000, reward total was -21.000000. running mean: -20.524709\n",
            "resetting env. episode 1532.000000, reward total was -21.000000. running mean: -20.529462\n",
            "resetting env. episode 1533.000000, reward total was -20.000000. running mean: -20.524167\n",
            "resetting env. episode 1534.000000, reward total was -21.000000. running mean: -20.528925\n",
            "resetting env. episode 1535.000000, reward total was -21.000000. running mean: -20.533636\n",
            "resetting env. episode 1536.000000, reward total was -18.000000. running mean: -20.508300\n",
            "resetting env. episode 1537.000000, reward total was -20.000000. running mean: -20.503217\n",
            "resetting env. episode 1538.000000, reward total was -18.000000. running mean: -20.478185\n",
            "resetting env. episode 1539.000000, reward total was -21.000000. running mean: -20.483403\n",
            "resetting env. episode 1540.000000, reward total was -21.000000. running mean: -20.488569\n",
            "resetting env. episode 1541.000000, reward total was -21.000000. running mean: -20.493683\n",
            "resetting env. episode 1542.000000, reward total was -21.000000. running mean: -20.498746\n",
            "resetting env. episode 1543.000000, reward total was -20.000000. running mean: -20.493759\n",
            "resetting env. episode 1544.000000, reward total was -21.000000. running mean: -20.498821\n",
            "resetting env. episode 1545.000000, reward total was -19.000000. running mean: -20.483833\n",
            "resetting env. episode 1546.000000, reward total was -21.000000. running mean: -20.488995\n",
            "resetting env. episode 1547.000000, reward total was -20.000000. running mean: -20.484105\n",
            "resetting env. episode 1548.000000, reward total was -21.000000. running mean: -20.489264\n",
            "resetting env. episode 1549.000000, reward total was -19.000000. running mean: -20.474371\n",
            "resetting env. episode 1550.000000, reward total was -21.000000. running mean: -20.479627\n",
            "resetting env. episode 1551.000000, reward total was -20.000000. running mean: -20.474831\n",
            "resetting env. episode 1552.000000, reward total was -18.000000. running mean: -20.450083\n",
            "resetting env. episode 1553.000000, reward total was -21.000000. running mean: -20.455582\n",
            "resetting env. episode 1554.000000, reward total was -20.000000. running mean: -20.451026\n",
            "resetting env. episode 1555.000000, reward total was -21.000000. running mean: -20.456516\n",
            "resetting env. episode 1556.000000, reward total was -21.000000. running mean: -20.461951\n",
            "resetting env. episode 1557.000000, reward total was -20.000000. running mean: -20.457331\n",
            "resetting env. episode 1558.000000, reward total was -21.000000. running mean: -20.462758\n",
            "resetting env. episode 1559.000000, reward total was -20.000000. running mean: -20.458130\n",
            "resetting env. episode 1560.000000, reward total was -21.000000. running mean: -20.463549\n",
            "resetting env. episode 1561.000000, reward total was -21.000000. running mean: -20.468913\n",
            "resetting env. episode 1562.000000, reward total was -20.000000. running mean: -20.464224\n",
            "resetting env. episode 1563.000000, reward total was -20.000000. running mean: -20.459582\n",
            "resetting env. episode 1564.000000, reward total was -21.000000. running mean: -20.464986\n",
            "resetting env. episode 1565.000000, reward total was -20.000000. running mean: -20.460336\n",
            "resetting env. episode 1566.000000, reward total was -21.000000. running mean: -20.465733\n",
            "resetting env. episode 1567.000000, reward total was -21.000000. running mean: -20.471076\n",
            "resetting env. episode 1568.000000, reward total was -21.000000. running mean: -20.476365\n",
            "resetting env. episode 1569.000000, reward total was -19.000000. running mean: -20.461601\n",
            "resetting env. episode 1570.000000, reward total was -21.000000. running mean: -20.466985\n",
            "resetting env. episode 1571.000000, reward total was -19.000000. running mean: -20.452315\n",
            "resetting env. episode 1572.000000, reward total was -20.000000. running mean: -20.447792\n",
            "resetting env. episode 1573.000000, reward total was -21.000000. running mean: -20.453314\n",
            "resetting env. episode 1574.000000, reward total was -21.000000. running mean: -20.458781\n",
            "resetting env. episode 1575.000000, reward total was -21.000000. running mean: -20.464193\n",
            "resetting env. episode 1576.000000, reward total was -21.000000. running mean: -20.469551\n",
            "resetting env. episode 1577.000000, reward total was -21.000000. running mean: -20.474856\n",
            "resetting env. episode 1578.000000, reward total was -21.000000. running mean: -20.480107\n",
            "resetting env. episode 1579.000000, reward total was -19.000000. running mean: -20.465306\n",
            "resetting env. episode 1580.000000, reward total was -21.000000. running mean: -20.470653\n",
            "resetting env. episode 1581.000000, reward total was -20.000000. running mean: -20.465947\n",
            "resetting env. episode 1582.000000, reward total was -19.000000. running mean: -20.451287\n",
            "resetting env. episode 1583.000000, reward total was -19.000000. running mean: -20.436774\n",
            "resetting env. episode 1584.000000, reward total was -21.000000. running mean: -20.442407\n",
            "resetting env. episode 1585.000000, reward total was -21.000000. running mean: -20.447983\n",
            "resetting env. episode 1586.000000, reward total was -20.000000. running mean: -20.443503\n",
            "resetting env. episode 1587.000000, reward total was -20.000000. running mean: -20.439068\n",
            "resetting env. episode 1588.000000, reward total was -21.000000. running mean: -20.444677\n",
            "resetting env. episode 1589.000000, reward total was -19.000000. running mean: -20.430230\n",
            "resetting env. episode 1590.000000, reward total was -20.000000. running mean: -20.425928\n",
            "resetting env. episode 1591.000000, reward total was -21.000000. running mean: -20.431669\n",
            "resetting env. episode 1592.000000, reward total was -21.000000. running mean: -20.437352\n",
            "resetting env. episode 1593.000000, reward total was -21.000000. running mean: -20.442978\n",
            "resetting env. episode 1594.000000, reward total was -21.000000. running mean: -20.448549\n",
            "resetting env. episode 1595.000000, reward total was -20.000000. running mean: -20.444063\n",
            "resetting env. episode 1596.000000, reward total was -21.000000. running mean: -20.449623\n",
            "resetting env. episode 1597.000000, reward total was -21.000000. running mean: -20.455126\n",
            "resetting env. episode 1598.000000, reward total was -21.000000. running mean: -20.460575\n",
            "resetting env. episode 1599.000000, reward total was -21.000000. running mean: -20.465969\n",
            "resetting env. episode 1600.000000, reward total was -21.000000. running mean: -20.471310\n",
            "resetting env. episode 1601.000000, reward total was -20.000000. running mean: -20.466597\n",
            "resetting env. episode 1602.000000, reward total was -21.000000. running mean: -20.471931\n",
            "resetting env. episode 1603.000000, reward total was -21.000000. running mean: -20.477211\n",
            "resetting env. episode 1604.000000, reward total was -21.000000. running mean: -20.482439\n",
            "resetting env. episode 1605.000000, reward total was -21.000000. running mean: -20.487615\n",
            "resetting env. episode 1606.000000, reward total was -21.000000. running mean: -20.492739\n",
            "resetting env. episode 1607.000000, reward total was -20.000000. running mean: -20.487811\n",
            "resetting env. episode 1608.000000, reward total was -21.000000. running mean: -20.492933\n",
            "resetting env. episode 1609.000000, reward total was -21.000000. running mean: -20.498004\n",
            "resetting env. episode 1610.000000, reward total was -20.000000. running mean: -20.493024\n",
            "resetting env. episode 1611.000000, reward total was -21.000000. running mean: -20.498094\n",
            "resetting env. episode 1612.000000, reward total was -20.000000. running mean: -20.493113\n",
            "resetting env. episode 1613.000000, reward total was -20.000000. running mean: -20.488181\n",
            "resetting env. episode 1614.000000, reward total was -21.000000. running mean: -20.493300\n",
            "resetting env. episode 1615.000000, reward total was -21.000000. running mean: -20.498367\n",
            "resetting env. episode 1616.000000, reward total was -20.000000. running mean: -20.493383\n",
            "resetting env. episode 1617.000000, reward total was -20.000000. running mean: -20.488449\n",
            "resetting env. episode 1618.000000, reward total was -20.000000. running mean: -20.483565\n",
            "resetting env. episode 1619.000000, reward total was -21.000000. running mean: -20.488729\n",
            "resetting env. episode 1620.000000, reward total was -21.000000. running mean: -20.493842\n",
            "resetting env. episode 1621.000000, reward total was -21.000000. running mean: -20.498903\n",
            "resetting env. episode 1622.000000, reward total was -21.000000. running mean: -20.503914\n",
            "resetting env. episode 1623.000000, reward total was -21.000000. running mean: -20.508875\n",
            "resetting env. episode 1624.000000, reward total was -21.000000. running mean: -20.513786\n",
            "resetting env. episode 1625.000000, reward total was -21.000000. running mean: -20.518649\n",
            "resetting env. episode 1626.000000, reward total was -21.000000. running mean: -20.523462\n",
            "resetting env. episode 1627.000000, reward total was -20.000000. running mean: -20.518227\n",
            "resetting env. episode 1628.000000, reward total was -21.000000. running mean: -20.523045\n",
            "resetting env. episode 1629.000000, reward total was -21.000000. running mean: -20.527815\n",
            "resetting env. episode 1630.000000, reward total was -21.000000. running mean: -20.532537\n",
            "resetting env. episode 1631.000000, reward total was -19.000000. running mean: -20.517211\n",
            "resetting env. episode 1632.000000, reward total was -21.000000. running mean: -20.522039\n",
            "resetting env. episode 1633.000000, reward total was -19.000000. running mean: -20.506819\n",
            "resetting env. episode 1634.000000, reward total was -21.000000. running mean: -20.511750\n",
            "resetting env. episode 1635.000000, reward total was -21.000000. running mean: -20.516633\n",
            "resetting env. episode 1636.000000, reward total was -21.000000. running mean: -20.521467\n",
            "resetting env. episode 1637.000000, reward total was -20.000000. running mean: -20.516252\n",
            "resetting env. episode 1638.000000, reward total was -20.000000. running mean: -20.511089\n",
            "resetting env. episode 1639.000000, reward total was -21.000000. running mean: -20.515979\n",
            "resetting env. episode 1640.000000, reward total was -21.000000. running mean: -20.520819\n",
            "resetting env. episode 1641.000000, reward total was -21.000000. running mean: -20.525611\n",
            "resetting env. episode 1642.000000, reward total was -20.000000. running mean: -20.520354\n",
            "resetting env. episode 1643.000000, reward total was -21.000000. running mean: -20.525151\n",
            "resetting env. episode 1644.000000, reward total was -19.000000. running mean: -20.509899\n",
            "resetting env. episode 1645.000000, reward total was -19.000000. running mean: -20.494800\n",
            "resetting env. episode 1646.000000, reward total was -21.000000. running mean: -20.499852\n",
            "resetting env. episode 1647.000000, reward total was -20.000000. running mean: -20.494854\n",
            "resetting env. episode 1648.000000, reward total was -21.000000. running mean: -20.499905\n",
            "resetting env. episode 1649.000000, reward total was -21.000000. running mean: -20.504906\n",
            "resetting env. episode 1650.000000, reward total was -21.000000. running mean: -20.509857\n",
            "resetting env. episode 1651.000000, reward total was -18.000000. running mean: -20.484759\n",
            "resetting env. episode 1652.000000, reward total was -21.000000. running mean: -20.489911\n",
            "resetting env. episode 1653.000000, reward total was -20.000000. running mean: -20.485012\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -20.490162\n",
            "resetting env. episode 1655.000000, reward total was -20.000000. running mean: -20.485260\n",
            "resetting env. episode 1656.000000, reward total was -21.000000. running mean: -20.490408\n",
            "resetting env. episode 1657.000000, reward total was -19.000000. running mean: -20.475504\n",
            "resetting env. episode 1658.000000, reward total was -21.000000. running mean: -20.480749\n",
            "resetting env. episode 1659.000000, reward total was -21.000000. running mean: -20.485941\n",
            "resetting env. episode 1660.000000, reward total was -21.000000. running mean: -20.491082\n",
            "resetting env. episode 1661.000000, reward total was -20.000000. running mean: -20.486171\n",
            "resetting env. episode 1662.000000, reward total was -19.000000. running mean: -20.471309\n",
            "resetting env. episode 1663.000000, reward total was -21.000000. running mean: -20.476596\n",
            "resetting env. episode 1664.000000, reward total was -21.000000. running mean: -20.481830\n",
            "resetting env. episode 1665.000000, reward total was -21.000000. running mean: -20.487012\n",
            "resetting env. episode 1666.000000, reward total was -21.000000. running mean: -20.492142\n",
            "resetting env. episode 1667.000000, reward total was -19.000000. running mean: -20.477220\n",
            "resetting env. episode 1668.000000, reward total was -20.000000. running mean: -20.472448\n",
            "resetting env. episode 1669.000000, reward total was -21.000000. running mean: -20.477724\n",
            "resetting env. episode 1670.000000, reward total was -21.000000. running mean: -20.482946\n",
            "resetting env. episode 1671.000000, reward total was -21.000000. running mean: -20.488117\n",
            "resetting env. episode 1672.000000, reward total was -21.000000. running mean: -20.493236\n",
            "resetting env. episode 1673.000000, reward total was -21.000000. running mean: -20.498303\n",
            "resetting env. episode 1674.000000, reward total was -21.000000. running mean: -20.503320\n",
            "resetting env. episode 1675.000000, reward total was -21.000000. running mean: -20.508287\n",
            "resetting env. episode 1676.000000, reward total was -21.000000. running mean: -20.513204\n",
            "resetting env. episode 1677.000000, reward total was -20.000000. running mean: -20.508072\n",
            "resetting env. episode 1678.000000, reward total was -21.000000. running mean: -20.512991\n",
            "resetting env. episode 1679.000000, reward total was -19.000000. running mean: -20.497862\n",
            "resetting env. episode 1680.000000, reward total was -21.000000. running mean: -20.502883\n",
            "resetting env. episode 1681.000000, reward total was -20.000000. running mean: -20.497854\n",
            "resetting env. episode 1682.000000, reward total was -21.000000. running mean: -20.502876\n",
            "resetting env. episode 1683.000000, reward total was -19.000000. running mean: -20.487847\n",
            "resetting env. episode 1684.000000, reward total was -20.000000. running mean: -20.482968\n",
            "resetting env. episode 1685.000000, reward total was -21.000000. running mean: -20.488139\n",
            "resetting env. episode 1686.000000, reward total was -19.000000. running mean: -20.473257\n",
            "resetting env. episode 1687.000000, reward total was -20.000000. running mean: -20.468525\n",
            "resetting env. episode 1688.000000, reward total was -20.000000. running mean: -20.463839\n",
            "resetting env. episode 1689.000000, reward total was -19.000000. running mean: -20.449201\n",
            "resetting env. episode 1690.000000, reward total was -21.000000. running mean: -20.454709\n",
            "resetting env. episode 1691.000000, reward total was -21.000000. running mean: -20.460162\n",
            "resetting env. episode 1692.000000, reward total was -20.000000. running mean: -20.455560\n",
            "resetting env. episode 1693.000000, reward total was -21.000000. running mean: -20.461005\n",
            "resetting env. episode 1694.000000, reward total was -21.000000. running mean: -20.466395\n",
            "resetting env. episode 1695.000000, reward total was -21.000000. running mean: -20.471731\n",
            "resetting env. episode 1696.000000, reward total was -21.000000. running mean: -20.477013\n",
            "resetting env. episode 1697.000000, reward total was -21.000000. running mean: -20.482243\n",
            "resetting env. episode 1698.000000, reward total was -21.000000. running mean: -20.487421\n",
            "resetting env. episode 1699.000000, reward total was -20.000000. running mean: -20.482547\n",
            "resetting env. episode 1700.000000, reward total was -19.000000. running mean: -20.467721\n",
            "resetting env. episode 1701.000000, reward total was -20.000000. running mean: -20.463044\n",
            "resetting env. episode 1702.000000, reward total was -20.000000. running mean: -20.458414\n",
            "resetting env. episode 1703.000000, reward total was -21.000000. running mean: -20.463829\n",
            "resetting env. episode 1704.000000, reward total was -21.000000. running mean: -20.469191\n",
            "resetting env. episode 1705.000000, reward total was -21.000000. running mean: -20.474499\n",
            "resetting env. episode 1706.000000, reward total was -21.000000. running mean: -20.479754\n",
            "resetting env. episode 1707.000000, reward total was -21.000000. running mean: -20.484957\n",
            "resetting env. episode 1708.000000, reward total was -21.000000. running mean: -20.490107\n",
            "resetting env. episode 1709.000000, reward total was -20.000000. running mean: -20.485206\n",
            "resetting env. episode 1710.000000, reward total was -21.000000. running mean: -20.490354\n",
            "resetting env. episode 1711.000000, reward total was -21.000000. running mean: -20.495450\n",
            "resetting env. episode 1712.000000, reward total was -20.000000. running mean: -20.490496\n",
            "resetting env. episode 1713.000000, reward total was -20.000000. running mean: -20.485591\n",
            "resetting env. episode 1714.000000, reward total was -21.000000. running mean: -20.490735\n",
            "resetting env. episode 1715.000000, reward total was -21.000000. running mean: -20.495828\n",
            "resetting env. episode 1716.000000, reward total was -20.000000. running mean: -20.490869\n",
            "resetting env. episode 1717.000000, reward total was -21.000000. running mean: -20.495961\n",
            "resetting env. episode 1718.000000, reward total was -21.000000. running mean: -20.501001\n",
            "resetting env. episode 1719.000000, reward total was -21.000000. running mean: -20.505991\n",
            "resetting env. episode 1720.000000, reward total was -19.000000. running mean: -20.490931\n",
            "resetting env. episode 1721.000000, reward total was -21.000000. running mean: -20.496022\n",
            "resetting env. episode 1722.000000, reward total was -21.000000. running mean: -20.501062\n",
            "resetting env. episode 1723.000000, reward total was -21.000000. running mean: -20.506051\n",
            "resetting env. episode 1724.000000, reward total was -21.000000. running mean: -20.510991\n",
            "resetting env. episode 1725.000000, reward total was -21.000000. running mean: -20.515881\n",
            "resetting env. episode 1726.000000, reward total was -19.000000. running mean: -20.500722\n",
            "resetting env. episode 1727.000000, reward total was -21.000000. running mean: -20.505715\n",
            "resetting env. episode 1728.000000, reward total was -21.000000. running mean: -20.510657\n",
            "resetting env. episode 1729.000000, reward total was -20.000000. running mean: -20.505551\n",
            "resetting env. episode 1730.000000, reward total was -20.000000. running mean: -20.500495\n",
            "resetting env. episode 1731.000000, reward total was -19.000000. running mean: -20.485490\n",
            "resetting env. episode 1732.000000, reward total was -21.000000. running mean: -20.490636\n",
            "resetting env. episode 1733.000000, reward total was -21.000000. running mean: -20.495729\n",
            "resetting env. episode 1734.000000, reward total was -20.000000. running mean: -20.490772\n",
            "resetting env. episode 1735.000000, reward total was -21.000000. running mean: -20.495864\n",
            "resetting env. episode 1736.000000, reward total was -21.000000. running mean: -20.500906\n",
            "resetting env. episode 1737.000000, reward total was -20.000000. running mean: -20.495896\n",
            "resetting env. episode 1738.000000, reward total was -21.000000. running mean: -20.500937\n",
            "resetting env. episode 1739.000000, reward total was -20.000000. running mean: -20.495928\n",
            "resetting env. episode 1740.000000, reward total was -21.000000. running mean: -20.500969\n",
            "resetting env. episode 1741.000000, reward total was -21.000000. running mean: -20.505959\n",
            "resetting env. episode 1742.000000, reward total was -18.000000. running mean: -20.480900\n",
            "resetting env. episode 1743.000000, reward total was -21.000000. running mean: -20.486091\n",
            "resetting env. episode 1744.000000, reward total was -20.000000. running mean: -20.481230\n",
            "resetting env. episode 1745.000000, reward total was -21.000000. running mean: -20.486417\n",
            "resetting env. episode 1746.000000, reward total was -20.000000. running mean: -20.481553\n",
            "resetting env. episode 1747.000000, reward total was -20.000000. running mean: -20.476738\n",
            "resetting env. episode 1748.000000, reward total was -21.000000. running mean: -20.481970\n",
            "resetting env. episode 1749.000000, reward total was -21.000000. running mean: -20.487151\n",
            "resetting env. episode 1750.000000, reward total was -18.000000. running mean: -20.462279\n",
            "resetting env. episode 1751.000000, reward total was -21.000000. running mean: -20.467656\n",
            "resetting env. episode 1752.000000, reward total was -20.000000. running mean: -20.462980\n",
            "resetting env. episode 1753.000000, reward total was -19.000000. running mean: -20.448350\n",
            "resetting env. episode 1754.000000, reward total was -21.000000. running mean: -20.453866\n",
            "resetting env. episode 1755.000000, reward total was -20.000000. running mean: -20.449328\n",
            "resetting env. episode 1756.000000, reward total was -21.000000. running mean: -20.454834\n",
            "resetting env. episode 1757.000000, reward total was -21.000000. running mean: -20.460286\n",
            "resetting env. episode 1758.000000, reward total was -21.000000. running mean: -20.465683\n",
            "resetting env. episode 1759.000000, reward total was -21.000000. running mean: -20.471026\n",
            "resetting env. episode 1760.000000, reward total was -20.000000. running mean: -20.466316\n",
            "resetting env. episode 1761.000000, reward total was -20.000000. running mean: -20.461653\n",
            "resetting env. episode 1762.000000, reward total was -21.000000. running mean: -20.467036\n",
            "resetting env. episode 1763.000000, reward total was -20.000000. running mean: -20.462366\n",
            "resetting env. episode 1764.000000, reward total was -20.000000. running mean: -20.457742\n",
            "resetting env. episode 1765.000000, reward total was -21.000000. running mean: -20.463165\n",
            "resetting env. episode 1766.000000, reward total was -21.000000. running mean: -20.468533\n",
            "resetting env. episode 1767.000000, reward total was -21.000000. running mean: -20.473848\n",
            "resetting env. episode 1768.000000, reward total was -21.000000. running mean: -20.479110\n",
            "resetting env. episode 1769.000000, reward total was -20.000000. running mean: -20.474318\n",
            "resetting env. episode 1770.000000, reward total was -21.000000. running mean: -20.479575\n",
            "resetting env. episode 1771.000000, reward total was -19.000000. running mean: -20.464780\n",
            "resetting env. episode 1772.000000, reward total was -21.000000. running mean: -20.470132\n",
            "resetting env. episode 1773.000000, reward total was -21.000000. running mean: -20.475430\n",
            "resetting env. episode 1774.000000, reward total was -21.000000. running mean: -20.480676\n",
            "resetting env. episode 1775.000000, reward total was -19.000000. running mean: -20.465869\n",
            "resetting env. episode 1776.000000, reward total was -21.000000. running mean: -20.471211\n",
            "resetting env. episode 1777.000000, reward total was -21.000000. running mean: -20.476499\n",
            "resetting env. episode 1778.000000, reward total was -21.000000. running mean: -20.481734\n",
            "resetting env. episode 1779.000000, reward total was -21.000000. running mean: -20.486916\n",
            "resetting env. episode 1780.000000, reward total was -21.000000. running mean: -20.492047\n",
            "resetting env. episode 1781.000000, reward total was -21.000000. running mean: -20.497127\n",
            "resetting env. episode 1782.000000, reward total was -19.000000. running mean: -20.482155\n",
            "resetting env. episode 1783.000000, reward total was -21.000000. running mean: -20.487334\n",
            "resetting env. episode 1784.000000, reward total was -21.000000. running mean: -20.492460\n",
            "resetting env. episode 1785.000000, reward total was -21.000000. running mean: -20.497536\n",
            "resetting env. episode 1786.000000, reward total was -21.000000. running mean: -20.502560\n",
            "resetting env. episode 1787.000000, reward total was -21.000000. running mean: -20.507535\n",
            "resetting env. episode 1788.000000, reward total was -21.000000. running mean: -20.512460\n",
            "resetting env. episode 1789.000000, reward total was -21.000000. running mean: -20.517335\n",
            "resetting env. episode 1790.000000, reward total was -20.000000. running mean: -20.512162\n",
            "resetting env. episode 1791.000000, reward total was -20.000000. running mean: -20.507040\n",
            "resetting env. episode 1792.000000, reward total was -21.000000. running mean: -20.511970\n",
            "resetting env. episode 1793.000000, reward total was -18.000000. running mean: -20.486850\n",
            "resetting env. episode 1794.000000, reward total was -21.000000. running mean: -20.491981\n",
            "resetting env. episode 1795.000000, reward total was -19.000000. running mean: -20.477062\n",
            "resetting env. episode 1796.000000, reward total was -20.000000. running mean: -20.472291\n",
            "resetting env. episode 1797.000000, reward total was -20.000000. running mean: -20.467568\n",
            "resetting env. episode 1798.000000, reward total was -21.000000. running mean: -20.472892\n",
            "resetting env. episode 1799.000000, reward total was -20.000000. running mean: -20.468163\n",
            "resetting env. episode 1800.000000, reward total was -21.000000. running mean: -20.473482\n",
            "resetting env. episode 1801.000000, reward total was -20.000000. running mean: -20.468747\n",
            "resetting env. episode 1802.000000, reward total was -21.000000. running mean: -20.474060\n",
            "resetting env. episode 1803.000000, reward total was -20.000000. running mean: -20.469319\n",
            "resetting env. episode 1804.000000, reward total was -20.000000. running mean: -20.464626\n",
            "resetting env. episode 1805.000000, reward total was -21.000000. running mean: -20.469979\n",
            "resetting env. episode 1806.000000, reward total was -20.000000. running mean: -20.465280\n",
            "resetting env. episode 1807.000000, reward total was -21.000000. running mean: -20.470627\n",
            "resetting env. episode 1808.000000, reward total was -20.000000. running mean: -20.465921\n",
            "resetting env. episode 1809.000000, reward total was -21.000000. running mean: -20.471261\n",
            "resetting env. episode 1810.000000, reward total was -19.000000. running mean: -20.456549\n",
            "resetting env. episode 1811.000000, reward total was -21.000000. running mean: -20.461983\n",
            "resetting env. episode 1812.000000, reward total was -21.000000. running mean: -20.467363\n",
            "resetting env. episode 1813.000000, reward total was -21.000000. running mean: -20.472690\n",
            "resetting env. episode 1814.000000, reward total was -21.000000. running mean: -20.477963\n",
            "resetting env. episode 1815.000000, reward total was -20.000000. running mean: -20.473183\n",
            "resetting env. episode 1816.000000, reward total was -21.000000. running mean: -20.478451\n",
            "resetting env. episode 1817.000000, reward total was -20.000000. running mean: -20.473667\n",
            "resetting env. episode 1818.000000, reward total was -21.000000. running mean: -20.478930\n",
            "resetting env. episode 1819.000000, reward total was -20.000000. running mean: -20.474141\n",
            "resetting env. episode 1820.000000, reward total was -21.000000. running mean: -20.479400\n",
            "resetting env. episode 1821.000000, reward total was -18.000000. running mean: -20.454606\n",
            "resetting env. episode 1822.000000, reward total was -21.000000. running mean: -20.460060\n",
            "resetting env. episode 1823.000000, reward total was -21.000000. running mean: -20.465459\n",
            "resetting env. episode 1824.000000, reward total was -21.000000. running mean: -20.470804\n",
            "resetting env. episode 1825.000000, reward total was -21.000000. running mean: -20.476096\n",
            "resetting env. episode 1826.000000, reward total was -21.000000. running mean: -20.481335\n",
            "resetting env. episode 1827.000000, reward total was -17.000000. running mean: -20.446522\n",
            "resetting env. episode 1828.000000, reward total was -20.000000. running mean: -20.442057\n",
            "resetting env. episode 1829.000000, reward total was -21.000000. running mean: -20.447636\n",
            "resetting env. episode 1830.000000, reward total was -20.000000. running mean: -20.443160\n",
            "resetting env. episode 1831.000000, reward total was -21.000000. running mean: -20.448728\n",
            "resetting env. episode 1832.000000, reward total was -21.000000. running mean: -20.454241\n",
            "resetting env. episode 1833.000000, reward total was -21.000000. running mean: -20.459699\n",
            "resetting env. episode 1834.000000, reward total was -21.000000. running mean: -20.465102\n",
            "resetting env. episode 1835.000000, reward total was -21.000000. running mean: -20.470451\n",
            "resetting env. episode 1836.000000, reward total was -21.000000. running mean: -20.475746\n",
            "resetting env. episode 1837.000000, reward total was -20.000000. running mean: -20.470989\n",
            "resetting env. episode 1838.000000, reward total was -21.000000. running mean: -20.476279\n",
            "resetting env. episode 1839.000000, reward total was -21.000000. running mean: -20.481516\n",
            "resetting env. episode 1840.000000, reward total was -21.000000. running mean: -20.486701\n",
            "resetting env. episode 1841.000000, reward total was -21.000000. running mean: -20.491834\n",
            "resetting env. episode 1842.000000, reward total was -21.000000. running mean: -20.496915\n",
            "resetting env. episode 1843.000000, reward total was -20.000000. running mean: -20.491946\n",
            "resetting env. episode 1844.000000, reward total was -21.000000. running mean: -20.497027\n",
            "resetting env. episode 1845.000000, reward total was -21.000000. running mean: -20.502057\n",
            "resetting env. episode 1846.000000, reward total was -21.000000. running mean: -20.507036\n",
            "resetting env. episode 1847.000000, reward total was -20.000000. running mean: -20.501966\n",
            "resetting env. episode 1848.000000, reward total was -20.000000. running mean: -20.496946\n",
            "resetting env. episode 1849.000000, reward total was -20.000000. running mean: -20.491976\n",
            "resetting env. episode 1850.000000, reward total was -21.000000. running mean: -20.497057\n",
            "resetting env. episode 1851.000000, reward total was -21.000000. running mean: -20.502086\n",
            "resetting env. episode 1852.000000, reward total was -21.000000. running mean: -20.507065\n",
            "resetting env. episode 1853.000000, reward total was -18.000000. running mean: -20.481995\n",
            "resetting env. episode 1854.000000, reward total was -21.000000. running mean: -20.487175\n",
            "resetting env. episode 1855.000000, reward total was -20.000000. running mean: -20.482303\n",
            "resetting env. episode 1856.000000, reward total was -21.000000. running mean: -20.487480\n",
            "resetting env. episode 1857.000000, reward total was -21.000000. running mean: -20.492605\n",
            "resetting env. episode 1858.000000, reward total was -21.000000. running mean: -20.497679\n",
            "resetting env. episode 1859.000000, reward total was -21.000000. running mean: -20.502702\n",
            "resetting env. episode 1860.000000, reward total was -21.000000. running mean: -20.507675\n",
            "resetting env. episode 1861.000000, reward total was -21.000000. running mean: -20.512598\n",
            "resetting env. episode 1862.000000, reward total was -21.000000. running mean: -20.517473\n",
            "resetting env. episode 1863.000000, reward total was -21.000000. running mean: -20.522298\n",
            "resetting env. episode 1864.000000, reward total was -21.000000. running mean: -20.527075\n",
            "resetting env. episode 1865.000000, reward total was -21.000000. running mean: -20.531804\n",
            "resetting env. episode 1866.000000, reward total was -18.000000. running mean: -20.506486\n",
            "resetting env. episode 1867.000000, reward total was -21.000000. running mean: -20.511421\n",
            "resetting env. episode 1868.000000, reward total was -21.000000. running mean: -20.516307\n",
            "resetting env. episode 1869.000000, reward total was -20.000000. running mean: -20.511144\n",
            "resetting env. episode 1870.000000, reward total was -20.000000. running mean: -20.506032\n",
            "resetting env. episode 1871.000000, reward total was -21.000000. running mean: -20.510972\n",
            "resetting env. episode 1872.000000, reward total was -20.000000. running mean: -20.505862\n",
            "resetting env. episode 1873.000000, reward total was -20.000000. running mean: -20.500804\n",
            "resetting env. episode 1874.000000, reward total was -20.000000. running mean: -20.495796\n",
            "resetting env. episode 1875.000000, reward total was -20.000000. running mean: -20.490838\n",
            "resetting env. episode 1876.000000, reward total was -21.000000. running mean: -20.495929\n",
            "resetting env. episode 1877.000000, reward total was -21.000000. running mean: -20.500970\n",
            "resetting env. episode 1878.000000, reward total was -21.000000. running mean: -20.505960\n",
            "resetting env. episode 1879.000000, reward total was -21.000000. running mean: -20.510901\n",
            "resetting env. episode 1880.000000, reward total was -21.000000. running mean: -20.515792\n",
            "resetting env. episode 1881.000000, reward total was -21.000000. running mean: -20.520634\n",
            "resetting env. episode 1882.000000, reward total was -21.000000. running mean: -20.525428\n",
            "resetting env. episode 1883.000000, reward total was -20.000000. running mean: -20.520173\n",
            "resetting env. episode 1884.000000, reward total was -21.000000. running mean: -20.524972\n",
            "resetting env. episode 1885.000000, reward total was -21.000000. running mean: -20.529722\n",
            "resetting env. episode 1886.000000, reward total was -20.000000. running mean: -20.524425\n",
            "resetting env. episode 1887.000000, reward total was -21.000000. running mean: -20.529180\n",
            "resetting env. episode 1888.000000, reward total was -21.000000. running mean: -20.533889\n",
            "resetting env. episode 1889.000000, reward total was -21.000000. running mean: -20.538550\n",
            "resetting env. episode 1890.000000, reward total was -21.000000. running mean: -20.543164\n",
            "resetting env. episode 1891.000000, reward total was -20.000000. running mean: -20.537733\n",
            "resetting env. episode 1892.000000, reward total was -21.000000. running mean: -20.542355\n",
            "resetting env. episode 1893.000000, reward total was -20.000000. running mean: -20.536932\n",
            "resetting env. episode 1894.000000, reward total was -20.000000. running mean: -20.531562\n",
            "resetting env. episode 1895.000000, reward total was -21.000000. running mean: -20.536247\n",
            "resetting env. episode 1896.000000, reward total was -20.000000. running mean: -20.530884\n",
            "resetting env. episode 1897.000000, reward total was -20.000000. running mean: -20.525575\n",
            "resetting env. episode 1898.000000, reward total was -20.000000. running mean: -20.520320\n",
            "resetting env. episode 1899.000000, reward total was -21.000000. running mean: -20.525116\n",
            "resetting env. episode 1900.000000, reward total was -20.000000. running mean: -20.519865\n",
            "resetting env. episode 1901.000000, reward total was -20.000000. running mean: -20.514667\n",
            "resetting env. episode 1902.000000, reward total was -21.000000. running mean: -20.519520\n",
            "resetting env. episode 1903.000000, reward total was -21.000000. running mean: -20.524325\n",
            "resetting env. episode 1904.000000, reward total was -20.000000. running mean: -20.519082\n",
            "resetting env. episode 1905.000000, reward total was -19.000000. running mean: -20.503891\n",
            "resetting env. episode 1906.000000, reward total was -20.000000. running mean: -20.498852\n",
            "resetting env. episode 1907.000000, reward total was -21.000000. running mean: -20.503863\n",
            "resetting env. episode 1908.000000, reward total was -21.000000. running mean: -20.508825\n",
            "resetting env. episode 1909.000000, reward total was -20.000000. running mean: -20.503736\n",
            "resetting env. episode 1910.000000, reward total was -20.000000. running mean: -20.498699\n",
            "resetting env. episode 1911.000000, reward total was -21.000000. running mean: -20.503712\n",
            "resetting env. episode 1912.000000, reward total was -21.000000. running mean: -20.508675\n",
            "resetting env. episode 1913.000000, reward total was -21.000000. running mean: -20.513588\n",
            "resetting env. episode 1914.000000, reward total was -21.000000. running mean: -20.518452\n",
            "resetting env. episode 1915.000000, reward total was -21.000000. running mean: -20.523268\n",
            "resetting env. episode 1916.000000, reward total was -20.000000. running mean: -20.518035\n",
            "resetting env. episode 1917.000000, reward total was -21.000000. running mean: -20.522855\n",
            "resetting env. episode 1918.000000, reward total was -21.000000. running mean: -20.527626\n",
            "resetting env. episode 1919.000000, reward total was -21.000000. running mean: -20.532350\n",
            "resetting env. episode 1920.000000, reward total was -21.000000. running mean: -20.537026\n",
            "resetting env. episode 1921.000000, reward total was -19.000000. running mean: -20.521656\n",
            "resetting env. episode 1922.000000, reward total was -21.000000. running mean: -20.526440\n",
            "resetting env. episode 1923.000000, reward total was -20.000000. running mean: -20.521175\n",
            "resetting env. episode 1924.000000, reward total was -20.000000. running mean: -20.515963\n",
            "resetting env. episode 1925.000000, reward total was -19.000000. running mean: -20.500804\n",
            "resetting env. episode 1926.000000, reward total was -20.000000. running mean: -20.495796\n",
            "resetting env. episode 1927.000000, reward total was -21.000000. running mean: -20.500838\n",
            "resetting env. episode 1928.000000, reward total was -19.000000. running mean: -20.485829\n",
            "resetting env. episode 1929.000000, reward total was -18.000000. running mean: -20.460971\n",
            "resetting env. episode 1930.000000, reward total was -21.000000. running mean: -20.466361\n",
            "resetting env. episode 1931.000000, reward total was -21.000000. running mean: -20.471698\n",
            "resetting env. episode 1932.000000, reward total was -20.000000. running mean: -20.466981\n",
            "resetting env. episode 1933.000000, reward total was -21.000000. running mean: -20.472311\n",
            "resetting env. episode 1934.000000, reward total was -20.000000. running mean: -20.467588\n",
            "resetting env. episode 1935.000000, reward total was -20.000000. running mean: -20.462912\n",
            "resetting env. episode 1936.000000, reward total was -20.000000. running mean: -20.458283\n",
            "resetting env. episode 1937.000000, reward total was -21.000000. running mean: -20.463700\n",
            "resetting env. episode 1938.000000, reward total was -20.000000. running mean: -20.459063\n",
            "resetting env. episode 1939.000000, reward total was -21.000000. running mean: -20.464472\n",
            "resetting env. episode 1940.000000, reward total was -21.000000. running mean: -20.469828\n",
            "resetting env. episode 1941.000000, reward total was -21.000000. running mean: -20.475129\n",
            "resetting env. episode 1942.000000, reward total was -21.000000. running mean: -20.480378\n",
            "resetting env. episode 1943.000000, reward total was -21.000000. running mean: -20.485574\n",
            "resetting env. episode 1944.000000, reward total was -20.000000. running mean: -20.480719\n",
            "resetting env. episode 1945.000000, reward total was -21.000000. running mean: -20.485911\n",
            "resetting env. episode 1946.000000, reward total was -21.000000. running mean: -20.491052\n",
            "resetting env. episode 1947.000000, reward total was -20.000000. running mean: -20.486142\n",
            "resetting env. episode 1948.000000, reward total was -21.000000. running mean: -20.491280\n",
            "resetting env. episode 1949.000000, reward total was -21.000000. running mean: -20.496368\n",
            "resetting env. episode 1950.000000, reward total was -20.000000. running mean: -20.491404\n",
            "resetting env. episode 1951.000000, reward total was -21.000000. running mean: -20.496490\n",
            "resetting env. episode 1952.000000, reward total was -21.000000. running mean: -20.501525\n",
            "resetting env. episode 1953.000000, reward total was -21.000000. running mean: -20.506510\n",
            "resetting env. episode 1954.000000, reward total was -21.000000. running mean: -20.511445\n",
            "resetting env. episode 1955.000000, reward total was -21.000000. running mean: -20.516330\n",
            "resetting env. episode 1956.000000, reward total was -21.000000. running mean: -20.521167\n",
            "resetting env. episode 1957.000000, reward total was -21.000000. running mean: -20.525955\n",
            "resetting env. episode 1958.000000, reward total was -20.000000. running mean: -20.520696\n",
            "resetting env. episode 1959.000000, reward total was -20.000000. running mean: -20.515489\n",
            "resetting env. episode 1960.000000, reward total was -21.000000. running mean: -20.520334\n",
            "resetting env. episode 1961.000000, reward total was -21.000000. running mean: -20.525130\n",
            "resetting env. episode 1962.000000, reward total was -19.000000. running mean: -20.509879\n",
            "resetting env. episode 1963.000000, reward total was -19.000000. running mean: -20.494780\n",
            "resetting env. episode 1964.000000, reward total was -21.000000. running mean: -20.499833\n",
            "resetting env. episode 1965.000000, reward total was -18.000000. running mean: -20.474834\n",
            "resetting env. episode 1966.000000, reward total was -21.000000. running mean: -20.480086\n",
            "resetting env. episode 1967.000000, reward total was -21.000000. running mean: -20.485285\n",
            "resetting env. episode 1968.000000, reward total was -21.000000. running mean: -20.490432\n",
            "resetting env. episode 1969.000000, reward total was -19.000000. running mean: -20.475528\n",
            "resetting env. episode 1970.000000, reward total was -19.000000. running mean: -20.460773\n",
            "resetting env. episode 1971.000000, reward total was -21.000000. running mean: -20.466165\n",
            "resetting env. episode 1972.000000, reward total was -21.000000. running mean: -20.471503\n",
            "resetting env. episode 1973.000000, reward total was -20.000000. running mean: -20.466788\n",
            "resetting env. episode 1974.000000, reward total was -19.000000. running mean: -20.452120\n",
            "resetting env. episode 1975.000000, reward total was -20.000000. running mean: -20.447599\n",
            "resetting env. episode 1976.000000, reward total was -21.000000. running mean: -20.453123\n",
            "resetting env. episode 1977.000000, reward total was -20.000000. running mean: -20.448592\n",
            "resetting env. episode 1978.000000, reward total was -20.000000. running mean: -20.444106\n",
            "resetting env. episode 1979.000000, reward total was -21.000000. running mean: -20.449665\n",
            "resetting env. episode 1980.000000, reward total was -21.000000. running mean: -20.455168\n",
            "resetting env. episode 1981.000000, reward total was -21.000000. running mean: -20.460617\n",
            "resetting env. episode 1982.000000, reward total was -20.000000. running mean: -20.456010\n",
            "resetting env. episode 1983.000000, reward total was -19.000000. running mean: -20.441450\n",
            "resetting env. episode 1984.000000, reward total was -21.000000. running mean: -20.447036\n",
            "resetting env. episode 1985.000000, reward total was -21.000000. running mean: -20.452565\n",
            "resetting env. episode 1986.000000, reward total was -20.000000. running mean: -20.448040\n",
            "resetting env. episode 1987.000000, reward total was -21.000000. running mean: -20.453559\n",
            "resetting env. episode 1988.000000, reward total was -21.000000. running mean: -20.459024\n",
            "resetting env. episode 1989.000000, reward total was -21.000000. running mean: -20.464434\n",
            "resetting env. episode 1990.000000, reward total was -20.000000. running mean: -20.459789\n",
            "resetting env. episode 1991.000000, reward total was -21.000000. running mean: -20.465191\n",
            "resetting env. episode 1992.000000, reward total was -21.000000. running mean: -20.470539\n",
            "resetting env. episode 1993.000000, reward total was -18.000000. running mean: -20.445834\n",
            "resetting env. episode 1994.000000, reward total was -21.000000. running mean: -20.451376\n",
            "resetting env. episode 1995.000000, reward total was -21.000000. running mean: -20.456862\n",
            "resetting env. episode 1996.000000, reward total was -21.000000. running mean: -20.462293\n",
            "resetting env. episode 1997.000000, reward total was -21.000000. running mean: -20.467670\n",
            "resetting env. episode 1998.000000, reward total was -21.000000. running mean: -20.472994\n",
            "resetting env. episode 1999.000000, reward total was -19.000000. running mean: -20.458264\n",
            "resetting env. episode 2000.000000, reward total was -21.000000. running mean: -20.463681\n",
            "resetting env. episode 2001.000000, reward total was -20.000000. running mean: -20.459044\n",
            "resetting env. episode 2002.000000, reward total was -21.000000. running mean: -20.464454\n",
            "resetting env. episode 2003.000000, reward total was -18.000000. running mean: -20.439809\n",
            "resetting env. episode 2004.000000, reward total was -21.000000. running mean: -20.445411\n",
            "resetting env. episode 2005.000000, reward total was -21.000000. running mean: -20.450957\n",
            "resetting env. episode 2006.000000, reward total was -21.000000. running mean: -20.456448\n",
            "resetting env. episode 2007.000000, reward total was -19.000000. running mean: -20.441883\n",
            "resetting env. episode 2008.000000, reward total was -21.000000. running mean: -20.447464\n",
            "resetting env. episode 2009.000000, reward total was -21.000000. running mean: -20.452990\n",
            "resetting env. episode 2010.000000, reward total was -21.000000. running mean: -20.458460\n",
            "resetting env. episode 2011.000000, reward total was -20.000000. running mean: -20.453875\n",
            "resetting env. episode 2012.000000, reward total was -19.000000. running mean: -20.439336\n",
            "resetting env. episode 2013.000000, reward total was -21.000000. running mean: -20.444943\n",
            "resetting env. episode 2014.000000, reward total was -19.000000. running mean: -20.430494\n",
            "resetting env. episode 2015.000000, reward total was -21.000000. running mean: -20.436189\n",
            "resetting env. episode 2016.000000, reward total was -21.000000. running mean: -20.441827\n",
            "resetting env. episode 2017.000000, reward total was -21.000000. running mean: -20.447408\n",
            "resetting env. episode 2018.000000, reward total was -21.000000. running mean: -20.452934\n",
            "resetting env. episode 2019.000000, reward total was -20.000000. running mean: -20.448405\n",
            "resetting env. episode 2020.000000, reward total was -21.000000. running mean: -20.453921\n",
            "resetting env. episode 2021.000000, reward total was -20.000000. running mean: -20.449382\n",
            "resetting env. episode 2022.000000, reward total was -20.000000. running mean: -20.444888\n",
            "resetting env. episode 2023.000000, reward total was -21.000000. running mean: -20.450439\n",
            "resetting env. episode 2024.000000, reward total was -21.000000. running mean: -20.455935\n",
            "resetting env. episode 2025.000000, reward total was -20.000000. running mean: -20.451375\n",
            "resetting env. episode 2026.000000, reward total was -21.000000. running mean: -20.456862\n",
            "resetting env. episode 2027.000000, reward total was -21.000000. running mean: -20.462293\n",
            "resetting env. episode 2028.000000, reward total was -21.000000. running mean: -20.467670\n",
            "resetting env. episode 2029.000000, reward total was -21.000000. running mean: -20.472993\n",
            "resetting env. episode 2030.000000, reward total was -21.000000. running mean: -20.478263\n",
            "resetting env. episode 2031.000000, reward total was -20.000000. running mean: -20.473481\n",
            "resetting env. episode 2032.000000, reward total was -19.000000. running mean: -20.458746\n",
            "resetting env. episode 2033.000000, reward total was -21.000000. running mean: -20.464159\n",
            "resetting env. episode 2034.000000, reward total was -21.000000. running mean: -20.469517\n",
            "resetting env. episode 2035.000000, reward total was -21.000000. running mean: -20.474822\n",
            "resetting env. episode 2036.000000, reward total was -21.000000. running mean: -20.480074\n",
            "resetting env. episode 2037.000000, reward total was -21.000000. running mean: -20.485273\n",
            "resetting env. episode 2038.000000, reward total was -19.000000. running mean: -20.470420\n",
            "resetting env. episode 2039.000000, reward total was -19.000000. running mean: -20.455716\n",
            "resetting env. episode 2040.000000, reward total was -20.000000. running mean: -20.451159\n",
            "resetting env. episode 2041.000000, reward total was -21.000000. running mean: -20.456647\n",
            "resetting env. episode 2042.000000, reward total was -21.000000. running mean: -20.462081\n",
            "resetting env. episode 2043.000000, reward total was -21.000000. running mean: -20.467460\n",
            "resetting env. episode 2044.000000, reward total was -20.000000. running mean: -20.462785\n",
            "resetting env. episode 2045.000000, reward total was -19.000000. running mean: -20.448157\n",
            "resetting env. episode 2046.000000, reward total was -20.000000. running mean: -20.443676\n",
            "resetting env. episode 2047.000000, reward total was -21.000000. running mean: -20.449239\n",
            "resetting env. episode 2048.000000, reward total was -20.000000. running mean: -20.444747\n",
            "resetting env. episode 2049.000000, reward total was -21.000000. running mean: -20.450299\n",
            "resetting env. episode 2050.000000, reward total was -20.000000. running mean: -20.445796\n",
            "resetting env. episode 2051.000000, reward total was -21.000000. running mean: -20.451338\n",
            "resetting env. episode 2052.000000, reward total was -21.000000. running mean: -20.456825\n",
            "resetting env. episode 2053.000000, reward total was -20.000000. running mean: -20.452257\n",
            "resetting env. episode 2054.000000, reward total was -20.000000. running mean: -20.447734\n",
            "resetting env. episode 2055.000000, reward total was -21.000000. running mean: -20.453257\n",
            "resetting env. episode 2056.000000, reward total was -20.000000. running mean: -20.448724\n",
            "resetting env. episode 2057.000000, reward total was -21.000000. running mean: -20.454237\n",
            "resetting env. episode 2058.000000, reward total was -21.000000. running mean: -20.459695\n",
            "resetting env. episode 2059.000000, reward total was -21.000000. running mean: -20.465098\n",
            "resetting env. episode 2060.000000, reward total was -19.000000. running mean: -20.450447\n",
            "resetting env. episode 2061.000000, reward total was -20.000000. running mean: -20.445942\n",
            "resetting env. episode 2062.000000, reward total was -21.000000. running mean: -20.451483\n",
            "resetting env. episode 2063.000000, reward total was -20.000000. running mean: -20.446968\n",
            "resetting env. episode 2064.000000, reward total was -19.000000. running mean: -20.432498\n",
            "resetting env. episode 2065.000000, reward total was -20.000000. running mean: -20.428173\n",
            "resetting env. episode 2066.000000, reward total was -21.000000. running mean: -20.433892\n",
            "resetting env. episode 2067.000000, reward total was -21.000000. running mean: -20.439553\n",
            "resetting env. episode 2068.000000, reward total was -20.000000. running mean: -20.435157\n",
            "resetting env. episode 2069.000000, reward total was -21.000000. running mean: -20.440805\n",
            "resetting env. episode 2070.000000, reward total was -18.000000. running mean: -20.416397\n",
            "resetting env. episode 2071.000000, reward total was -21.000000. running mean: -20.422233\n",
            "resetting env. episode 2072.000000, reward total was -21.000000. running mean: -20.428011\n",
            "resetting env. episode 2073.000000, reward total was -21.000000. running mean: -20.433731\n",
            "resetting env. episode 2074.000000, reward total was -21.000000. running mean: -20.439394\n",
            "resetting env. episode 2075.000000, reward total was -21.000000. running mean: -20.445000\n",
            "resetting env. episode 2076.000000, reward total was -20.000000. running mean: -20.440550\n",
            "resetting env. episode 2077.000000, reward total was -21.000000. running mean: -20.446144\n",
            "resetting env. episode 2078.000000, reward total was -20.000000. running mean: -20.441683\n",
            "resetting env. episode 2079.000000, reward total was -20.000000. running mean: -20.437266\n",
            "resetting env. episode 2080.000000, reward total was -21.000000. running mean: -20.442893\n",
            "resetting env. episode 2081.000000, reward total was -21.000000. running mean: -20.448464\n",
            "resetting env. episode 2082.000000, reward total was -20.000000. running mean: -20.443980\n",
            "resetting env. episode 2083.000000, reward total was -21.000000. running mean: -20.449540\n",
            "resetting env. episode 2084.000000, reward total was -21.000000. running mean: -20.455045\n",
            "resetting env. episode 2085.000000, reward total was -21.000000. running mean: -20.460494\n",
            "resetting env. episode 2086.000000, reward total was -20.000000. running mean: -20.455889\n",
            "resetting env. episode 2087.000000, reward total was -21.000000. running mean: -20.461330\n",
            "resetting env. episode 2088.000000, reward total was -21.000000. running mean: -20.466717\n",
            "resetting env. episode 2089.000000, reward total was -20.000000. running mean: -20.462050\n",
            "resetting env. episode 2090.000000, reward total was -20.000000. running mean: -20.457429\n",
            "resetting env. episode 2091.000000, reward total was -21.000000. running mean: -20.462855\n",
            "resetting env. episode 2092.000000, reward total was -19.000000. running mean: -20.448226\n",
            "resetting env. episode 2093.000000, reward total was -21.000000. running mean: -20.453744\n",
            "resetting env. episode 2094.000000, reward total was -20.000000. running mean: -20.449207\n",
            "resetting env. episode 2095.000000, reward total was -21.000000. running mean: -20.454715\n",
            "resetting env. episode 2096.000000, reward total was -21.000000. running mean: -20.460168\n",
            "resetting env. episode 2097.000000, reward total was -19.000000. running mean: -20.445566\n",
            "resetting env. episode 2098.000000, reward total was -21.000000. running mean: -20.451110\n",
            "resetting env. episode 2099.000000, reward total was -21.000000. running mean: -20.456599\n",
            "resetting env. episode 2100.000000, reward total was -21.000000. running mean: -20.462033\n",
            "resetting env. episode 2101.000000, reward total was -21.000000. running mean: -20.467413\n",
            "resetting env. episode 2102.000000, reward total was -18.000000. running mean: -20.442739\n",
            "resetting env. episode 2103.000000, reward total was -20.000000. running mean: -20.438311\n",
            "resetting env. episode 2104.000000, reward total was -18.000000. running mean: -20.413928\n",
            "resetting env. episode 2105.000000, reward total was -21.000000. running mean: -20.419789\n",
            "resetting env. episode 2106.000000, reward total was -18.000000. running mean: -20.395591\n",
            "resetting env. episode 2107.000000, reward total was -21.000000. running mean: -20.401635\n",
            "resetting env. episode 2108.000000, reward total was -21.000000. running mean: -20.407619\n",
            "resetting env. episode 2109.000000, reward total was -21.000000. running mean: -20.413543\n",
            "resetting env. episode 2110.000000, reward total was -21.000000. running mean: -20.419407\n",
            "resetting env. episode 2111.000000, reward total was -21.000000. running mean: -20.425213\n",
            "resetting env. episode 2112.000000, reward total was -19.000000. running mean: -20.410961\n",
            "resetting env. episode 2113.000000, reward total was -21.000000. running mean: -20.416851\n",
            "resetting env. episode 2114.000000, reward total was -20.000000. running mean: -20.412683\n",
            "resetting env. episode 2115.000000, reward total was -20.000000. running mean: -20.408556\n",
            "resetting env. episode 2116.000000, reward total was -21.000000. running mean: -20.414470\n",
            "resetting env. episode 2117.000000, reward total was -21.000000. running mean: -20.420326\n",
            "resetting env. episode 2118.000000, reward total was -21.000000. running mean: -20.426122\n",
            "resetting env. episode 2119.000000, reward total was -21.000000. running mean: -20.431861\n",
            "resetting env. episode 2120.000000, reward total was -21.000000. running mean: -20.437543\n",
            "resetting env. episode 2121.000000, reward total was -21.000000. running mean: -20.443167\n",
            "resetting env. episode 2122.000000, reward total was -21.000000. running mean: -20.448736\n",
            "resetting env. episode 2123.000000, reward total was -20.000000. running mean: -20.444248\n",
            "resetting env. episode 2124.000000, reward total was -21.000000. running mean: -20.449806\n",
            "resetting env. episode 2125.000000, reward total was -20.000000. running mean: -20.445308\n",
            "resetting env. episode 2126.000000, reward total was -21.000000. running mean: -20.450855\n",
            "resetting env. episode 2127.000000, reward total was -20.000000. running mean: -20.446346\n",
            "resetting env. episode 2128.000000, reward total was -21.000000. running mean: -20.451883\n",
            "resetting env. episode 2129.000000, reward total was -20.000000. running mean: -20.447364\n",
            "resetting env. episode 2130.000000, reward total was -21.000000. running mean: -20.452890\n",
            "resetting env. episode 2131.000000, reward total was -20.000000. running mean: -20.448361\n",
            "resetting env. episode 2132.000000, reward total was -20.000000. running mean: -20.443878\n",
            "resetting env. episode 2133.000000, reward total was -21.000000. running mean: -20.449439\n",
            "resetting env. episode 2134.000000, reward total was -21.000000. running mean: -20.454944\n",
            "resetting env. episode 2135.000000, reward total was -21.000000. running mean: -20.460395\n",
            "resetting env. episode 2136.000000, reward total was -19.000000. running mean: -20.445791\n",
            "resetting env. episode 2137.000000, reward total was -21.000000. running mean: -20.451333\n",
            "resetting env. episode 2138.000000, reward total was -21.000000. running mean: -20.456820\n",
            "resetting env. episode 2139.000000, reward total was -21.000000. running mean: -20.462252\n",
            "resetting env. episode 2140.000000, reward total was -21.000000. running mean: -20.467629\n",
            "resetting env. episode 2141.000000, reward total was -21.000000. running mean: -20.472953\n",
            "resetting env. episode 2142.000000, reward total was -21.000000. running mean: -20.478223\n",
            "resetting env. episode 2143.000000, reward total was -21.000000. running mean: -20.483441\n",
            "resetting env. episode 2144.000000, reward total was -20.000000. running mean: -20.478607\n",
            "resetting env. episode 2145.000000, reward total was -20.000000. running mean: -20.473821\n",
            "resetting env. episode 2146.000000, reward total was -20.000000. running mean: -20.469082\n",
            "resetting env. episode 2147.000000, reward total was -20.000000. running mean: -20.464391\n",
            "resetting env. episode 2148.000000, reward total was -21.000000. running mean: -20.469748\n",
            "resetting env. episode 2149.000000, reward total was -21.000000. running mean: -20.475050\n",
            "resetting env. episode 2150.000000, reward total was -18.000000. running mean: -20.450300\n",
            "resetting env. episode 2151.000000, reward total was -21.000000. running mean: -20.455797\n",
            "resetting env. episode 2152.000000, reward total was -21.000000. running mean: -20.461239\n",
            "resetting env. episode 2153.000000, reward total was -21.000000. running mean: -20.466626\n",
            "resetting env. episode 2154.000000, reward total was -21.000000. running mean: -20.471960\n",
            "resetting env. episode 2155.000000, reward total was -21.000000. running mean: -20.477240\n",
            "resetting env. episode 2156.000000, reward total was -21.000000. running mean: -20.482468\n",
            "resetting env. episode 2157.000000, reward total was -20.000000. running mean: -20.477643\n",
            "resetting env. episode 2158.000000, reward total was -20.000000. running mean: -20.472867\n",
            "resetting env. episode 2159.000000, reward total was -21.000000. running mean: -20.478138\n",
            "resetting env. episode 2160.000000, reward total was -20.000000. running mean: -20.473357\n",
            "resetting env. episode 2161.000000, reward total was -21.000000. running mean: -20.478623\n",
            "resetting env. episode 2162.000000, reward total was -20.000000. running mean: -20.473837\n",
            "resetting env. episode 2163.000000, reward total was -20.000000. running mean: -20.469099\n",
            "resetting env. episode 2164.000000, reward total was -20.000000. running mean: -20.464408\n",
            "resetting env. episode 2165.000000, reward total was -20.000000. running mean: -20.459764\n",
            "resetting env. episode 2166.000000, reward total was -20.000000. running mean: -20.455166\n",
            "resetting env. episode 2167.000000, reward total was -21.000000. running mean: -20.460614\n",
            "resetting env. episode 2168.000000, reward total was -21.000000. running mean: -20.466008\n",
            "resetting env. episode 2169.000000, reward total was -20.000000. running mean: -20.461348\n",
            "resetting env. episode 2170.000000, reward total was -21.000000. running mean: -20.466735\n",
            "resetting env. episode 2171.000000, reward total was -21.000000. running mean: -20.472067\n",
            "resetting env. episode 2172.000000, reward total was -21.000000. running mean: -20.477347\n",
            "resetting env. episode 2173.000000, reward total was -21.000000. running mean: -20.482573\n",
            "resetting env. episode 2174.000000, reward total was -21.000000. running mean: -20.487747\n",
            "resetting env. episode 2175.000000, reward total was -21.000000. running mean: -20.492870\n",
            "resetting env. episode 2176.000000, reward total was -21.000000. running mean: -20.497941\n",
            "resetting env. episode 2177.000000, reward total was -21.000000. running mean: -20.502962\n",
            "resetting env. episode 2178.000000, reward total was -21.000000. running mean: -20.507932\n",
            "resetting env. episode 2179.000000, reward total was -21.000000. running mean: -20.512853\n",
            "resetting env. episode 2180.000000, reward total was -21.000000. running mean: -20.517724\n",
            "resetting env. episode 2181.000000, reward total was -21.000000. running mean: -20.522547\n",
            "resetting env. episode 2182.000000, reward total was -20.000000. running mean: -20.517322\n",
            "resetting env. episode 2183.000000, reward total was -20.000000. running mean: -20.512148\n",
            "resetting env. episode 2184.000000, reward total was -20.000000. running mean: -20.507027\n",
            "resetting env. episode 2185.000000, reward total was -21.000000. running mean: -20.511957\n",
            "resetting env. episode 2186.000000, reward total was -21.000000. running mean: -20.516837\n",
            "resetting env. episode 2187.000000, reward total was -20.000000. running mean: -20.511669\n",
            "resetting env. episode 2188.000000, reward total was -21.000000. running mean: -20.516552\n",
            "resetting env. episode 2189.000000, reward total was -21.000000. running mean: -20.521386\n",
            "resetting env. episode 2190.000000, reward total was -21.000000. running mean: -20.526173\n",
            "resetting env. episode 2191.000000, reward total was -20.000000. running mean: -20.520911\n",
            "resetting env. episode 2192.000000, reward total was -21.000000. running mean: -20.525702\n",
            "resetting env. episode 2193.000000, reward total was -21.000000. running mean: -20.530445\n",
            "resetting env. episode 2194.000000, reward total was -18.000000. running mean: -20.505140\n",
            "resetting env. episode 2195.000000, reward total was -19.000000. running mean: -20.490089\n",
            "resetting env. episode 2196.000000, reward total was -20.000000. running mean: -20.485188\n",
            "resetting env. episode 2197.000000, reward total was -21.000000. running mean: -20.490336\n",
            "resetting env. episode 2198.000000, reward total was -19.000000. running mean: -20.475433\n",
            "resetting env. episode 2199.000000, reward total was -21.000000. running mean: -20.480678\n",
            "resetting env. episode 2200.000000, reward total was -21.000000. running mean: -20.485872\n",
            "resetting env. episode 2201.000000, reward total was -21.000000. running mean: -20.491013\n",
            "resetting env. episode 2202.000000, reward total was -21.000000. running mean: -20.496103\n",
            "resetting env. episode 2203.000000, reward total was -20.000000. running mean: -20.491142\n",
            "resetting env. episode 2204.000000, reward total was -21.000000. running mean: -20.496230\n",
            "resetting env. episode 2205.000000, reward total was -20.000000. running mean: -20.491268\n",
            "resetting env. episode 2206.000000, reward total was -21.000000. running mean: -20.496355\n",
            "resetting env. episode 2207.000000, reward total was -20.000000. running mean: -20.491392\n",
            "resetting env. episode 2208.000000, reward total was -21.000000. running mean: -20.496478\n",
            "resetting env. episode 2209.000000, reward total was -21.000000. running mean: -20.501513\n",
            "resetting env. episode 2210.000000, reward total was -21.000000. running mean: -20.506498\n",
            "resetting env. episode 2211.000000, reward total was -21.000000. running mean: -20.511433\n",
            "resetting env. episode 2212.000000, reward total was -21.000000. running mean: -20.516319\n",
            "resetting env. episode 2213.000000, reward total was -20.000000. running mean: -20.511156\n",
            "resetting env. episode 2214.000000, reward total was -21.000000. running mean: -20.516044\n",
            "resetting env. episode 2215.000000, reward total was -21.000000. running mean: -20.520884\n",
            "resetting env. episode 2216.000000, reward total was -21.000000. running mean: -20.525675\n",
            "resetting env. episode 2217.000000, reward total was -20.000000. running mean: -20.520418\n",
            "resetting env. episode 2218.000000, reward total was -21.000000. running mean: -20.525214\n",
            "resetting env. episode 2219.000000, reward total was -21.000000. running mean: -20.529962\n",
            "resetting env. episode 2220.000000, reward total was -21.000000. running mean: -20.534662\n",
            "resetting env. episode 2221.000000, reward total was -19.000000. running mean: -20.519315\n",
            "resetting env. episode 2222.000000, reward total was -19.000000. running mean: -20.504122\n",
            "resetting env. episode 2223.000000, reward total was -21.000000. running mean: -20.509081\n",
            "resetting env. episode 2224.000000, reward total was -20.000000. running mean: -20.503990\n",
            "resetting env. episode 2225.000000, reward total was -21.000000. running mean: -20.508950\n",
            "resetting env. episode 2226.000000, reward total was -21.000000. running mean: -20.513861\n",
            "resetting env. episode 2227.000000, reward total was -18.000000. running mean: -20.488722\n",
            "resetting env. episode 2228.000000, reward total was -21.000000. running mean: -20.493835\n",
            "resetting env. episode 2229.000000, reward total was -21.000000. running mean: -20.498897\n",
            "resetting env. episode 2230.000000, reward total was -21.000000. running mean: -20.503908\n",
            "resetting env. episode 2231.000000, reward total was -20.000000. running mean: -20.498869\n",
            "resetting env. episode 2232.000000, reward total was -21.000000. running mean: -20.503880\n",
            "resetting env. episode 2233.000000, reward total was -20.000000. running mean: -20.498841\n",
            "resetting env. episode 2234.000000, reward total was -21.000000. running mean: -20.503853\n",
            "resetting env. episode 2235.000000, reward total was -21.000000. running mean: -20.508814\n",
            "resetting env. episode 2236.000000, reward total was -21.000000. running mean: -20.513726\n",
            "resetting env. episode 2237.000000, reward total was -21.000000. running mean: -20.518589\n",
            "resetting env. episode 2238.000000, reward total was -21.000000. running mean: -20.523403\n",
            "resetting env. episode 2239.000000, reward total was -18.000000. running mean: -20.498169\n",
            "resetting env. episode 2240.000000, reward total was -19.000000. running mean: -20.483187\n",
            "resetting env. episode 2241.000000, reward total was -20.000000. running mean: -20.478355\n",
            "resetting env. episode 2242.000000, reward total was -21.000000. running mean: -20.483572\n",
            "resetting env. episode 2243.000000, reward total was -20.000000. running mean: -20.478736\n",
            "resetting env. episode 2244.000000, reward total was -21.000000. running mean: -20.483949\n",
            "resetting env. episode 2245.000000, reward total was -19.000000. running mean: -20.469109\n",
            "resetting env. episode 2246.000000, reward total was -21.000000. running mean: -20.474418\n",
            "resetting env. episode 2247.000000, reward total was -21.000000. running mean: -20.479674\n",
            "resetting env. episode 2248.000000, reward total was -21.000000. running mean: -20.484877\n",
            "resetting env. episode 2249.000000, reward total was -21.000000. running mean: -20.490028\n",
            "resetting env. episode 2250.000000, reward total was -21.000000. running mean: -20.495128\n",
            "resetting env. episode 2251.000000, reward total was -21.000000. running mean: -20.500177\n",
            "resetting env. episode 2252.000000, reward total was -21.000000. running mean: -20.505175\n",
            "resetting env. episode 2253.000000, reward total was -21.000000. running mean: -20.510123\n",
            "resetting env. episode 2254.000000, reward total was -21.000000. running mean: -20.515022\n",
            "resetting env. episode 2255.000000, reward total was -20.000000. running mean: -20.509872\n",
            "resetting env. episode 2256.000000, reward total was -21.000000. running mean: -20.514773\n",
            "resetting env. episode 2257.000000, reward total was -21.000000. running mean: -20.519625\n",
            "resetting env. episode 2258.000000, reward total was -21.000000. running mean: -20.524429\n",
            "resetting env. episode 2259.000000, reward total was -20.000000. running mean: -20.519185\n",
            "resetting env. episode 2260.000000, reward total was -21.000000. running mean: -20.523993\n",
            "resetting env. episode 2261.000000, reward total was -21.000000. running mean: -20.528753\n",
            "resetting env. episode 2262.000000, reward total was -20.000000. running mean: -20.523466\n",
            "resetting env. episode 2263.000000, reward total was -21.000000. running mean: -20.528231\n",
            "resetting env. episode 2264.000000, reward total was -20.000000. running mean: -20.522949\n",
            "resetting env. episode 2265.000000, reward total was -20.000000. running mean: -20.517719\n",
            "resetting env. episode 2266.000000, reward total was -21.000000. running mean: -20.522542\n",
            "resetting env. episode 2267.000000, reward total was -21.000000. running mean: -20.527316\n",
            "resetting env. episode 2268.000000, reward total was -21.000000. running mean: -20.532043\n",
            "resetting env. episode 2269.000000, reward total was -18.000000. running mean: -20.506723\n",
            "resetting env. episode 2270.000000, reward total was -20.000000. running mean: -20.501656\n",
            "resetting env. episode 2271.000000, reward total was -18.000000. running mean: -20.476639\n",
            "resetting env. episode 2272.000000, reward total was -21.000000. running mean: -20.481873\n",
            "resetting env. episode 2273.000000, reward total was -21.000000. running mean: -20.487054\n",
            "resetting env. episode 2274.000000, reward total was -21.000000. running mean: -20.492183\n",
            "resetting env. episode 2275.000000, reward total was -21.000000. running mean: -20.497262\n",
            "resetting env. episode 2276.000000, reward total was -21.000000. running mean: -20.502289\n",
            "resetting env. episode 2277.000000, reward total was -19.000000. running mean: -20.487266\n",
            "resetting env. episode 2278.000000, reward total was -21.000000. running mean: -20.492393\n",
            "resetting env. episode 2279.000000, reward total was -20.000000. running mean: -20.487470\n",
            "resetting env. episode 2280.000000, reward total was -21.000000. running mean: -20.492595\n",
            "resetting env. episode 2281.000000, reward total was -21.000000. running mean: -20.497669\n",
            "resetting env. episode 2282.000000, reward total was -20.000000. running mean: -20.492692\n",
            "resetting env. episode 2283.000000, reward total was -20.000000. running mean: -20.487765\n",
            "resetting env. episode 2284.000000, reward total was -20.000000. running mean: -20.482888\n",
            "resetting env. episode 2285.000000, reward total was -21.000000. running mean: -20.488059\n",
            "resetting env. episode 2286.000000, reward total was -19.000000. running mean: -20.473178\n",
            "resetting env. episode 2287.000000, reward total was -19.000000. running mean: -20.458446\n",
            "resetting env. episode 2288.000000, reward total was -20.000000. running mean: -20.453862\n",
            "resetting env. episode 2289.000000, reward total was -20.000000. running mean: -20.449323\n",
            "resetting env. episode 2290.000000, reward total was -21.000000. running mean: -20.454830\n",
            "resetting env. episode 2291.000000, reward total was -21.000000. running mean: -20.460282\n",
            "resetting env. episode 2292.000000, reward total was -21.000000. running mean: -20.465679\n",
            "resetting env. episode 2293.000000, reward total was -20.000000. running mean: -20.461022\n",
            "resetting env. episode 2294.000000, reward total was -21.000000. running mean: -20.466412\n",
            "resetting env. episode 2295.000000, reward total was -21.000000. running mean: -20.471748\n",
            "resetting env. episode 2296.000000, reward total was -21.000000. running mean: -20.477030\n",
            "resetting env. episode 2297.000000, reward total was -20.000000. running mean: -20.472260\n",
            "resetting env. episode 2298.000000, reward total was -21.000000. running mean: -20.477537\n",
            "resetting env. episode 2299.000000, reward total was -21.000000. running mean: -20.482762\n",
            "resetting env. episode 2300.000000, reward total was -21.000000. running mean: -20.487934\n",
            "resetting env. episode 2301.000000, reward total was -21.000000. running mean: -20.493055\n",
            "resetting env. episode 2302.000000, reward total was -21.000000. running mean: -20.498125\n",
            "resetting env. episode 2303.000000, reward total was -21.000000. running mean: -20.503143\n",
            "resetting env. episode 2304.000000, reward total was -21.000000. running mean: -20.508112\n",
            "resetting env. episode 2305.000000, reward total was -21.000000. running mean: -20.513031\n",
            "resetting env. episode 2306.000000, reward total was -21.000000. running mean: -20.517900\n",
            "resetting env. episode 2307.000000, reward total was -18.000000. running mean: -20.492721\n",
            "resetting env. episode 2308.000000, reward total was -21.000000. running mean: -20.497794\n",
            "resetting env. episode 2309.000000, reward total was -21.000000. running mean: -20.502816\n",
            "resetting env. episode 2310.000000, reward total was -19.000000. running mean: -20.487788\n",
            "resetting env. episode 2311.000000, reward total was -21.000000. running mean: -20.492910\n",
            "resetting env. episode 2312.000000, reward total was -20.000000. running mean: -20.487981\n",
            "resetting env. episode 2313.000000, reward total was -20.000000. running mean: -20.483101\n",
            "resetting env. episode 2314.000000, reward total was -19.000000. running mean: -20.468270\n",
            "resetting env. episode 2315.000000, reward total was -19.000000. running mean: -20.453588\n",
            "resetting env. episode 2316.000000, reward total was -20.000000. running mean: -20.449052\n",
            "resetting env. episode 2317.000000, reward total was -20.000000. running mean: -20.444561\n",
            "resetting env. episode 2318.000000, reward total was -21.000000. running mean: -20.450116\n",
            "resetting env. episode 2319.000000, reward total was -21.000000. running mean: -20.455614\n",
            "resetting env. episode 2320.000000, reward total was -21.000000. running mean: -20.461058\n",
            "resetting env. episode 2321.000000, reward total was -21.000000. running mean: -20.466448\n",
            "resetting env. episode 2322.000000, reward total was -21.000000. running mean: -20.471783\n",
            "resetting env. episode 2323.000000, reward total was -20.000000. running mean: -20.467065\n",
            "resetting env. episode 2324.000000, reward total was -21.000000. running mean: -20.472395\n",
            "resetting env. episode 2325.000000, reward total was -19.000000. running mean: -20.457671\n",
            "resetting env. episode 2326.000000, reward total was -21.000000. running mean: -20.463094\n",
            "resetting env. episode 2327.000000, reward total was -20.000000. running mean: -20.458463\n",
            "resetting env. episode 2328.000000, reward total was -18.000000. running mean: -20.433879\n",
            "resetting env. episode 2329.000000, reward total was -21.000000. running mean: -20.439540\n",
            "resetting env. episode 2330.000000, reward total was -21.000000. running mean: -20.445144\n",
            "resetting env. episode 2331.000000, reward total was -20.000000. running mean: -20.440693\n",
            "resetting env. episode 2332.000000, reward total was -21.000000. running mean: -20.446286\n",
            "resetting env. episode 2333.000000, reward total was -21.000000. running mean: -20.451823\n",
            "resetting env. episode 2334.000000, reward total was -20.000000. running mean: -20.447305\n",
            "resetting env. episode 2335.000000, reward total was -19.000000. running mean: -20.432832\n",
            "resetting env. episode 2336.000000, reward total was -21.000000. running mean: -20.438503\n",
            "resetting env. episode 2337.000000, reward total was -21.000000. running mean: -20.444118\n",
            "resetting env. episode 2338.000000, reward total was -19.000000. running mean: -20.429677\n",
            "resetting env. episode 2339.000000, reward total was -21.000000. running mean: -20.435381\n",
            "resetting env. episode 2340.000000, reward total was -21.000000. running mean: -20.441027\n",
            "resetting env. episode 2341.000000, reward total was -21.000000. running mean: -20.446616\n",
            "resetting env. episode 2342.000000, reward total was -21.000000. running mean: -20.452150\n",
            "resetting env. episode 2343.000000, reward total was -21.000000. running mean: -20.457629\n",
            "resetting env. episode 2344.000000, reward total was -21.000000. running mean: -20.463052\n",
            "resetting env. episode 2345.000000, reward total was -21.000000. running mean: -20.468422\n",
            "resetting env. episode 2346.000000, reward total was -21.000000. running mean: -20.473738\n",
            "resetting env. episode 2347.000000, reward total was -20.000000. running mean: -20.469000\n",
            "resetting env. episode 2348.000000, reward total was -19.000000. running mean: -20.454310\n",
            "resetting env. episode 2349.000000, reward total was -20.000000. running mean: -20.449767\n",
            "resetting env. episode 2350.000000, reward total was -20.000000. running mean: -20.445270\n",
            "resetting env. episode 2351.000000, reward total was -21.000000. running mean: -20.450817\n",
            "resetting env. episode 2352.000000, reward total was -21.000000. running mean: -20.456309\n",
            "resetting env. episode 2353.000000, reward total was -21.000000. running mean: -20.461746\n",
            "resetting env. episode 2354.000000, reward total was -21.000000. running mean: -20.467128\n",
            "resetting env. episode 2355.000000, reward total was -21.000000. running mean: -20.472457\n",
            "resetting env. episode 2356.000000, reward total was -21.000000. running mean: -20.477732\n",
            "resetting env. episode 2357.000000, reward total was -21.000000. running mean: -20.482955\n",
            "resetting env. episode 2358.000000, reward total was -21.000000. running mean: -20.488125\n",
            "resetting env. episode 2359.000000, reward total was -21.000000. running mean: -20.493244\n",
            "resetting env. episode 2360.000000, reward total was -21.000000. running mean: -20.498312\n",
            "resetting env. episode 2361.000000, reward total was -19.000000. running mean: -20.483329\n",
            "resetting env. episode 2362.000000, reward total was -21.000000. running mean: -20.488495\n",
            "resetting env. episode 2363.000000, reward total was -20.000000. running mean: -20.483610\n",
            "resetting env. episode 2364.000000, reward total was -19.000000. running mean: -20.468774\n",
            "resetting env. episode 2365.000000, reward total was -21.000000. running mean: -20.474087\n",
            "resetting env. episode 2366.000000, reward total was -21.000000. running mean: -20.479346\n",
            "resetting env. episode 2367.000000, reward total was -19.000000. running mean: -20.464552\n",
            "resetting env. episode 2368.000000, reward total was -19.000000. running mean: -20.449907\n",
            "resetting env. episode 2369.000000, reward total was -21.000000. running mean: -20.455408\n",
            "resetting env. episode 2370.000000, reward total was -21.000000. running mean: -20.460854\n",
            "resetting env. episode 2371.000000, reward total was -21.000000. running mean: -20.466245\n",
            "resetting env. episode 2372.000000, reward total was -19.000000. running mean: -20.451583\n",
            "resetting env. episode 2373.000000, reward total was -19.000000. running mean: -20.437067\n",
            "resetting env. episode 2374.000000, reward total was -20.000000. running mean: -20.432696\n",
            "resetting env. episode 2375.000000, reward total was -19.000000. running mean: -20.418369\n",
            "resetting env. episode 2376.000000, reward total was -21.000000. running mean: -20.424185\n",
            "resetting env. episode 2377.000000, reward total was -19.000000. running mean: -20.409944\n",
            "resetting env. episode 2378.000000, reward total was -21.000000. running mean: -20.415844\n",
            "resetting env. episode 2379.000000, reward total was -21.000000. running mean: -20.421686\n",
            "resetting env. episode 2380.000000, reward total was -21.000000. running mean: -20.427469\n",
            "resetting env. episode 2381.000000, reward total was -21.000000. running mean: -20.433194\n",
            "resetting env. episode 2382.000000, reward total was -21.000000. running mean: -20.438862\n",
            "resetting env. episode 2383.000000, reward total was -18.000000. running mean: -20.414474\n",
            "resetting env. episode 2384.000000, reward total was -20.000000. running mean: -20.410329\n",
            "resetting env. episode 2385.000000, reward total was -20.000000. running mean: -20.406226\n",
            "resetting env. episode 2386.000000, reward total was -21.000000. running mean: -20.412163\n",
            "resetting env. episode 2387.000000, reward total was -19.000000. running mean: -20.398042\n",
            "resetting env. episode 2388.000000, reward total was -21.000000. running mean: -20.404061\n",
            "resetting env. episode 2389.000000, reward total was -19.000000. running mean: -20.390021\n",
            "resetting env. episode 2390.000000, reward total was -21.000000. running mean: -20.396120\n",
            "resetting env. episode 2391.000000, reward total was -21.000000. running mean: -20.402159\n",
            "resetting env. episode 2392.000000, reward total was -20.000000. running mean: -20.398138\n",
            "resetting env. episode 2393.000000, reward total was -21.000000. running mean: -20.404156\n",
            "resetting env. episode 2394.000000, reward total was -20.000000. running mean: -20.400115\n",
            "resetting env. episode 2395.000000, reward total was -21.000000. running mean: -20.406114\n",
            "resetting env. episode 2396.000000, reward total was -21.000000. running mean: -20.412052\n",
            "resetting env. episode 2397.000000, reward total was -21.000000. running mean: -20.417932\n",
            "resetting env. episode 2398.000000, reward total was -21.000000. running mean: -20.423753\n",
            "resetting env. episode 2399.000000, reward total was -20.000000. running mean: -20.419515\n",
            "resetting env. episode 2400.000000, reward total was -20.000000. running mean: -20.415320\n",
            "resetting env. episode 2401.000000, reward total was -21.000000. running mean: -20.421167\n",
            "resetting env. episode 2402.000000, reward total was -21.000000. running mean: -20.426955\n",
            "resetting env. episode 2403.000000, reward total was -21.000000. running mean: -20.432685\n",
            "resetting env. episode 2404.000000, reward total was -21.000000. running mean: -20.438359\n",
            "resetting env. episode 2405.000000, reward total was -21.000000. running mean: -20.443975\n",
            "resetting env. episode 2406.000000, reward total was -21.000000. running mean: -20.449535\n",
            "resetting env. episode 2407.000000, reward total was -20.000000. running mean: -20.445040\n",
            "resetting env. episode 2408.000000, reward total was -21.000000. running mean: -20.450590\n",
            "resetting env. episode 2409.000000, reward total was -18.000000. running mean: -20.426084\n",
            "resetting env. episode 2410.000000, reward total was -21.000000. running mean: -20.431823\n",
            "resetting env. episode 2411.000000, reward total was -18.000000. running mean: -20.407505\n",
            "resetting env. episode 2412.000000, reward total was -21.000000. running mean: -20.413430\n",
            "resetting env. episode 2413.000000, reward total was -20.000000. running mean: -20.409295\n",
            "resetting env. episode 2414.000000, reward total was -21.000000. running mean: -20.415202\n",
            "resetting env. episode 2415.000000, reward total was -20.000000. running mean: -20.411050\n",
            "resetting env. episode 2416.000000, reward total was -20.000000. running mean: -20.406940\n",
            "resetting env. episode 2417.000000, reward total was -21.000000. running mean: -20.412870\n",
            "resetting env. episode 2418.000000, reward total was -19.000000. running mean: -20.398742\n",
            "resetting env. episode 2419.000000, reward total was -20.000000. running mean: -20.394754\n",
            "resetting env. episode 2420.000000, reward total was -21.000000. running mean: -20.400807\n",
            "resetting env. episode 2421.000000, reward total was -21.000000. running mean: -20.406799\n",
            "resetting env. episode 2422.000000, reward total was -20.000000. running mean: -20.402731\n",
            "resetting env. episode 2423.000000, reward total was -18.000000. running mean: -20.378703\n",
            "resetting env. episode 2424.000000, reward total was -21.000000. running mean: -20.384916\n",
            "resetting env. episode 2425.000000, reward total was -21.000000. running mean: -20.391067\n",
            "resetting env. episode 2426.000000, reward total was -21.000000. running mean: -20.397156\n",
            "resetting env. episode 2427.000000, reward total was -21.000000. running mean: -20.403185\n",
            "resetting env. episode 2428.000000, reward total was -21.000000. running mean: -20.409153\n",
            "resetting env. episode 2429.000000, reward total was -21.000000. running mean: -20.415062\n",
            "resetting env. episode 2430.000000, reward total was -21.000000. running mean: -20.420911\n",
            "resetting env. episode 2431.000000, reward total was -20.000000. running mean: -20.416702\n",
            "resetting env. episode 2432.000000, reward total was -20.000000. running mean: -20.412535\n",
            "resetting env. episode 2433.000000, reward total was -21.000000. running mean: -20.418409\n",
            "resetting env. episode 2434.000000, reward total was -21.000000. running mean: -20.424225\n",
            "resetting env. episode 2435.000000, reward total was -21.000000. running mean: -20.429983\n",
            "resetting env. episode 2436.000000, reward total was -21.000000. running mean: -20.435683\n",
            "resetting env. episode 2437.000000, reward total was -21.000000. running mean: -20.441326\n",
            "resetting env. episode 2438.000000, reward total was -19.000000. running mean: -20.426913\n",
            "resetting env. episode 2439.000000, reward total was -21.000000. running mean: -20.432644\n",
            "resetting env. episode 2440.000000, reward total was -21.000000. running mean: -20.438318\n",
            "resetting env. episode 2441.000000, reward total was -20.000000. running mean: -20.433934\n",
            "resetting env. episode 2442.000000, reward total was -21.000000. running mean: -20.439595\n",
            "resetting env. episode 2443.000000, reward total was -21.000000. running mean: -20.445199\n",
            "resetting env. episode 2444.000000, reward total was -21.000000. running mean: -20.450747\n",
            "resetting env. episode 2445.000000, reward total was -21.000000. running mean: -20.456240\n",
            "resetting env. episode 2446.000000, reward total was -19.000000. running mean: -20.441677\n",
            "resetting env. episode 2447.000000, reward total was -20.000000. running mean: -20.437260\n",
            "resetting env. episode 2448.000000, reward total was -21.000000. running mean: -20.442888\n",
            "resetting env. episode 2449.000000, reward total was -20.000000. running mean: -20.438459\n",
            "resetting env. episode 2450.000000, reward total was -20.000000. running mean: -20.434074\n",
            "resetting env. episode 2451.000000, reward total was -21.000000. running mean: -20.439734\n",
            "resetting env. episode 2452.000000, reward total was -21.000000. running mean: -20.445336\n",
            "resetting env. episode 2453.000000, reward total was -20.000000. running mean: -20.440883\n",
            "resetting env. episode 2454.000000, reward total was -21.000000. running mean: -20.446474\n",
            "resetting env. episode 2455.000000, reward total was -20.000000. running mean: -20.442009\n",
            "resetting env. episode 2456.000000, reward total was -21.000000. running mean: -20.447589\n",
            "resetting env. episode 2457.000000, reward total was -21.000000. running mean: -20.453113\n",
            "resetting env. episode 2458.000000, reward total was -20.000000. running mean: -20.448582\n",
            "resetting env. episode 2459.000000, reward total was -18.000000. running mean: -20.424096\n",
            "resetting env. episode 2460.000000, reward total was -21.000000. running mean: -20.429855\n",
            "resetting env. episode 2461.000000, reward total was -20.000000. running mean: -20.425557\n",
            "resetting env. episode 2462.000000, reward total was -21.000000. running mean: -20.431301\n",
            "resetting env. episode 2463.000000, reward total was -21.000000. running mean: -20.436988\n",
            "resetting env. episode 2464.000000, reward total was -18.000000. running mean: -20.412618\n",
            "resetting env. episode 2465.000000, reward total was -21.000000. running mean: -20.418492\n",
            "resetting env. episode 2466.000000, reward total was -20.000000. running mean: -20.414307\n",
            "resetting env. episode 2467.000000, reward total was -21.000000. running mean: -20.420164\n",
            "resetting env. episode 2468.000000, reward total was -21.000000. running mean: -20.425963\n",
            "resetting env. episode 2469.000000, reward total was -21.000000. running mean: -20.431703\n",
            "resetting env. episode 2470.000000, reward total was -19.000000. running mean: -20.417386\n",
            "resetting env. episode 2471.000000, reward total was -21.000000. running mean: -20.423212\n",
            "resetting env. episode 2472.000000, reward total was -18.000000. running mean: -20.398980\n",
            "resetting env. episode 2473.000000, reward total was -21.000000. running mean: -20.404990\n",
            "resetting env. episode 2474.000000, reward total was -20.000000. running mean: -20.400940\n",
            "resetting env. episode 2475.000000, reward total was -21.000000. running mean: -20.406931\n",
            "resetting env. episode 2476.000000, reward total was -21.000000. running mean: -20.412862\n",
            "resetting env. episode 2477.000000, reward total was -16.000000. running mean: -20.368733\n",
            "resetting env. episode 2478.000000, reward total was -21.000000. running mean: -20.375046\n",
            "resetting env. episode 2479.000000, reward total was -21.000000. running mean: -20.381295\n",
            "resetting env. episode 2480.000000, reward total was -20.000000. running mean: -20.377482\n",
            "resetting env. episode 2481.000000, reward total was -20.000000. running mean: -20.373707\n",
            "resetting env. episode 2482.000000, reward total was -21.000000. running mean: -20.379970\n",
            "resetting env. episode 2483.000000, reward total was -21.000000. running mean: -20.386171\n",
            "resetting env. episode 2484.000000, reward total was -21.000000. running mean: -20.392309\n",
            "resetting env. episode 2485.000000, reward total was -21.000000. running mean: -20.398386\n",
            "resetting env. episode 2486.000000, reward total was -21.000000. running mean: -20.404402\n",
            "resetting env. episode 2487.000000, reward total was -21.000000. running mean: -20.410358\n",
            "resetting env. episode 2488.000000, reward total was -19.000000. running mean: -20.396254\n",
            "resetting env. episode 2489.000000, reward total was -17.000000. running mean: -20.362292\n",
            "resetting env. episode 2490.000000, reward total was -21.000000. running mean: -20.368669\n",
            "resetting env. episode 2491.000000, reward total was -21.000000. running mean: -20.374982\n",
            "resetting env. episode 2492.000000, reward total was -19.000000. running mean: -20.361232\n",
            "resetting env. episode 2493.000000, reward total was -21.000000. running mean: -20.367620\n",
            "resetting env. episode 2494.000000, reward total was -21.000000. running mean: -20.373944\n",
            "resetting env. episode 2495.000000, reward total was -21.000000. running mean: -20.380204\n",
            "resetting env. episode 2496.000000, reward total was -20.000000. running mean: -20.376402\n",
            "resetting env. episode 2497.000000, reward total was -19.000000. running mean: -20.362638\n",
            "resetting env. episode 2498.000000, reward total was -18.000000. running mean: -20.339012\n",
            "resetting env. episode 2499.000000, reward total was -19.000000. running mean: -20.325622\n",
            "resetting env. episode 2500.000000, reward total was -21.000000. running mean: -20.332366\n",
            "resetting env. episode 2501.000000, reward total was -21.000000. running mean: -20.339042\n",
            "resetting env. episode 2502.000000, reward total was -20.000000. running mean: -20.335652\n",
            "resetting env. episode 2503.000000, reward total was -20.000000. running mean: -20.332295\n",
            "resetting env. episode 2504.000000, reward total was -20.000000. running mean: -20.328972\n",
            "resetting env. episode 2505.000000, reward total was -21.000000. running mean: -20.335682\n",
            "resetting env. episode 2506.000000, reward total was -21.000000. running mean: -20.342326\n",
            "resetting env. episode 2507.000000, reward total was -19.000000. running mean: -20.328902\n",
            "resetting env. episode 2508.000000, reward total was -21.000000. running mean: -20.335613\n",
            "resetting env. episode 2509.000000, reward total was -21.000000. running mean: -20.342257\n",
            "resetting env. episode 2510.000000, reward total was -21.000000. running mean: -20.348835\n",
            "resetting env. episode 2511.000000, reward total was -21.000000. running mean: -20.355346\n",
            "resetting env. episode 2512.000000, reward total was -20.000000. running mean: -20.351793\n",
            "resetting env. episode 2513.000000, reward total was -19.000000. running mean: -20.338275\n",
            "resetting env. episode 2514.000000, reward total was -21.000000. running mean: -20.344892\n",
            "resetting env. episode 2515.000000, reward total was -21.000000. running mean: -20.351443\n",
            "resetting env. episode 2516.000000, reward total was -21.000000. running mean: -20.357929\n",
            "resetting env. episode 2517.000000, reward total was -21.000000. running mean: -20.364349\n",
            "resetting env. episode 2518.000000, reward total was -21.000000. running mean: -20.370706\n",
            "resetting env. episode 2519.000000, reward total was -19.000000. running mean: -20.356999\n",
            "resetting env. episode 2520.000000, reward total was -21.000000. running mean: -20.363429\n",
            "resetting env. episode 2521.000000, reward total was -21.000000. running mean: -20.369795\n",
            "resetting env. episode 2522.000000, reward total was -21.000000. running mean: -20.376097\n",
            "resetting env. episode 2523.000000, reward total was -21.000000. running mean: -20.382336\n",
            "resetting env. episode 2524.000000, reward total was -21.000000. running mean: -20.388512\n",
            "resetting env. episode 2525.000000, reward total was -21.000000. running mean: -20.394627\n",
            "resetting env. episode 2526.000000, reward total was -21.000000. running mean: -20.400681\n",
            "resetting env. episode 2527.000000, reward total was -21.000000. running mean: -20.406674\n",
            "resetting env. episode 2528.000000, reward total was -19.000000. running mean: -20.392607\n",
            "resetting env. episode 2529.000000, reward total was -20.000000. running mean: -20.388681\n",
            "resetting env. episode 2530.000000, reward total was -21.000000. running mean: -20.394795\n",
            "resetting env. episode 2531.000000, reward total was -21.000000. running mean: -20.400847\n",
            "resetting env. episode 2532.000000, reward total was -19.000000. running mean: -20.386838\n",
            "resetting env. episode 2533.000000, reward total was -21.000000. running mean: -20.392970\n",
            "resetting env. episode 2534.000000, reward total was -18.000000. running mean: -20.369040\n",
            "resetting env. episode 2535.000000, reward total was -20.000000. running mean: -20.365350\n",
            "resetting env. episode 2536.000000, reward total was -20.000000. running mean: -20.361696\n",
            "resetting env. episode 2537.000000, reward total was -21.000000. running mean: -20.368079\n",
            "resetting env. episode 2538.000000, reward total was -21.000000. running mean: -20.374398\n",
            "resetting env. episode 2539.000000, reward total was -21.000000. running mean: -20.380654\n",
            "resetting env. episode 2540.000000, reward total was -19.000000. running mean: -20.366848\n",
            "resetting env. episode 2541.000000, reward total was -20.000000. running mean: -20.363179\n",
            "resetting env. episode 2542.000000, reward total was -20.000000. running mean: -20.359548\n",
            "resetting env. episode 2543.000000, reward total was -19.000000. running mean: -20.345952\n",
            "resetting env. episode 2544.000000, reward total was -20.000000. running mean: -20.342493\n",
            "resetting env. episode 2545.000000, reward total was -21.000000. running mean: -20.349068\n",
            "resetting env. episode 2546.000000, reward total was -21.000000. running mean: -20.355577\n",
            "resetting env. episode 2547.000000, reward total was -21.000000. running mean: -20.362021\n",
            "resetting env. episode 2548.000000, reward total was -21.000000. running mean: -20.368401\n",
            "resetting env. episode 2549.000000, reward total was -21.000000. running mean: -20.374717\n",
            "resetting env. episode 2550.000000, reward total was -18.000000. running mean: -20.350970\n",
            "resetting env. episode 2551.000000, reward total was -21.000000. running mean: -20.357460\n",
            "resetting env. episode 2552.000000, reward total was -21.000000. running mean: -20.363886\n",
            "resetting env. episode 2553.000000, reward total was -21.000000. running mean: -20.370247\n",
            "resetting env. episode 2554.000000, reward total was -21.000000. running mean: -20.376544\n",
            "resetting env. episode 2555.000000, reward total was -20.000000. running mean: -20.372779\n",
            "resetting env. episode 2556.000000, reward total was -20.000000. running mean: -20.369051\n",
            "resetting env. episode 2557.000000, reward total was -21.000000. running mean: -20.375360\n",
            "resetting env. episode 2558.000000, reward total was -20.000000. running mean: -20.371607\n",
            "resetting env. episode 2559.000000, reward total was -21.000000. running mean: -20.377891\n",
            "resetting env. episode 2560.000000, reward total was -21.000000. running mean: -20.384112\n",
            "resetting env. episode 2561.000000, reward total was -20.000000. running mean: -20.380271\n",
            "resetting env. episode 2562.000000, reward total was -21.000000. running mean: -20.386468\n",
            "resetting env. episode 2563.000000, reward total was -21.000000. running mean: -20.392603\n",
            "resetting env. episode 2564.000000, reward total was -21.000000. running mean: -20.398677\n",
            "resetting env. episode 2565.000000, reward total was -21.000000. running mean: -20.404691\n",
            "resetting env. episode 2566.000000, reward total was -20.000000. running mean: -20.400644\n",
            "resetting env. episode 2567.000000, reward total was -21.000000. running mean: -20.406637\n",
            "resetting env. episode 2568.000000, reward total was -21.000000. running mean: -20.412571\n",
            "resetting env. episode 2569.000000, reward total was -19.000000. running mean: -20.398445\n",
            "resetting env. episode 2570.000000, reward total was -21.000000. running mean: -20.404461\n",
            "resetting env. episode 2571.000000, reward total was -19.000000. running mean: -20.390416\n",
            "resetting env. episode 2572.000000, reward total was -21.000000. running mean: -20.396512\n",
            "resetting env. episode 2573.000000, reward total was -21.000000. running mean: -20.402547\n",
            "resetting env. episode 2574.000000, reward total was -20.000000. running mean: -20.398521\n",
            "resetting env. episode 2575.000000, reward total was -21.000000. running mean: -20.404536\n",
            "resetting env. episode 2576.000000, reward total was -21.000000. running mean: -20.410491\n",
            "resetting env. episode 2577.000000, reward total was -20.000000. running mean: -20.406386\n",
            "resetting env. episode 2578.000000, reward total was -20.000000. running mean: -20.402322\n",
            "resetting env. episode 2579.000000, reward total was -20.000000. running mean: -20.398299\n",
            "resetting env. episode 2580.000000, reward total was -21.000000. running mean: -20.404316\n",
            "resetting env. episode 2581.000000, reward total was -21.000000. running mean: -20.410273\n",
            "resetting env. episode 2582.000000, reward total was -21.000000. running mean: -20.416170\n",
            "resetting env. episode 2583.000000, reward total was -20.000000. running mean: -20.412008\n",
            "resetting env. episode 2584.000000, reward total was -19.000000. running mean: -20.397888\n",
            "resetting env. episode 2585.000000, reward total was -18.000000. running mean: -20.373909\n",
            "resetting env. episode 2586.000000, reward total was -21.000000. running mean: -20.380170\n",
            "resetting env. episode 2587.000000, reward total was -21.000000. running mean: -20.386368\n",
            "resetting env. episode 2588.000000, reward total was -21.000000. running mean: -20.392505\n",
            "resetting env. episode 2589.000000, reward total was -21.000000. running mean: -20.398580\n",
            "resetting env. episode 2590.000000, reward total was -21.000000. running mean: -20.404594\n",
            "resetting env. episode 2591.000000, reward total was -21.000000. running mean: -20.410548\n",
            "resetting env. episode 2592.000000, reward total was -21.000000. running mean: -20.416442\n",
            "resetting env. episode 2593.000000, reward total was -21.000000. running mean: -20.422278\n",
            "resetting env. episode 2594.000000, reward total was -21.000000. running mean: -20.428055\n",
            "resetting env. episode 2595.000000, reward total was -21.000000. running mean: -20.433775\n",
            "resetting env. episode 2596.000000, reward total was -20.000000. running mean: -20.429437\n",
            "resetting env. episode 2597.000000, reward total was -20.000000. running mean: -20.425143\n",
            "resetting env. episode 2598.000000, reward total was -21.000000. running mean: -20.430891\n",
            "resetting env. episode 2599.000000, reward total was -21.000000. running mean: -20.436582\n",
            "resetting env. episode 2600.000000, reward total was -21.000000. running mean: -20.442216\n",
            "resetting env. episode 2601.000000, reward total was -21.000000. running mean: -20.447794\n",
            "resetting env. episode 2602.000000, reward total was -19.000000. running mean: -20.433316\n",
            "resetting env. episode 2603.000000, reward total was -20.000000. running mean: -20.428983\n",
            "resetting env. episode 2604.000000, reward total was -19.000000. running mean: -20.414693\n",
            "resetting env. episode 2605.000000, reward total was -21.000000. running mean: -20.420546\n",
            "resetting env. episode 2606.000000, reward total was -20.000000. running mean: -20.416341\n",
            "resetting env. episode 2607.000000, reward total was -20.000000. running mean: -20.412178\n",
            "resetting env. episode 2608.000000, reward total was -21.000000. running mean: -20.418056\n",
            "resetting env. episode 2609.000000, reward total was -21.000000. running mean: -20.423875\n",
            "resetting env. episode 2610.000000, reward total was -20.000000. running mean: -20.419636\n",
            "resetting env. episode 2611.000000, reward total was -21.000000. running mean: -20.425440\n",
            "resetting env. episode 2612.000000, reward total was -21.000000. running mean: -20.431186\n",
            "resetting env. episode 2613.000000, reward total was -20.000000. running mean: -20.426874\n",
            "resetting env. episode 2614.000000, reward total was -20.000000. running mean: -20.422605\n",
            "resetting env. episode 2615.000000, reward total was -21.000000. running mean: -20.428379\n",
            "resetting env. episode 2616.000000, reward total was -20.000000. running mean: -20.424095\n",
            "resetting env. episode 2617.000000, reward total was -20.000000. running mean: -20.419854\n",
            "resetting env. episode 2618.000000, reward total was -21.000000. running mean: -20.425656\n",
            "resetting env. episode 2619.000000, reward total was -19.000000. running mean: -20.411399\n",
            "resetting env. episode 2620.000000, reward total was -21.000000. running mean: -20.417285\n",
            "resetting env. episode 2621.000000, reward total was -21.000000. running mean: -20.423112\n",
            "resetting env. episode 2622.000000, reward total was -21.000000. running mean: -20.428881\n",
            "resetting env. episode 2623.000000, reward total was -21.000000. running mean: -20.434592\n",
            "resetting env. episode 2624.000000, reward total was -19.000000. running mean: -20.420247\n",
            "resetting env. episode 2625.000000, reward total was -19.000000. running mean: -20.406044\n",
            "resetting env. episode 2626.000000, reward total was -20.000000. running mean: -20.401984\n",
            "resetting env. episode 2627.000000, reward total was -21.000000. running mean: -20.407964\n",
            "resetting env. episode 2628.000000, reward total was -21.000000. running mean: -20.413884\n",
            "resetting env. episode 2629.000000, reward total was -21.000000. running mean: -20.419745\n",
            "resetting env. episode 2630.000000, reward total was -20.000000. running mean: -20.415548\n",
            "resetting env. episode 2631.000000, reward total was -20.000000. running mean: -20.411392\n",
            "resetting env. episode 2632.000000, reward total was -21.000000. running mean: -20.417278\n",
            "resetting env. episode 2633.000000, reward total was -20.000000. running mean: -20.413106\n",
            "resetting env. episode 2634.000000, reward total was -21.000000. running mean: -20.418975\n",
            "resetting env. episode 2635.000000, reward total was -21.000000. running mean: -20.424785\n",
            "resetting env. episode 2636.000000, reward total was -21.000000. running mean: -20.430537\n",
            "resetting env. episode 2637.000000, reward total was -21.000000. running mean: -20.436232\n",
            "resetting env. episode 2638.000000, reward total was -20.000000. running mean: -20.431869\n",
            "resetting env. episode 2639.000000, reward total was -21.000000. running mean: -20.437551\n",
            "resetting env. episode 2640.000000, reward total was -20.000000. running mean: -20.433175\n",
            "resetting env. episode 2641.000000, reward total was -21.000000. running mean: -20.438843\n",
            "resetting env. episode 2642.000000, reward total was -21.000000. running mean: -20.444455\n",
            "resetting env. episode 2643.000000, reward total was -21.000000. running mean: -20.450010\n",
            "resetting env. episode 2644.000000, reward total was -21.000000. running mean: -20.455510\n",
            "resetting env. episode 2645.000000, reward total was -21.000000. running mean: -20.460955\n",
            "resetting env. episode 2646.000000, reward total was -21.000000. running mean: -20.466346\n",
            "resetting env. episode 2647.000000, reward total was -20.000000. running mean: -20.461682\n",
            "resetting env. episode 2648.000000, reward total was -20.000000. running mean: -20.457065\n",
            "resetting env. episode 2649.000000, reward total was -21.000000. running mean: -20.462495\n",
            "resetting env. episode 2650.000000, reward total was -21.000000. running mean: -20.467870\n",
            "resetting env. episode 2651.000000, reward total was -21.000000. running mean: -20.473191\n",
            "resetting env. episode 2652.000000, reward total was -21.000000. running mean: -20.478459\n",
            "resetting env. episode 2653.000000, reward total was -19.000000. running mean: -20.463675\n",
            "resetting env. episode 2654.000000, reward total was -20.000000. running mean: -20.459038\n",
            "resetting env. episode 2655.000000, reward total was -20.000000. running mean: -20.454447\n",
            "resetting env. episode 2656.000000, reward total was -18.000000. running mean: -20.429903\n",
            "resetting env. episode 2657.000000, reward total was -19.000000. running mean: -20.415604\n",
            "resetting env. episode 2658.000000, reward total was -18.000000. running mean: -20.391448\n",
            "resetting env. episode 2659.000000, reward total was -21.000000. running mean: -20.397533\n",
            "resetting env. episode 2660.000000, reward total was -21.000000. running mean: -20.403558\n",
            "resetting env. episode 2661.000000, reward total was -21.000000. running mean: -20.409522\n",
            "resetting env. episode 2662.000000, reward total was -20.000000. running mean: -20.405427\n",
            "resetting env. episode 2663.000000, reward total was -21.000000. running mean: -20.411373\n",
            "resetting env. episode 2664.000000, reward total was -21.000000. running mean: -20.417259\n",
            "resetting env. episode 2665.000000, reward total was -21.000000. running mean: -20.423087\n",
            "resetting env. episode 2666.000000, reward total was -21.000000. running mean: -20.428856\n",
            "resetting env. episode 2667.000000, reward total was -21.000000. running mean: -20.434567\n",
            "resetting env. episode 2668.000000, reward total was -21.000000. running mean: -20.440222\n",
            "resetting env. episode 2669.000000, reward total was -21.000000. running mean: -20.445819\n",
            "resetting env. episode 2670.000000, reward total was -21.000000. running mean: -20.451361\n",
            "resetting env. episode 2671.000000, reward total was -21.000000. running mean: -20.456848\n",
            "resetting env. episode 2672.000000, reward total was -21.000000. running mean: -20.462279\n",
            "resetting env. episode 2673.000000, reward total was -21.000000. running mean: -20.467656\n",
            "resetting env. episode 2674.000000, reward total was -21.000000. running mean: -20.472980\n",
            "resetting env. episode 2675.000000, reward total was -21.000000. running mean: -20.478250\n",
            "resetting env. episode 2676.000000, reward total was -21.000000. running mean: -20.483467\n",
            "resetting env. episode 2677.000000, reward total was -20.000000. running mean: -20.478633\n",
            "resetting env. episode 2678.000000, reward total was -21.000000. running mean: -20.483846\n",
            "resetting env. episode 2679.000000, reward total was -20.000000. running mean: -20.479008\n",
            "resetting env. episode 2680.000000, reward total was -21.000000. running mean: -20.484218\n",
            "resetting env. episode 2681.000000, reward total was -19.000000. running mean: -20.469376\n",
            "resetting env. episode 2682.000000, reward total was -21.000000. running mean: -20.474682\n",
            "resetting env. episode 2683.000000, reward total was -21.000000. running mean: -20.479935\n",
            "resetting env. episode 2684.000000, reward total was -21.000000. running mean: -20.485136\n",
            "resetting env. episode 2685.000000, reward total was -21.000000. running mean: -20.490284\n",
            "resetting env. episode 2686.000000, reward total was -21.000000. running mean: -20.495382\n",
            "resetting env. episode 2687.000000, reward total was -20.000000. running mean: -20.490428\n",
            "resetting env. episode 2688.000000, reward total was -21.000000. running mean: -20.495523\n",
            "resetting env. episode 2689.000000, reward total was -20.000000. running mean: -20.490568\n",
            "resetting env. episode 2690.000000, reward total was -21.000000. running mean: -20.495663\n",
            "resetting env. episode 2691.000000, reward total was -21.000000. running mean: -20.500706\n",
            "resetting env. episode 2692.000000, reward total was -21.000000. running mean: -20.505699\n",
            "resetting env. episode 2693.000000, reward total was -20.000000. running mean: -20.500642\n",
            "resetting env. episode 2694.000000, reward total was -21.000000. running mean: -20.505635\n",
            "resetting env. episode 2695.000000, reward total was -21.000000. running mean: -20.510579\n",
            "resetting env. episode 2696.000000, reward total was -19.000000. running mean: -20.495473\n",
            "resetting env. episode 2697.000000, reward total was -21.000000. running mean: -20.500519\n",
            "resetting env. episode 2698.000000, reward total was -21.000000. running mean: -20.505513\n",
            "resetting env. episode 2699.000000, reward total was -21.000000. running mean: -20.510458\n",
            "resetting env. episode 2700.000000, reward total was -21.000000. running mean: -20.515354\n",
            "resetting env. episode 2701.000000, reward total was -20.000000. running mean: -20.510200\n",
            "resetting env. episode 2702.000000, reward total was -21.000000. running mean: -20.515098\n",
            "resetting env. episode 2703.000000, reward total was -21.000000. running mean: -20.519947\n",
            "resetting env. episode 2704.000000, reward total was -21.000000. running mean: -20.524748\n",
            "resetting env. episode 2705.000000, reward total was -20.000000. running mean: -20.519500\n",
            "resetting env. episode 2706.000000, reward total was -21.000000. running mean: -20.524305\n",
            "resetting env. episode 2707.000000, reward total was -18.000000. running mean: -20.499062\n",
            "resetting env. episode 2708.000000, reward total was -21.000000. running mean: -20.504072\n",
            "resetting env. episode 2709.000000, reward total was -21.000000. running mean: -20.509031\n",
            "resetting env. episode 2710.000000, reward total was -20.000000. running mean: -20.503941\n",
            "resetting env. episode 2711.000000, reward total was -21.000000. running mean: -20.508901\n",
            "resetting env. episode 2712.000000, reward total was -21.000000. running mean: -20.513812\n",
            "resetting env. episode 2713.000000, reward total was -21.000000. running mean: -20.518674\n",
            "resetting env. episode 2714.000000, reward total was -19.000000. running mean: -20.503487\n",
            "resetting env. episode 2715.000000, reward total was -21.000000. running mean: -20.508452\n",
            "resetting env. episode 2716.000000, reward total was -21.000000. running mean: -20.513368\n",
            "resetting env. episode 2717.000000, reward total was -20.000000. running mean: -20.508234\n",
            "resetting env. episode 2718.000000, reward total was -20.000000. running mean: -20.503152\n",
            "resetting env. episode 2719.000000, reward total was -20.000000. running mean: -20.498120\n",
            "resetting env. episode 2720.000000, reward total was -21.000000. running mean: -20.503139\n",
            "resetting env. episode 2721.000000, reward total was -21.000000. running mean: -20.508108\n",
            "resetting env. episode 2722.000000, reward total was -21.000000. running mean: -20.513027\n",
            "resetting env. episode 2723.000000, reward total was -21.000000. running mean: -20.517896\n",
            "resetting env. episode 2724.000000, reward total was -19.000000. running mean: -20.502717\n",
            "resetting env. episode 2725.000000, reward total was -19.000000. running mean: -20.487690\n",
            "resetting env. episode 2726.000000, reward total was -19.000000. running mean: -20.472813\n",
            "resetting env. episode 2727.000000, reward total was -20.000000. running mean: -20.468085\n",
            "resetting env. episode 2728.000000, reward total was -20.000000. running mean: -20.463404\n",
            "resetting env. episode 2729.000000, reward total was -21.000000. running mean: -20.468770\n",
            "resetting env. episode 2730.000000, reward total was -19.000000. running mean: -20.454083\n",
            "resetting env. episode 2731.000000, reward total was -21.000000. running mean: -20.459542\n",
            "resetting env. episode 2732.000000, reward total was -19.000000. running mean: -20.444946\n",
            "resetting env. episode 2733.000000, reward total was -21.000000. running mean: -20.450497\n",
            "resetting env. episode 2734.000000, reward total was -21.000000. running mean: -20.455992\n",
            "resetting env. episode 2735.000000, reward total was -21.000000. running mean: -20.461432\n",
            "resetting env. episode 2736.000000, reward total was -21.000000. running mean: -20.466818\n",
            "resetting env. episode 2737.000000, reward total was -21.000000. running mean: -20.472150\n",
            "resetting env. episode 2738.000000, reward total was -17.000000. running mean: -20.437428\n",
            "resetting env. episode 2739.000000, reward total was -19.000000. running mean: -20.423054\n",
            "resetting env. episode 2740.000000, reward total was -21.000000. running mean: -20.428823\n",
            "resetting env. episode 2741.000000, reward total was -21.000000. running mean: -20.434535\n",
            "resetting env. episode 2742.000000, reward total was -20.000000. running mean: -20.430190\n",
            "resetting env. episode 2743.000000, reward total was -21.000000. running mean: -20.435888\n",
            "resetting env. episode 2744.000000, reward total was -21.000000. running mean: -20.441529\n",
            "resetting env. episode 2745.000000, reward total was -21.000000. running mean: -20.447114\n",
            "resetting env. episode 2746.000000, reward total was -21.000000. running mean: -20.452642\n",
            "resetting env. episode 2747.000000, reward total was -21.000000. running mean: -20.458116\n",
            "resetting env. episode 2748.000000, reward total was -21.000000. running mean: -20.463535\n",
            "resetting env. episode 2749.000000, reward total was -21.000000. running mean: -20.468899\n",
            "resetting env. episode 2750.000000, reward total was -20.000000. running mean: -20.464210\n",
            "resetting env. episode 2751.000000, reward total was -21.000000. running mean: -20.469568\n",
            "resetting env. episode 2752.000000, reward total was -21.000000. running mean: -20.474873\n",
            "resetting env. episode 2753.000000, reward total was -21.000000. running mean: -20.480124\n",
            "resetting env. episode 2754.000000, reward total was -21.000000. running mean: -20.485323\n",
            "resetting env. episode 2755.000000, reward total was -19.000000. running mean: -20.470470\n",
            "resetting env. episode 2756.000000, reward total was -21.000000. running mean: -20.475765\n",
            "resetting env. episode 2757.000000, reward total was -20.000000. running mean: -20.471007\n",
            "resetting env. episode 2758.000000, reward total was -21.000000. running mean: -20.476297\n",
            "resetting env. episode 2759.000000, reward total was -21.000000. running mean: -20.481534\n",
            "resetting env. episode 2760.000000, reward total was -19.000000. running mean: -20.466719\n",
            "resetting env. episode 2761.000000, reward total was -17.000000. running mean: -20.432052\n",
            "resetting env. episode 2762.000000, reward total was -21.000000. running mean: -20.437731\n",
            "resetting env. episode 2763.000000, reward total was -21.000000. running mean: -20.443354\n",
            "resetting env. episode 2764.000000, reward total was -20.000000. running mean: -20.438920\n",
            "resetting env. episode 2765.000000, reward total was -21.000000. running mean: -20.444531\n",
            "resetting env. episode 2766.000000, reward total was -20.000000. running mean: -20.440086\n",
            "resetting env. episode 2767.000000, reward total was -21.000000. running mean: -20.445685\n",
            "resetting env. episode 2768.000000, reward total was -21.000000. running mean: -20.451228\n",
            "resetting env. episode 2769.000000, reward total was -21.000000. running mean: -20.456716\n",
            "resetting env. episode 2770.000000, reward total was -21.000000. running mean: -20.462149\n",
            "resetting env. episode 2771.000000, reward total was -21.000000. running mean: -20.467527\n",
            "resetting env. episode 2772.000000, reward total was -21.000000. running mean: -20.472852\n",
            "resetting env. episode 2773.000000, reward total was -21.000000. running mean: -20.478123\n",
            "resetting env. episode 2774.000000, reward total was -21.000000. running mean: -20.483342\n",
            "resetting env. episode 2775.000000, reward total was -21.000000. running mean: -20.488509\n",
            "resetting env. episode 2776.000000, reward total was -21.000000. running mean: -20.493624\n",
            "resetting env. episode 2777.000000, reward total was -20.000000. running mean: -20.488687\n",
            "resetting env. episode 2778.000000, reward total was -20.000000. running mean: -20.483800\n",
            "resetting env. episode 2779.000000, reward total was -20.000000. running mean: -20.478962\n",
            "resetting env. episode 2780.000000, reward total was -21.000000. running mean: -20.484173\n",
            "resetting env. episode 2781.000000, reward total was -19.000000. running mean: -20.469331\n",
            "resetting env. episode 2782.000000, reward total was -21.000000. running mean: -20.474638\n",
            "resetting env. episode 2783.000000, reward total was -21.000000. running mean: -20.479891\n",
            "resetting env. episode 2784.000000, reward total was -21.000000. running mean: -20.485092\n",
            "resetting env. episode 2785.000000, reward total was -21.000000. running mean: -20.490242\n",
            "resetting env. episode 2786.000000, reward total was -20.000000. running mean: -20.485339\n",
            "resetting env. episode 2787.000000, reward total was -21.000000. running mean: -20.490486\n",
            "resetting env. episode 2788.000000, reward total was -21.000000. running mean: -20.495581\n",
            "resetting env. episode 2789.000000, reward total was -21.000000. running mean: -20.500625\n",
            "resetting env. episode 2790.000000, reward total was -19.000000. running mean: -20.485619\n",
            "resetting env. episode 2791.000000, reward total was -21.000000. running mean: -20.490763\n",
            "resetting env. episode 2792.000000, reward total was -19.000000. running mean: -20.475855\n",
            "resetting env. episode 2793.000000, reward total was -19.000000. running mean: -20.461096\n",
            "resetting env. episode 2794.000000, reward total was -20.000000. running mean: -20.456486\n",
            "resetting env. episode 2795.000000, reward total was -21.000000. running mean: -20.461921\n",
            "resetting env. episode 2796.000000, reward total was -21.000000. running mean: -20.467301\n",
            "resetting env. episode 2797.000000, reward total was -21.000000. running mean: -20.472628\n",
            "resetting env. episode 2798.000000, reward total was -21.000000. running mean: -20.477902\n",
            "resetting env. episode 2799.000000, reward total was -20.000000. running mean: -20.473123\n",
            "resetting env. episode 2800.000000, reward total was -20.000000. running mean: -20.468392\n",
            "resetting env. episode 2801.000000, reward total was -21.000000. running mean: -20.473708\n",
            "resetting env. episode 2802.000000, reward total was -20.000000. running mean: -20.468971\n",
            "resetting env. episode 2803.000000, reward total was -21.000000. running mean: -20.474281\n",
            "resetting env. episode 2804.000000, reward total was -20.000000. running mean: -20.469538\n",
            "resetting env. episode 2805.000000, reward total was -21.000000. running mean: -20.474843\n",
            "resetting env. episode 2806.000000, reward total was -21.000000. running mean: -20.480095\n",
            "resetting env. episode 2807.000000, reward total was -20.000000. running mean: -20.475294\n",
            "resetting env. episode 2808.000000, reward total was -17.000000. running mean: -20.440541\n",
            "resetting env. episode 2809.000000, reward total was -20.000000. running mean: -20.436135\n",
            "resetting env. episode 2810.000000, reward total was -21.000000. running mean: -20.441774\n",
            "resetting env. episode 2811.000000, reward total was -21.000000. running mean: -20.447356\n",
            "resetting env. episode 2812.000000, reward total was -21.000000. running mean: -20.452883\n",
            "resetting env. episode 2813.000000, reward total was -21.000000. running mean: -20.458354\n",
            "resetting env. episode 2814.000000, reward total was -21.000000. running mean: -20.463770\n",
            "resetting env. episode 2815.000000, reward total was -19.000000. running mean: -20.449133\n",
            "resetting env. episode 2816.000000, reward total was -20.000000. running mean: -20.444641\n",
            "resetting env. episode 2817.000000, reward total was -21.000000. running mean: -20.450195\n",
            "resetting env. episode 2818.000000, reward total was -21.000000. running mean: -20.455693\n",
            "resetting env. episode 2819.000000, reward total was -18.000000. running mean: -20.431136\n",
            "resetting env. episode 2820.000000, reward total was -21.000000. running mean: -20.436825\n",
            "resetting env. episode 2821.000000, reward total was -19.000000. running mean: -20.422456\n",
            "resetting env. episode 2822.000000, reward total was -21.000000. running mean: -20.428232\n",
            "resetting env. episode 2823.000000, reward total was -21.000000. running mean: -20.433949\n",
            "resetting env. episode 2824.000000, reward total was -21.000000. running mean: -20.439610\n",
            "resetting env. episode 2825.000000, reward total was -21.000000. running mean: -20.445214\n",
            "resetting env. episode 2826.000000, reward total was -21.000000. running mean: -20.450762\n",
            "resetting env. episode 2827.000000, reward total was -21.000000. running mean: -20.456254\n",
            "resetting env. episode 2828.000000, reward total was -21.000000. running mean: -20.461692\n",
            "resetting env. episode 2829.000000, reward total was -21.000000. running mean: -20.467075\n",
            "resetting env. episode 2830.000000, reward total was -21.000000. running mean: -20.472404\n",
            "resetting env. episode 2831.000000, reward total was -19.000000. running mean: -20.457680\n",
            "resetting env. episode 2832.000000, reward total was -21.000000. running mean: -20.463103\n",
            "resetting env. episode 2833.000000, reward total was -21.000000. running mean: -20.468472\n",
            "resetting env. episode 2834.000000, reward total was -20.000000. running mean: -20.463787\n",
            "resetting env. episode 2835.000000, reward total was -21.000000. running mean: -20.469149\n",
            "resetting env. episode 2836.000000, reward total was -21.000000. running mean: -20.474458\n",
            "resetting env. episode 2837.000000, reward total was -21.000000. running mean: -20.479713\n",
            "resetting env. episode 2838.000000, reward total was -21.000000. running mean: -20.484916\n",
            "resetting env. episode 2839.000000, reward total was -21.000000. running mean: -20.490067\n",
            "resetting env. episode 2840.000000, reward total was -20.000000. running mean: -20.485166\n",
            "resetting env. episode 2841.000000, reward total was -21.000000. running mean: -20.490315\n",
            "resetting env. episode 2842.000000, reward total was -21.000000. running mean: -20.495412\n",
            "resetting env. episode 2843.000000, reward total was -20.000000. running mean: -20.490457\n",
            "resetting env. episode 2844.000000, reward total was -21.000000. running mean: -20.495553\n",
            "resetting env. episode 2845.000000, reward total was -20.000000. running mean: -20.490597\n",
            "resetting env. episode 2846.000000, reward total was -21.000000. running mean: -20.495691\n",
            "resetting env. episode 2847.000000, reward total was -21.000000. running mean: -20.500734\n",
            "resetting env. episode 2848.000000, reward total was -21.000000. running mean: -20.505727\n",
            "resetting env. episode 2849.000000, reward total was -20.000000. running mean: -20.500670\n",
            "resetting env. episode 2850.000000, reward total was -19.000000. running mean: -20.485663\n",
            "resetting env. episode 2851.000000, reward total was -19.000000. running mean: -20.470807\n",
            "resetting env. episode 2852.000000, reward total was -20.000000. running mean: -20.466098\n",
            "resetting env. episode 2853.000000, reward total was -21.000000. running mean: -20.471437\n",
            "resetting env. episode 2854.000000, reward total was -21.000000. running mean: -20.476723\n",
            "resetting env. episode 2855.000000, reward total was -21.000000. running mean: -20.481956\n",
            "resetting env. episode 2856.000000, reward total was -21.000000. running mean: -20.487136\n",
            "resetting env. episode 2857.000000, reward total was -21.000000. running mean: -20.492265\n",
            "resetting env. episode 2858.000000, reward total was -21.000000. running mean: -20.497342\n",
            "resetting env. episode 2859.000000, reward total was -21.000000. running mean: -20.502369\n",
            "resetting env. episode 2860.000000, reward total was -21.000000. running mean: -20.507345\n",
            "resetting env. episode 2861.000000, reward total was -21.000000. running mean: -20.512272\n",
            "resetting env. episode 2862.000000, reward total was -20.000000. running mean: -20.507149\n",
            "resetting env. episode 2863.000000, reward total was -21.000000. running mean: -20.512078\n",
            "resetting env. episode 2864.000000, reward total was -21.000000. running mean: -20.516957\n",
            "resetting env. episode 2865.000000, reward total was -20.000000. running mean: -20.511787\n",
            "resetting env. episode 2866.000000, reward total was -21.000000. running mean: -20.516669\n",
            "resetting env. episode 2867.000000, reward total was -20.000000. running mean: -20.511503\n",
            "resetting env. episode 2868.000000, reward total was -21.000000. running mean: -20.516388\n",
            "resetting env. episode 2869.000000, reward total was -21.000000. running mean: -20.521224\n",
            "resetting env. episode 2870.000000, reward total was -21.000000. running mean: -20.526011\n",
            "resetting env. episode 2871.000000, reward total was -20.000000. running mean: -20.520751\n",
            "resetting env. episode 2872.000000, reward total was -21.000000. running mean: -20.525544\n",
            "resetting env. episode 2873.000000, reward total was -21.000000. running mean: -20.530288\n",
            "resetting env. episode 2874.000000, reward total was -18.000000. running mean: -20.504986\n",
            "resetting env. episode 2875.000000, reward total was -20.000000. running mean: -20.499936\n",
            "resetting env. episode 2876.000000, reward total was -20.000000. running mean: -20.494936\n",
            "resetting env. episode 2877.000000, reward total was -20.000000. running mean: -20.489987\n",
            "resetting env. episode 2878.000000, reward total was -21.000000. running mean: -20.495087\n",
            "resetting env. episode 2879.000000, reward total was -20.000000. running mean: -20.490136\n",
            "resetting env. episode 2880.000000, reward total was -20.000000. running mean: -20.485235\n",
            "resetting env. episode 2881.000000, reward total was -16.000000. running mean: -20.440383\n",
            "resetting env. episode 2882.000000, reward total was -21.000000. running mean: -20.445979\n",
            "resetting env. episode 2883.000000, reward total was -21.000000. running mean: -20.451519\n",
            "resetting env. episode 2884.000000, reward total was -21.000000. running mean: -20.457004\n",
            "resetting env. episode 2885.000000, reward total was -20.000000. running mean: -20.452434\n",
            "resetting env. episode 2886.000000, reward total was -21.000000. running mean: -20.457909\n",
            "resetting env. episode 2887.000000, reward total was -21.000000. running mean: -20.463330\n",
            "resetting env. episode 2888.000000, reward total was -20.000000. running mean: -20.458697\n",
            "resetting env. episode 2889.000000, reward total was -21.000000. running mean: -20.464110\n",
            "resetting env. episode 2890.000000, reward total was -21.000000. running mean: -20.469469\n",
            "resetting env. episode 2891.000000, reward total was -20.000000. running mean: -20.464774\n",
            "resetting env. episode 2892.000000, reward total was -21.000000. running mean: -20.470126\n",
            "resetting env. episode 2893.000000, reward total was -21.000000. running mean: -20.475425\n",
            "resetting env. episode 2894.000000, reward total was -21.000000. running mean: -20.480671\n",
            "resetting env. episode 2895.000000, reward total was -21.000000. running mean: -20.485864\n",
            "resetting env. episode 2896.000000, reward total was -21.000000. running mean: -20.491006\n",
            "resetting env. episode 2897.000000, reward total was -21.000000. running mean: -20.496096\n",
            "resetting env. episode 2898.000000, reward total was -21.000000. running mean: -20.501135\n",
            "resetting env. episode 2899.000000, reward total was -21.000000. running mean: -20.506123\n",
            "resetting env. episode 2900.000000, reward total was -20.000000. running mean: -20.501062\n",
            "resetting env. episode 2901.000000, reward total was -21.000000. running mean: -20.506051\n",
            "resetting env. episode 2902.000000, reward total was -21.000000. running mean: -20.510991\n",
            "resetting env. episode 2903.000000, reward total was -21.000000. running mean: -20.515881\n",
            "resetting env. episode 2904.000000, reward total was -21.000000. running mean: -20.520722\n",
            "resetting env. episode 2905.000000, reward total was -21.000000. running mean: -20.525515\n",
            "resetting env. episode 2906.000000, reward total was -21.000000. running mean: -20.530260\n",
            "resetting env. episode 2907.000000, reward total was -20.000000. running mean: -20.524957\n",
            "resetting env. episode 2908.000000, reward total was -21.000000. running mean: -20.529708\n",
            "resetting env. episode 2909.000000, reward total was -21.000000. running mean: -20.534411\n",
            "resetting env. episode 2910.000000, reward total was -21.000000. running mean: -20.539066\n",
            "resetting env. episode 2911.000000, reward total was -21.000000. running mean: -20.543676\n",
            "resetting env. episode 2912.000000, reward total was -20.000000. running mean: -20.538239\n",
            "resetting env. episode 2913.000000, reward total was -21.000000. running mean: -20.542857\n",
            "resetting env. episode 2914.000000, reward total was -20.000000. running mean: -20.537428\n",
            "resetting env. episode 2915.000000, reward total was -19.000000. running mean: -20.522054\n",
            "resetting env. episode 2916.000000, reward total was -19.000000. running mean: -20.506833\n",
            "resetting env. episode 2917.000000, reward total was -21.000000. running mean: -20.511765\n",
            "resetting env. episode 2918.000000, reward total was -21.000000. running mean: -20.516647\n",
            "resetting env. episode 2919.000000, reward total was -21.000000. running mean: -20.521481\n",
            "resetting env. episode 2920.000000, reward total was -19.000000. running mean: -20.506266\n",
            "resetting env. episode 2921.000000, reward total was -21.000000. running mean: -20.511203\n",
            "resetting env. episode 2922.000000, reward total was -21.000000. running mean: -20.516091\n",
            "resetting env. episode 2923.000000, reward total was -20.000000. running mean: -20.510930\n",
            "resetting env. episode 2924.000000, reward total was -20.000000. running mean: -20.505821\n",
            "resetting env. episode 2925.000000, reward total was -19.000000. running mean: -20.490763\n",
            "resetting env. episode 2926.000000, reward total was -20.000000. running mean: -20.485855\n",
            "resetting env. episode 2927.000000, reward total was -21.000000. running mean: -20.490997\n",
            "resetting env. episode 2928.000000, reward total was -21.000000. running mean: -20.496087\n",
            "resetting env. episode 2929.000000, reward total was -21.000000. running mean: -20.501126\n",
            "resetting env. episode 2930.000000, reward total was -21.000000. running mean: -20.506115\n",
            "resetting env. episode 2931.000000, reward total was -21.000000. running mean: -20.511053\n",
            "resetting env. episode 2932.000000, reward total was -20.000000. running mean: -20.505943\n",
            "resetting env. episode 2933.000000, reward total was -21.000000. running mean: -20.510883\n",
            "resetting env. episode 2934.000000, reward total was -19.000000. running mean: -20.495775\n",
            "resetting env. episode 2935.000000, reward total was -20.000000. running mean: -20.490817\n",
            "resetting env. episode 2936.000000, reward total was -20.000000. running mean: -20.485909\n",
            "resetting env. episode 2937.000000, reward total was -20.000000. running mean: -20.481050\n",
            "resetting env. episode 2938.000000, reward total was -21.000000. running mean: -20.486239\n",
            "resetting env. episode 2939.000000, reward total was -20.000000. running mean: -20.481377\n",
            "resetting env. episode 2940.000000, reward total was -20.000000. running mean: -20.476563\n",
            "resetting env. episode 2941.000000, reward total was -21.000000. running mean: -20.481797\n",
            "resetting env. episode 2942.000000, reward total was -21.000000. running mean: -20.486979\n",
            "resetting env. episode 2943.000000, reward total was -20.000000. running mean: -20.482110\n",
            "resetting env. episode 2944.000000, reward total was -21.000000. running mean: -20.487288\n",
            "resetting env. episode 2945.000000, reward total was -21.000000. running mean: -20.492416\n",
            "resetting env. episode 2946.000000, reward total was -20.000000. running mean: -20.487491\n",
            "resetting env. episode 2947.000000, reward total was -20.000000. running mean: -20.482617\n",
            "resetting env. episode 2948.000000, reward total was -21.000000. running mean: -20.487790\n",
            "resetting env. episode 2949.000000, reward total was -20.000000. running mean: -20.482912\n",
            "resetting env. episode 2950.000000, reward total was -17.000000. running mean: -20.448083\n",
            "resetting env. episode 2951.000000, reward total was -21.000000. running mean: -20.453602\n",
            "resetting env. episode 2952.000000, reward total was -21.000000. running mean: -20.459066\n",
            "resetting env. episode 2953.000000, reward total was -20.000000. running mean: -20.454476\n",
            "resetting env. episode 2954.000000, reward total was -19.000000. running mean: -20.439931\n",
            "resetting env. episode 2955.000000, reward total was -21.000000. running mean: -20.445532\n",
            "resetting env. episode 2956.000000, reward total was -21.000000. running mean: -20.451076\n",
            "resetting env. episode 2957.000000, reward total was -19.000000. running mean: -20.436566\n",
            "resetting env. episode 2958.000000, reward total was -21.000000. running mean: -20.442200\n",
            "resetting env. episode 2959.000000, reward total was -19.000000. running mean: -20.427778\n",
            "resetting env. episode 2960.000000, reward total was -17.000000. running mean: -20.393500\n",
            "resetting env. episode 2961.000000, reward total was -21.000000. running mean: -20.399565\n",
            "resetting env. episode 2962.000000, reward total was -19.000000. running mean: -20.385570\n",
            "resetting env. episode 2963.000000, reward total was -21.000000. running mean: -20.391714\n",
            "resetting env. episode 2964.000000, reward total was -21.000000. running mean: -20.397797\n",
            "resetting env. episode 2965.000000, reward total was -21.000000. running mean: -20.403819\n",
            "resetting env. episode 2966.000000, reward total was -21.000000. running mean: -20.409781\n",
            "resetting env. episode 2967.000000, reward total was -21.000000. running mean: -20.415683\n",
            "resetting env. episode 2968.000000, reward total was -20.000000. running mean: -20.411526\n",
            "resetting env. episode 2969.000000, reward total was -20.000000. running mean: -20.407411\n",
            "resetting env. episode 2970.000000, reward total was -21.000000. running mean: -20.413337\n",
            "resetting env. episode 2971.000000, reward total was -21.000000. running mean: -20.419203\n",
            "resetting env. episode 2972.000000, reward total was -21.000000. running mean: -20.425011\n",
            "resetting env. episode 2973.000000, reward total was -21.000000. running mean: -20.430761\n",
            "resetting env. episode 2974.000000, reward total was -21.000000. running mean: -20.436453\n",
            "resetting env. episode 2975.000000, reward total was -21.000000. running mean: -20.442089\n",
            "resetting env. episode 2976.000000, reward total was -21.000000. running mean: -20.447668\n",
            "resetting env. episode 2977.000000, reward total was -20.000000. running mean: -20.443191\n",
            "resetting env. episode 2978.000000, reward total was -19.000000. running mean: -20.428759\n",
            "resetting env. episode 2979.000000, reward total was -19.000000. running mean: -20.414472\n",
            "resetting env. episode 2980.000000, reward total was -21.000000. running mean: -20.420327\n",
            "resetting env. episode 2981.000000, reward total was -20.000000. running mean: -20.416124\n",
            "resetting env. episode 2982.000000, reward total was -20.000000. running mean: -20.411963\n",
            "resetting env. episode 2983.000000, reward total was -21.000000. running mean: -20.417843\n",
            "resetting env. episode 2984.000000, reward total was -21.000000. running mean: -20.423665\n",
            "resetting env. episode 2985.000000, reward total was -20.000000. running mean: -20.419428\n",
            "resetting env. episode 2986.000000, reward total was -20.000000. running mean: -20.415234\n",
            "resetting env. episode 2987.000000, reward total was -21.000000. running mean: -20.421081\n",
            "resetting env. episode 2988.000000, reward total was -21.000000. running mean: -20.426870\n",
            "resetting env. episode 2989.000000, reward total was -21.000000. running mean: -20.432602\n",
            "resetting env. episode 2990.000000, reward total was -19.000000. running mean: -20.418276\n",
            "resetting env. episode 2991.000000, reward total was -21.000000. running mean: -20.424093\n",
            "resetting env. episode 2992.000000, reward total was -21.000000. running mean: -20.429852\n",
            "resetting env. episode 2993.000000, reward total was -21.000000. running mean: -20.435554\n",
            "resetting env. episode 2994.000000, reward total was -21.000000. running mean: -20.441198\n",
            "resetting env. episode 2995.000000, reward total was -21.000000. running mean: -20.446786\n",
            "resetting env. episode 2996.000000, reward total was -20.000000. running mean: -20.442318\n",
            "resetting env. episode 2997.000000, reward total was -21.000000. running mean: -20.447895\n",
            "resetting env. episode 2998.000000, reward total was -19.000000. running mean: -20.433416\n",
            "resetting env. episode 2999.000000, reward total was -21.000000. running mean: -20.439082\n",
            "resetting env. episode 3000.000000, reward total was -21.000000. running mean: -20.444691\n",
            "resetting env. episode 3001.000000, reward total was -20.000000. running mean: -20.440244\n",
            "resetting env. episode 3002.000000, reward total was -20.000000. running mean: -20.435842\n",
            "resetting env. episode 3003.000000, reward total was -21.000000. running mean: -20.441483\n",
            "resetting env. episode 3004.000000, reward total was -20.000000. running mean: -20.437068\n",
            "resetting env. episode 3005.000000, reward total was -21.000000. running mean: -20.442698\n",
            "resetting env. episode 3006.000000, reward total was -21.000000. running mean: -20.448271\n",
            "resetting env. episode 3007.000000, reward total was -21.000000. running mean: -20.453788\n",
            "resetting env. episode 3008.000000, reward total was -21.000000. running mean: -20.459250\n",
            "resetting env. episode 3009.000000, reward total was -20.000000. running mean: -20.454658\n",
            "resetting env. episode 3010.000000, reward total was -20.000000. running mean: -20.450111\n",
            "resetting env. episode 3011.000000, reward total was -21.000000. running mean: -20.455610\n",
            "resetting env. episode 3012.000000, reward total was -21.000000. running mean: -20.461054\n",
            "resetting env. episode 3013.000000, reward total was -21.000000. running mean: -20.466443\n",
            "resetting env. episode 3014.000000, reward total was -21.000000. running mean: -20.471779\n",
            "resetting env. episode 3015.000000, reward total was -21.000000. running mean: -20.477061\n",
            "resetting env. episode 3016.000000, reward total was -20.000000. running mean: -20.472291\n",
            "resetting env. episode 3017.000000, reward total was -20.000000. running mean: -20.467568\n",
            "resetting env. episode 3018.000000, reward total was -21.000000. running mean: -20.472892\n",
            "resetting env. episode 3019.000000, reward total was -20.000000. running mean: -20.468163\n",
            "resetting env. episode 3020.000000, reward total was -21.000000. running mean: -20.473481\n",
            "resetting env. episode 3021.000000, reward total was -20.000000. running mean: -20.468747\n",
            "resetting env. episode 3022.000000, reward total was -21.000000. running mean: -20.474059\n",
            "resetting env. episode 3023.000000, reward total was -20.000000. running mean: -20.469319\n",
            "resetting env. episode 3024.000000, reward total was -20.000000. running mean: -20.464625\n",
            "resetting env. episode 3025.000000, reward total was -20.000000. running mean: -20.459979\n",
            "resetting env. episode 3026.000000, reward total was -20.000000. running mean: -20.455379\n",
            "resetting env. episode 3027.000000, reward total was -20.000000. running mean: -20.450826\n",
            "resetting env. episode 3028.000000, reward total was -21.000000. running mean: -20.456317\n",
            "resetting env. episode 3029.000000, reward total was -21.000000. running mean: -20.461754\n",
            "resetting env. episode 3030.000000, reward total was -21.000000. running mean: -20.467137\n",
            "resetting env. episode 3031.000000, reward total was -21.000000. running mean: -20.472465\n",
            "resetting env. episode 3032.000000, reward total was -21.000000. running mean: -20.477741\n",
            "resetting env. episode 3033.000000, reward total was -21.000000. running mean: -20.482963\n",
            "resetting env. episode 3034.000000, reward total was -19.000000. running mean: -20.468133\n",
            "resetting env. episode 3035.000000, reward total was -20.000000. running mean: -20.463452\n",
            "resetting env. episode 3036.000000, reward total was -21.000000. running mean: -20.468818\n",
            "resetting env. episode 3037.000000, reward total was -21.000000. running mean: -20.474129\n",
            "resetting env. episode 3038.000000, reward total was -21.000000. running mean: -20.479388\n",
            "resetting env. episode 3039.000000, reward total was -21.000000. running mean: -20.484594\n",
            "resetting env. episode 3040.000000, reward total was -17.000000. running mean: -20.449748\n",
            "resetting env. episode 3041.000000, reward total was -21.000000. running mean: -20.455251\n",
            "resetting env. episode 3042.000000, reward total was -21.000000. running mean: -20.460698\n",
            "resetting env. episode 3043.000000, reward total was -20.000000. running mean: -20.456091\n",
            "resetting env. episode 3044.000000, reward total was -20.000000. running mean: -20.451530\n",
            "resetting env. episode 3045.000000, reward total was -21.000000. running mean: -20.457015\n",
            "resetting env. episode 3046.000000, reward total was -20.000000. running mean: -20.452445\n",
            "resetting env. episode 3047.000000, reward total was -21.000000. running mean: -20.457921\n",
            "resetting env. episode 3048.000000, reward total was -19.000000. running mean: -20.443341\n",
            "resetting env. episode 3049.000000, reward total was -21.000000. running mean: -20.448908\n",
            "resetting env. episode 3050.000000, reward total was -20.000000. running mean: -20.444419\n",
            "resetting env. episode 3051.000000, reward total was -21.000000. running mean: -20.449975\n",
            "resetting env. episode 3052.000000, reward total was -21.000000. running mean: -20.455475\n",
            "resetting env. episode 3053.000000, reward total was -21.000000. running mean: -20.460920\n",
            "resetting env. episode 3054.000000, reward total was -21.000000. running mean: -20.466311\n",
            "resetting env. episode 3055.000000, reward total was -21.000000. running mean: -20.471648\n",
            "resetting env. episode 3056.000000, reward total was -21.000000. running mean: -20.476931\n",
            "resetting env. episode 3057.000000, reward total was -20.000000. running mean: -20.472162\n",
            "resetting env. episode 3058.000000, reward total was -21.000000. running mean: -20.477440\n",
            "resetting env. episode 3059.000000, reward total was -20.000000. running mean: -20.472666\n",
            "resetting env. episode 3060.000000, reward total was -21.000000. running mean: -20.477939\n",
            "resetting env. episode 3061.000000, reward total was -21.000000. running mean: -20.483160\n",
            "resetting env. episode 3062.000000, reward total was -21.000000. running mean: -20.488328\n",
            "resetting env. episode 3063.000000, reward total was -21.000000. running mean: -20.493445\n",
            "resetting env. episode 3064.000000, reward total was -21.000000. running mean: -20.498511\n",
            "resetting env. episode 3065.000000, reward total was -21.000000. running mean: -20.503526\n",
            "resetting env. episode 3066.000000, reward total was -19.000000. running mean: -20.488490\n",
            "resetting env. episode 3067.000000, reward total was -21.000000. running mean: -20.493605\n",
            "resetting env. episode 3068.000000, reward total was -21.000000. running mean: -20.498669\n",
            "resetting env. episode 3069.000000, reward total was -20.000000. running mean: -20.493683\n",
            "resetting env. episode 3070.000000, reward total was -21.000000. running mean: -20.498746\n",
            "resetting env. episode 3071.000000, reward total was -21.000000. running mean: -20.503758\n",
            "resetting env. episode 3072.000000, reward total was -21.000000. running mean: -20.508721\n",
            "resetting env. episode 3073.000000, reward total was -21.000000. running mean: -20.513634\n",
            "resetting env. episode 3074.000000, reward total was -17.000000. running mean: -20.478497\n",
            "resetting env. episode 3075.000000, reward total was -21.000000. running mean: -20.483712\n",
            "resetting env. episode 3076.000000, reward total was -21.000000. running mean: -20.488875\n",
            "resetting env. episode 3077.000000, reward total was -21.000000. running mean: -20.493986\n",
            "resetting env. episode 3078.000000, reward total was -21.000000. running mean: -20.499047\n",
            "resetting env. episode 3079.000000, reward total was -19.000000. running mean: -20.484056\n",
            "resetting env. episode 3080.000000, reward total was -21.000000. running mean: -20.489215\n",
            "resetting env. episode 3081.000000, reward total was -21.000000. running mean: -20.494323\n",
            "resetting env. episode 3082.000000, reward total was -21.000000. running mean: -20.499380\n",
            "resetting env. episode 3083.000000, reward total was -21.000000. running mean: -20.504386\n",
            "resetting env. episode 3084.000000, reward total was -21.000000. running mean: -20.509342\n",
            "resetting env. episode 3085.000000, reward total was -20.000000. running mean: -20.504249\n",
            "resetting env. episode 3086.000000, reward total was -20.000000. running mean: -20.499207\n",
            "resetting env. episode 3087.000000, reward total was -21.000000. running mean: -20.504214\n",
            "resetting env. episode 3088.000000, reward total was -20.000000. running mean: -20.499172\n",
            "resetting env. episode 3089.000000, reward total was -19.000000. running mean: -20.484181\n",
            "resetting env. episode 3090.000000, reward total was -21.000000. running mean: -20.489339\n",
            "resetting env. episode 3091.000000, reward total was -21.000000. running mean: -20.494445\n",
            "resetting env. episode 3092.000000, reward total was -20.000000. running mean: -20.489501\n",
            "resetting env. episode 3093.000000, reward total was -20.000000. running mean: -20.484606\n",
            "resetting env. episode 3094.000000, reward total was -19.000000. running mean: -20.469760\n",
            "resetting env. episode 3095.000000, reward total was -21.000000. running mean: -20.475062\n",
            "resetting env. episode 3096.000000, reward total was -21.000000. running mean: -20.480312\n",
            "resetting env. episode 3097.000000, reward total was -20.000000. running mean: -20.475509\n",
            "resetting env. episode 3098.000000, reward total was -21.000000. running mean: -20.480753\n",
            "resetting env. episode 3099.000000, reward total was -20.000000. running mean: -20.475946\n",
            "resetting env. episode 3100.000000, reward total was -21.000000. running mean: -20.481186\n",
            "resetting env. episode 3101.000000, reward total was -21.000000. running mean: -20.486375\n",
            "resetting env. episode 3102.000000, reward total was -18.000000. running mean: -20.461511\n",
            "resetting env. episode 3103.000000, reward total was -21.000000. running mean: -20.466896\n",
            "resetting env. episode 3104.000000, reward total was -19.000000. running mean: -20.452227\n",
            "resetting env. episode 3105.000000, reward total was -21.000000. running mean: -20.457705\n",
            "resetting env. episode 3106.000000, reward total was -21.000000. running mean: -20.463127\n",
            "resetting env. episode 3107.000000, reward total was -20.000000. running mean: -20.458496\n",
            "resetting env. episode 3108.000000, reward total was -21.000000. running mean: -20.463911\n",
            "resetting env. episode 3109.000000, reward total was -20.000000. running mean: -20.459272\n",
            "resetting env. episode 3110.000000, reward total was -21.000000. running mean: -20.464679\n",
            "resetting env. episode 3111.000000, reward total was -18.000000. running mean: -20.440033\n",
            "resetting env. episode 3112.000000, reward total was -21.000000. running mean: -20.445632\n",
            "resetting env. episode 3113.000000, reward total was -21.000000. running mean: -20.451176\n",
            "resetting env. episode 3114.000000, reward total was -21.000000. running mean: -20.456664\n",
            "resetting env. episode 3115.000000, reward total was -21.000000. running mean: -20.462098\n",
            "resetting env. episode 3116.000000, reward total was -20.000000. running mean: -20.457477\n",
            "resetting env. episode 3117.000000, reward total was -20.000000. running mean: -20.452902\n",
            "resetting env. episode 3118.000000, reward total was -19.000000. running mean: -20.438373\n",
            "resetting env. episode 3119.000000, reward total was -21.000000. running mean: -20.443989\n",
            "resetting env. episode 3120.000000, reward total was -20.000000. running mean: -20.439549\n",
            "resetting env. episode 3121.000000, reward total was -19.000000. running mean: -20.425154\n",
            "resetting env. episode 3122.000000, reward total was -19.000000. running mean: -20.410902\n",
            "resetting env. episode 3123.000000, reward total was -21.000000. running mean: -20.416793\n",
            "resetting env. episode 3124.000000, reward total was -20.000000. running mean: -20.412625\n",
            "resetting env. episode 3125.000000, reward total was -21.000000. running mean: -20.418499\n",
            "resetting env. episode 3126.000000, reward total was -21.000000. running mean: -20.424314\n",
            "resetting env. episode 3127.000000, reward total was -21.000000. running mean: -20.430071\n",
            "resetting env. episode 3128.000000, reward total was -20.000000. running mean: -20.425770\n",
            "resetting env. episode 3129.000000, reward total was -21.000000. running mean: -20.431512\n",
            "resetting env. episode 3130.000000, reward total was -20.000000. running mean: -20.427197\n",
            "resetting env. episode 3131.000000, reward total was -20.000000. running mean: -20.422925\n",
            "resetting env. episode 3132.000000, reward total was -20.000000. running mean: -20.418696\n",
            "resetting env. episode 3133.000000, reward total was -21.000000. running mean: -20.424509\n",
            "resetting env. episode 3134.000000, reward total was -21.000000. running mean: -20.430264\n",
            "resetting env. episode 3135.000000, reward total was -21.000000. running mean: -20.435961\n",
            "resetting env. episode 3136.000000, reward total was -20.000000. running mean: -20.431602\n",
            "resetting env. episode 3137.000000, reward total was -19.000000. running mean: -20.417286\n",
            "resetting env. episode 3138.000000, reward total was -21.000000. running mean: -20.423113\n",
            "resetting env. episode 3139.000000, reward total was -21.000000. running mean: -20.428882\n",
            "resetting env. episode 3140.000000, reward total was -21.000000. running mean: -20.434593\n",
            "resetting env. episode 3141.000000, reward total was -21.000000. running mean: -20.440247\n",
            "resetting env. episode 3142.000000, reward total was -21.000000. running mean: -20.445845\n",
            "resetting env. episode 3143.000000, reward total was -20.000000. running mean: -20.441386\n",
            "resetting env. episode 3144.000000, reward total was -20.000000. running mean: -20.436972\n",
            "resetting env. episode 3145.000000, reward total was -21.000000. running mean: -20.442602\n",
            "resetting env. episode 3146.000000, reward total was -21.000000. running mean: -20.448176\n",
            "resetting env. episode 3147.000000, reward total was -20.000000. running mean: -20.443695\n",
            "resetting env. episode 3148.000000, reward total was -21.000000. running mean: -20.449258\n",
            "resetting env. episode 3149.000000, reward total was -21.000000. running mean: -20.454765\n",
            "resetting env. episode 3150.000000, reward total was -21.000000. running mean: -20.460218\n",
            "resetting env. episode 3151.000000, reward total was -20.000000. running mean: -20.455615\n",
            "resetting env. episode 3152.000000, reward total was -21.000000. running mean: -20.461059\n",
            "resetting env. episode 3153.000000, reward total was -21.000000. running mean: -20.466449\n",
            "resetting env. episode 3154.000000, reward total was -20.000000. running mean: -20.461784\n",
            "resetting env. episode 3155.000000, reward total was -20.000000. running mean: -20.457166\n",
            "resetting env. episode 3156.000000, reward total was -21.000000. running mean: -20.462595\n",
            "resetting env. episode 3157.000000, reward total was -21.000000. running mean: -20.467969\n",
            "resetting env. episode 3158.000000, reward total was -21.000000. running mean: -20.473289\n",
            "resetting env. episode 3159.000000, reward total was -21.000000. running mean: -20.478556\n",
            "resetting env. episode 3160.000000, reward total was -20.000000. running mean: -20.473771\n",
            "resetting env. episode 3161.000000, reward total was -21.000000. running mean: -20.479033\n",
            "resetting env. episode 3162.000000, reward total was -21.000000. running mean: -20.484243\n",
            "resetting env. episode 3163.000000, reward total was -21.000000. running mean: -20.489400\n",
            "resetting env. episode 3164.000000, reward total was -21.000000. running mean: -20.494506\n",
            "resetting env. episode 3165.000000, reward total was -21.000000. running mean: -20.499561\n",
            "resetting env. episode 3166.000000, reward total was -21.000000. running mean: -20.504565\n",
            "resetting env. episode 3167.000000, reward total was -21.000000. running mean: -20.509520\n",
            "resetting env. episode 3168.000000, reward total was -21.000000. running mean: -20.514425\n",
            "resetting env. episode 3169.000000, reward total was -20.000000. running mean: -20.509280\n",
            "resetting env. episode 3170.000000, reward total was -19.000000. running mean: -20.494188\n",
            "resetting env. episode 3171.000000, reward total was -21.000000. running mean: -20.499246\n",
            "resetting env. episode 3172.000000, reward total was -21.000000. running mean: -20.504253\n",
            "resetting env. episode 3173.000000, reward total was -21.000000. running mean: -20.509211\n",
            "resetting env. episode 3174.000000, reward total was -15.000000. running mean: -20.454119\n",
            "resetting env. episode 3175.000000, reward total was -17.000000. running mean: -20.419577\n",
            "resetting env. episode 3176.000000, reward total was -21.000000. running mean: -20.425382\n",
            "resetting env. episode 3177.000000, reward total was -21.000000. running mean: -20.431128\n",
            "resetting env. episode 3178.000000, reward total was -21.000000. running mean: -20.436816\n",
            "resetting env. episode 3179.000000, reward total was -21.000000. running mean: -20.442448\n",
            "resetting env. episode 3180.000000, reward total was -21.000000. running mean: -20.448024\n",
            "resetting env. episode 3181.000000, reward total was -21.000000. running mean: -20.453544\n",
            "resetting env. episode 3182.000000, reward total was -21.000000. running mean: -20.459008\n",
            "resetting env. episode 3183.000000, reward total was -19.000000. running mean: -20.444418\n",
            "resetting env. episode 3184.000000, reward total was -20.000000. running mean: -20.439974\n",
            "resetting env. episode 3185.000000, reward total was -20.000000. running mean: -20.435574\n",
            "resetting env. episode 3186.000000, reward total was -20.000000. running mean: -20.431218\n",
            "resetting env. episode 3187.000000, reward total was -21.000000. running mean: -20.436906\n",
            "resetting env. episode 3188.000000, reward total was -21.000000. running mean: -20.442537\n",
            "resetting env. episode 3189.000000, reward total was -19.000000. running mean: -20.428112\n",
            "resetting env. episode 3190.000000, reward total was -21.000000. running mean: -20.433831\n",
            "resetting env. episode 3191.000000, reward total was -20.000000. running mean: -20.429492\n",
            "resetting env. episode 3192.000000, reward total was -21.000000. running mean: -20.435197\n",
            "resetting env. episode 3193.000000, reward total was -21.000000. running mean: -20.440845\n",
            "resetting env. episode 3194.000000, reward total was -21.000000. running mean: -20.446437\n",
            "resetting env. episode 3195.000000, reward total was -21.000000. running mean: -20.451973\n",
            "resetting env. episode 3196.000000, reward total was -19.000000. running mean: -20.437453\n",
            "resetting env. episode 3197.000000, reward total was -21.000000. running mean: -20.443078\n",
            "resetting env. episode 3198.000000, reward total was -20.000000. running mean: -20.438648\n",
            "resetting env. episode 3199.000000, reward total was -20.000000. running mean: -20.434261\n",
            "resetting env. episode 3200.000000, reward total was -19.000000. running mean: -20.419919\n",
            "resetting env. episode 3201.000000, reward total was -20.000000. running mean: -20.415719\n",
            "resetting env. episode 3202.000000, reward total was -21.000000. running mean: -20.421562\n",
            "resetting env. episode 3203.000000, reward total was -19.000000. running mean: -20.407347\n",
            "resetting env. episode 3204.000000, reward total was -21.000000. running mean: -20.413273\n",
            "resetting env. episode 3205.000000, reward total was -21.000000. running mean: -20.419140\n",
            "resetting env. episode 3206.000000, reward total was -21.000000. running mean: -20.424949\n",
            "resetting env. episode 3207.000000, reward total was -21.000000. running mean: -20.430699\n",
            "resetting env. episode 3208.000000, reward total was -21.000000. running mean: -20.436392\n",
            "resetting env. episode 3209.000000, reward total was -21.000000. running mean: -20.442029\n",
            "resetting env. episode 3210.000000, reward total was -19.000000. running mean: -20.427608\n",
            "resetting env. episode 3211.000000, reward total was -20.000000. running mean: -20.423332\n",
            "resetting env. episode 3212.000000, reward total was -21.000000. running mean: -20.429099\n",
            "resetting env. episode 3213.000000, reward total was -20.000000. running mean: -20.424808\n",
            "resetting env. episode 3214.000000, reward total was -19.000000. running mean: -20.410560\n",
            "resetting env. episode 3215.000000, reward total was -19.000000. running mean: -20.396454\n",
            "resetting env. episode 3216.000000, reward total was -20.000000. running mean: -20.392490\n",
            "resetting env. episode 3217.000000, reward total was -21.000000. running mean: -20.398565\n",
            "resetting env. episode 3218.000000, reward total was -21.000000. running mean: -20.404579\n",
            "resetting env. episode 3219.000000, reward total was -21.000000. running mean: -20.410533\n",
            "resetting env. episode 3220.000000, reward total was -20.000000. running mean: -20.406428\n",
            "resetting env. episode 3221.000000, reward total was -19.000000. running mean: -20.392364\n",
            "resetting env. episode 3222.000000, reward total was -21.000000. running mean: -20.398440\n",
            "resetting env. episode 3223.000000, reward total was -21.000000. running mean: -20.404456\n",
            "resetting env. episode 3224.000000, reward total was -21.000000. running mean: -20.410411\n",
            "resetting env. episode 3225.000000, reward total was -20.000000. running mean: -20.406307\n",
            "resetting env. episode 3226.000000, reward total was -21.000000. running mean: -20.412244\n",
            "resetting env. episode 3227.000000, reward total was -21.000000. running mean: -20.418121\n",
            "resetting env. episode 3228.000000, reward total was -21.000000. running mean: -20.423940\n",
            "resetting env. episode 3229.000000, reward total was -20.000000. running mean: -20.419701\n",
            "resetting env. episode 3230.000000, reward total was -21.000000. running mean: -20.425504\n",
            "resetting env. episode 3231.000000, reward total was -20.000000. running mean: -20.421249\n",
            "resetting env. episode 3232.000000, reward total was -21.000000. running mean: -20.427036\n",
            "resetting env. episode 3233.000000, reward total was -21.000000. running mean: -20.432766\n",
            "resetting env. episode 3234.000000, reward total was -20.000000. running mean: -20.428438\n",
            "resetting env. episode 3235.000000, reward total was -21.000000. running mean: -20.434154\n",
            "resetting env. episode 3236.000000, reward total was -21.000000. running mean: -20.439812\n",
            "resetting env. episode 3237.000000, reward total was -20.000000. running mean: -20.435414\n",
            "resetting env. episode 3238.000000, reward total was -21.000000. running mean: -20.441060\n",
            "resetting env. episode 3239.000000, reward total was -21.000000. running mean: -20.446650\n",
            "resetting env. episode 3240.000000, reward total was -21.000000. running mean: -20.452183\n",
            "resetting env. episode 3241.000000, reward total was -21.000000. running mean: -20.457661\n",
            "resetting env. episode 3242.000000, reward total was -21.000000. running mean: -20.463085\n",
            "resetting env. episode 3243.000000, reward total was -20.000000. running mean: -20.458454\n",
            "resetting env. episode 3244.000000, reward total was -21.000000. running mean: -20.463869\n",
            "resetting env. episode 3245.000000, reward total was -21.000000. running mean: -20.469230\n",
            "resetting env. episode 3246.000000, reward total was -21.000000. running mean: -20.474538\n",
            "resetting env. episode 3247.000000, reward total was -19.000000. running mean: -20.459793\n",
            "resetting env. episode 3248.000000, reward total was -21.000000. running mean: -20.465195\n",
            "resetting env. episode 3249.000000, reward total was -21.000000. running mean: -20.470543\n",
            "resetting env. episode 3250.000000, reward total was -21.000000. running mean: -20.475837\n",
            "resetting env. episode 3251.000000, reward total was -19.000000. running mean: -20.461079\n",
            "resetting env. episode 3252.000000, reward total was -21.000000. running mean: -20.466468\n",
            "resetting env. episode 3253.000000, reward total was -21.000000. running mean: -20.471804\n",
            "resetting env. episode 3254.000000, reward total was -21.000000. running mean: -20.477086\n",
            "resetting env. episode 3255.000000, reward total was -21.000000. running mean: -20.482315\n",
            "resetting env. episode 3256.000000, reward total was -21.000000. running mean: -20.487492\n",
            "resetting env. episode 3257.000000, reward total was -21.000000. running mean: -20.492617\n",
            "resetting env. episode 3258.000000, reward total was -21.000000. running mean: -20.497691\n",
            "resetting env. episode 3259.000000, reward total was -21.000000. running mean: -20.502714\n",
            "resetting env. episode 3260.000000, reward total was -21.000000. running mean: -20.507686\n",
            "resetting env. episode 3261.000000, reward total was -21.000000. running mean: -20.512610\n",
            "resetting env. episode 3262.000000, reward total was -21.000000. running mean: -20.517484\n",
            "resetting env. episode 3263.000000, reward total was -19.000000. running mean: -20.502309\n",
            "resetting env. episode 3264.000000, reward total was -20.000000. running mean: -20.497286\n",
            "resetting env. episode 3265.000000, reward total was -21.000000. running mean: -20.502313\n",
            "resetting env. episode 3266.000000, reward total was -21.000000. running mean: -20.507290\n",
            "resetting env. episode 3267.000000, reward total was -21.000000. running mean: -20.512217\n",
            "resetting env. episode 3268.000000, reward total was -21.000000. running mean: -20.517095\n",
            "resetting env. episode 3269.000000, reward total was -21.000000. running mean: -20.521924\n",
            "resetting env. episode 3270.000000, reward total was -20.000000. running mean: -20.516704\n",
            "resetting env. episode 3271.000000, reward total was -20.000000. running mean: -20.511537\n",
            "resetting env. episode 3272.000000, reward total was -21.000000. running mean: -20.516422\n",
            "resetting env. episode 3273.000000, reward total was -21.000000. running mean: -20.521258\n",
            "resetting env. episode 3274.000000, reward total was -20.000000. running mean: -20.516045\n",
            "resetting env. episode 3275.000000, reward total was -19.000000. running mean: -20.500885\n",
            "resetting env. episode 3276.000000, reward total was -21.000000. running mean: -20.505876\n",
            "resetting env. episode 3277.000000, reward total was -20.000000. running mean: -20.500817\n",
            "resetting env. episode 3278.000000, reward total was -21.000000. running mean: -20.505809\n",
            "resetting env. episode 3279.000000, reward total was -21.000000. running mean: -20.510751\n",
            "resetting env. episode 3280.000000, reward total was -18.000000. running mean: -20.485643\n",
            "resetting env. episode 3281.000000, reward total was -19.000000. running mean: -20.470787\n",
            "resetting env. episode 3282.000000, reward total was -21.000000. running mean: -20.476079\n",
            "resetting env. episode 3283.000000, reward total was -21.000000. running mean: -20.481318\n",
            "resetting env. episode 3284.000000, reward total was -21.000000. running mean: -20.486505\n",
            "resetting env. episode 3285.000000, reward total was -21.000000. running mean: -20.491640\n",
            "resetting env. episode 3286.000000, reward total was -19.000000. running mean: -20.476724\n",
            "resetting env. episode 3287.000000, reward total was -21.000000. running mean: -20.481956\n",
            "resetting env. episode 3288.000000, reward total was -21.000000. running mean: -20.487137\n",
            "resetting env. episode 3289.000000, reward total was -20.000000. running mean: -20.482265\n",
            "resetting env. episode 3290.000000, reward total was -21.000000. running mean: -20.487443\n",
            "resetting env. episode 3291.000000, reward total was -21.000000. running mean: -20.492568\n",
            "resetting env. episode 3292.000000, reward total was -21.000000. running mean: -20.497643\n",
            "resetting env. episode 3293.000000, reward total was -19.000000. running mean: -20.482666\n",
            "resetting env. episode 3294.000000, reward total was -20.000000. running mean: -20.477840\n",
            "resetting env. episode 3295.000000, reward total was -20.000000. running mean: -20.473061\n",
            "resetting env. episode 3296.000000, reward total was -21.000000. running mean: -20.478331\n",
            "resetting env. episode 3297.000000, reward total was -19.000000. running mean: -20.463547\n",
            "resetting env. episode 3298.000000, reward total was -19.000000. running mean: -20.448912\n",
            "resetting env. episode 3299.000000, reward total was -21.000000. running mean: -20.454423\n",
            "resetting env. episode 3300.000000, reward total was -17.000000. running mean: -20.419878\n",
            "resetting env. episode 3301.000000, reward total was -21.000000. running mean: -20.425680\n",
            "resetting env. episode 3302.000000, reward total was -21.000000. running mean: -20.431423\n",
            "resetting env. episode 3303.000000, reward total was -21.000000. running mean: -20.437109\n",
            "resetting env. episode 3304.000000, reward total was -21.000000. running mean: -20.442738\n",
            "resetting env. episode 3305.000000, reward total was -21.000000. running mean: -20.448310\n",
            "resetting env. episode 3306.000000, reward total was -21.000000. running mean: -20.453827\n",
            "resetting env. episode 3307.000000, reward total was -21.000000. running mean: -20.459289\n",
            "resetting env. episode 3308.000000, reward total was -21.000000. running mean: -20.464696\n",
            "resetting env. episode 3309.000000, reward total was -21.000000. running mean: -20.470049\n",
            "resetting env. episode 3310.000000, reward total was -20.000000. running mean: -20.465348\n",
            "resetting env. episode 3311.000000, reward total was -21.000000. running mean: -20.470695\n",
            "resetting env. episode 3312.000000, reward total was -21.000000. running mean: -20.475988\n",
            "resetting env. episode 3313.000000, reward total was -21.000000. running mean: -20.481228\n",
            "resetting env. episode 3314.000000, reward total was -20.000000. running mean: -20.476416\n",
            "resetting env. episode 3315.000000, reward total was -20.000000. running mean: -20.471652\n",
            "resetting env. episode 3316.000000, reward total was -21.000000. running mean: -20.476935\n",
            "resetting env. episode 3317.000000, reward total was -21.000000. running mean: -20.482166\n",
            "resetting env. episode 3318.000000, reward total was -21.000000. running mean: -20.487344\n",
            "resetting env. episode 3319.000000, reward total was -20.000000. running mean: -20.482471\n",
            "resetting env. episode 3320.000000, reward total was -21.000000. running mean: -20.487646\n",
            "resetting env. episode 3321.000000, reward total was -21.000000. running mean: -20.492770\n",
            "resetting env. episode 3322.000000, reward total was -21.000000. running mean: -20.497842\n",
            "resetting env. episode 3323.000000, reward total was -21.000000. running mean: -20.502863\n",
            "resetting env. episode 3324.000000, reward total was -20.000000. running mean: -20.497835\n",
            "resetting env. episode 3325.000000, reward total was -20.000000. running mean: -20.492856\n",
            "resetting env. episode 3326.000000, reward total was -20.000000. running mean: -20.487928\n",
            "resetting env. episode 3327.000000, reward total was -20.000000. running mean: -20.483049\n",
            "resetting env. episode 3328.000000, reward total was -20.000000. running mean: -20.478218\n",
            "resetting env. episode 3329.000000, reward total was -21.000000. running mean: -20.483436\n",
            "resetting env. episode 3330.000000, reward total was -21.000000. running mean: -20.488602\n",
            "resetting env. episode 3331.000000, reward total was -21.000000. running mean: -20.493716\n",
            "resetting env. episode 3332.000000, reward total was -20.000000. running mean: -20.488778\n",
            "resetting env. episode 3333.000000, reward total was -21.000000. running mean: -20.493891\n",
            "resetting env. episode 3334.000000, reward total was -21.000000. running mean: -20.498952\n",
            "resetting env. episode 3335.000000, reward total was -21.000000. running mean: -20.503962\n",
            "resetting env. episode 3336.000000, reward total was -21.000000. running mean: -20.508923\n",
            "resetting env. episode 3337.000000, reward total was -20.000000. running mean: -20.503833\n",
            "resetting env. episode 3338.000000, reward total was -18.000000. running mean: -20.478795\n",
            "resetting env. episode 3339.000000, reward total was -20.000000. running mean: -20.474007\n",
            "resetting env. episode 3340.000000, reward total was -20.000000. running mean: -20.469267\n",
            "resetting env. episode 3341.000000, reward total was -20.000000. running mean: -20.464574\n",
            "resetting env. episode 3342.000000, reward total was -21.000000. running mean: -20.469929\n",
            "resetting env. episode 3343.000000, reward total was -20.000000. running mean: -20.465229\n",
            "resetting env. episode 3344.000000, reward total was -20.000000. running mean: -20.460577\n",
            "resetting env. episode 3345.000000, reward total was -21.000000. running mean: -20.465971\n",
            "resetting env. episode 3346.000000, reward total was -20.000000. running mean: -20.461312\n",
            "resetting env. episode 3347.000000, reward total was -21.000000. running mean: -20.466698\n",
            "resetting env. episode 3348.000000, reward total was -20.000000. running mean: -20.462031\n",
            "resetting env. episode 3349.000000, reward total was -20.000000. running mean: -20.457411\n",
            "resetting env. episode 3350.000000, reward total was -21.000000. running mean: -20.462837\n",
            "resetting env. episode 3351.000000, reward total was -21.000000. running mean: -20.468209\n",
            "resetting env. episode 3352.000000, reward total was -21.000000. running mean: -20.473527\n",
            "resetting env. episode 3353.000000, reward total was -18.000000. running mean: -20.448791\n",
            "resetting env. episode 3354.000000, reward total was -21.000000. running mean: -20.454303\n",
            "resetting env. episode 3355.000000, reward total was -21.000000. running mean: -20.459760\n",
            "resetting env. episode 3356.000000, reward total was -21.000000. running mean: -20.465163\n",
            "resetting env. episode 3357.000000, reward total was -21.000000. running mean: -20.470511\n",
            "resetting env. episode 3358.000000, reward total was -20.000000. running mean: -20.465806\n",
            "resetting env. episode 3359.000000, reward total was -20.000000. running mean: -20.461148\n",
            "resetting env. episode 3360.000000, reward total was -20.000000. running mean: -20.456536\n",
            "resetting env. episode 3361.000000, reward total was -21.000000. running mean: -20.461971\n",
            "resetting env. episode 3362.000000, reward total was -20.000000. running mean: -20.457351\n",
            "resetting env. episode 3363.000000, reward total was -21.000000. running mean: -20.462778\n",
            "resetting env. episode 3364.000000, reward total was -20.000000. running mean: -20.458150\n",
            "resetting env. episode 3365.000000, reward total was -19.000000. running mean: -20.443569\n",
            "resetting env. episode 3366.000000, reward total was -21.000000. running mean: -20.449133\n",
            "resetting env. episode 3367.000000, reward total was -20.000000. running mean: -20.444642\n",
            "resetting env. episode 3368.000000, reward total was -21.000000. running mean: -20.450195\n",
            "resetting env. episode 3369.000000, reward total was -21.000000. running mean: -20.455693\n",
            "resetting env. episode 3370.000000, reward total was -20.000000. running mean: -20.451136\n",
            "resetting env. episode 3371.000000, reward total was -21.000000. running mean: -20.456625\n",
            "resetting env. episode 3372.000000, reward total was -21.000000. running mean: -20.462059\n",
            "resetting env. episode 3373.000000, reward total was -21.000000. running mean: -20.467438\n",
            "resetting env. episode 3374.000000, reward total was -21.000000. running mean: -20.472764\n",
            "resetting env. episode 3375.000000, reward total was -20.000000. running mean: -20.468036\n",
            "resetting env. episode 3376.000000, reward total was -21.000000. running mean: -20.473356\n",
            "resetting env. episode 3377.000000, reward total was -20.000000. running mean: -20.468622\n",
            "resetting env. episode 3378.000000, reward total was -21.000000. running mean: -20.473936\n",
            "resetting env. episode 3379.000000, reward total was -21.000000. running mean: -20.479197\n",
            "resetting env. episode 3380.000000, reward total was -21.000000. running mean: -20.484405\n",
            "resetting env. episode 3381.000000, reward total was -20.000000. running mean: -20.479561\n",
            "resetting env. episode 3382.000000, reward total was -19.000000. running mean: -20.464765\n",
            "resetting env. episode 3383.000000, reward total was -21.000000. running mean: -20.470117\n",
            "resetting env. episode 3384.000000, reward total was -20.000000. running mean: -20.465416\n",
            "resetting env. episode 3385.000000, reward total was -21.000000. running mean: -20.470762\n",
            "resetting env. episode 3386.000000, reward total was -20.000000. running mean: -20.466054\n",
            "resetting env. episode 3387.000000, reward total was -21.000000. running mean: -20.471394\n",
            "resetting env. episode 3388.000000, reward total was -21.000000. running mean: -20.476680\n",
            "resetting env. episode 3389.000000, reward total was -21.000000. running mean: -20.481913\n",
            "resetting env. episode 3390.000000, reward total was -19.000000. running mean: -20.467094\n",
            "resetting env. episode 3391.000000, reward total was -21.000000. running mean: -20.472423\n",
            "resetting env. episode 3392.000000, reward total was -20.000000. running mean: -20.467699\n",
            "resetting env. episode 3393.000000, reward total was -20.000000. running mean: -20.463022\n",
            "resetting env. episode 3394.000000, reward total was -20.000000. running mean: -20.458392\n",
            "resetting env. episode 3395.000000, reward total was -21.000000. running mean: -20.463808\n",
            "resetting env. episode 3396.000000, reward total was -19.000000. running mean: -20.449170\n",
            "resetting env. episode 3397.000000, reward total was -20.000000. running mean: -20.444678\n",
            "resetting env. episode 3398.000000, reward total was -20.000000. running mean: -20.440231\n",
            "resetting env. episode 3399.000000, reward total was -19.000000. running mean: -20.425829\n",
            "resetting env. episode 3400.000000, reward total was -21.000000. running mean: -20.431570\n",
            "resetting env. episode 3401.000000, reward total was -20.000000. running mean: -20.427255\n",
            "resetting env. episode 3402.000000, reward total was -21.000000. running mean: -20.432982\n",
            "resetting env. episode 3403.000000, reward total was -18.000000. running mean: -20.408652\n",
            "resetting env. episode 3404.000000, reward total was -21.000000. running mean: -20.414566\n",
            "resetting env. episode 3405.000000, reward total was -21.000000. running mean: -20.420420\n",
            "resetting env. episode 3406.000000, reward total was -20.000000. running mean: -20.416216\n",
            "resetting env. episode 3407.000000, reward total was -21.000000. running mean: -20.422054\n",
            "resetting env. episode 3408.000000, reward total was -20.000000. running mean: -20.417833\n",
            "resetting env. episode 3409.000000, reward total was -20.000000. running mean: -20.413655\n",
            "resetting env. episode 3410.000000, reward total was -20.000000. running mean: -20.409518\n",
            "resetting env. episode 3411.000000, reward total was -20.000000. running mean: -20.405423\n",
            "resetting env. episode 3412.000000, reward total was -21.000000. running mean: -20.411369\n",
            "resetting env. episode 3413.000000, reward total was -21.000000. running mean: -20.417255\n",
            "resetting env. episode 3414.000000, reward total was -21.000000. running mean: -20.423083\n",
            "resetting env. episode 3415.000000, reward total was -21.000000. running mean: -20.428852\n",
            "resetting env. episode 3416.000000, reward total was -21.000000. running mean: -20.434563\n",
            "resetting env. episode 3417.000000, reward total was -20.000000. running mean: -20.430218\n",
            "resetting env. episode 3418.000000, reward total was -21.000000. running mean: -20.435916\n",
            "resetting env. episode 3419.000000, reward total was -20.000000. running mean: -20.431556\n",
            "resetting env. episode 3420.000000, reward total was -21.000000. running mean: -20.437241\n",
            "resetting env. episode 3421.000000, reward total was -21.000000. running mean: -20.442869\n",
            "resetting env. episode 3422.000000, reward total was -21.000000. running mean: -20.448440\n",
            "resetting env. episode 3423.000000, reward total was -21.000000. running mean: -20.453955\n",
            "resetting env. episode 3424.000000, reward total was -21.000000. running mean: -20.459416\n",
            "resetting env. episode 3425.000000, reward total was -20.000000. running mean: -20.454822\n",
            "resetting env. episode 3426.000000, reward total was -21.000000. running mean: -20.460273\n",
            "resetting env. episode 3427.000000, reward total was -19.000000. running mean: -20.445671\n",
            "resetting env. episode 3428.000000, reward total was -21.000000. running mean: -20.451214\n",
            "resetting env. episode 3429.000000, reward total was -21.000000. running mean: -20.456702\n",
            "resetting env. episode 3430.000000, reward total was -19.000000. running mean: -20.442135\n",
            "resetting env. episode 3431.000000, reward total was -20.000000. running mean: -20.437714\n",
            "resetting env. episode 3432.000000, reward total was -21.000000. running mean: -20.443336\n",
            "resetting env. episode 3433.000000, reward total was -21.000000. running mean: -20.448903\n",
            "resetting env. episode 3434.000000, reward total was -20.000000. running mean: -20.444414\n",
            "resetting env. episode 3435.000000, reward total was -21.000000. running mean: -20.449970\n",
            "resetting env. episode 3436.000000, reward total was -21.000000. running mean: -20.455470\n",
            "resetting env. episode 3437.000000, reward total was -21.000000. running mean: -20.460915\n",
            "resetting env. episode 3438.000000, reward total was -21.000000. running mean: -20.466306\n",
            "resetting env. episode 3439.000000, reward total was -21.000000. running mean: -20.471643\n",
            "resetting env. episode 3440.000000, reward total was -21.000000. running mean: -20.476927\n",
            "resetting env. episode 3441.000000, reward total was -20.000000. running mean: -20.472158\n",
            "resetting env. episode 3442.000000, reward total was -21.000000. running mean: -20.477436\n",
            "resetting env. episode 3443.000000, reward total was -20.000000. running mean: -20.472662\n",
            "resetting env. episode 3444.000000, reward total was -19.000000. running mean: -20.457935\n",
            "resetting env. episode 3445.000000, reward total was -20.000000. running mean: -20.453356\n",
            "resetting env. episode 3446.000000, reward total was -21.000000. running mean: -20.458822\n",
            "resetting env. episode 3447.000000, reward total was -21.000000. running mean: -20.464234\n",
            "resetting env. episode 3448.000000, reward total was -21.000000. running mean: -20.469592\n",
            "resetting env. episode 3449.000000, reward total was -20.000000. running mean: -20.464896\n",
            "resetting env. episode 3450.000000, reward total was -21.000000. running mean: -20.470247\n",
            "resetting env. episode 3451.000000, reward total was -20.000000. running mean: -20.465544\n",
            "resetting env. episode 3452.000000, reward total was -21.000000. running mean: -20.470889\n",
            "resetting env. episode 3453.000000, reward total was -21.000000. running mean: -20.476180\n",
            "resetting env. episode 3454.000000, reward total was -20.000000. running mean: -20.471418\n",
            "resetting env. episode 3455.000000, reward total was -21.000000. running mean: -20.476704\n",
            "resetting env. episode 3456.000000, reward total was -19.000000. running mean: -20.461937\n",
            "resetting env. episode 3457.000000, reward total was -21.000000. running mean: -20.467317\n",
            "resetting env. episode 3458.000000, reward total was -21.000000. running mean: -20.472644\n",
            "resetting env. episode 3459.000000, reward total was -21.000000. running mean: -20.477918\n",
            "resetting env. episode 3460.000000, reward total was -21.000000. running mean: -20.483139\n",
            "resetting env. episode 3461.000000, reward total was -20.000000. running mean: -20.478307\n",
            "resetting env. episode 3462.000000, reward total was -21.000000. running mean: -20.483524\n",
            "resetting env. episode 3463.000000, reward total was -21.000000. running mean: -20.488689\n",
            "resetting env. episode 3464.000000, reward total was -20.000000. running mean: -20.483802\n",
            "resetting env. episode 3465.000000, reward total was -21.000000. running mean: -20.488964\n",
            "resetting env. episode 3466.000000, reward total was -21.000000. running mean: -20.494074\n",
            "resetting env. episode 3467.000000, reward total was -21.000000. running mean: -20.499134\n",
            "resetting env. episode 3468.000000, reward total was -20.000000. running mean: -20.494142\n",
            "resetting env. episode 3469.000000, reward total was -16.000000. running mean: -20.449201\n",
            "resetting env. episode 3470.000000, reward total was -20.000000. running mean: -20.444709\n",
            "resetting env. episode 3471.000000, reward total was -21.000000. running mean: -20.450262\n",
            "resetting env. episode 3472.000000, reward total was -21.000000. running mean: -20.455759\n",
            "resetting env. episode 3473.000000, reward total was -20.000000. running mean: -20.451202\n",
            "resetting env. episode 3474.000000, reward total was -20.000000. running mean: -20.446690\n",
            "resetting env. episode 3475.000000, reward total was -21.000000. running mean: -20.452223\n",
            "resetting env. episode 3476.000000, reward total was -21.000000. running mean: -20.457700\n",
            "resetting env. episode 3477.000000, reward total was -20.000000. running mean: -20.453123\n",
            "resetting env. episode 3478.000000, reward total was -19.000000. running mean: -20.438592\n",
            "resetting env. episode 3479.000000, reward total was -19.000000. running mean: -20.424206\n",
            "resetting env. episode 3480.000000, reward total was -18.000000. running mean: -20.399964\n",
            "resetting env. episode 3481.000000, reward total was -20.000000. running mean: -20.395965\n",
            "resetting env. episode 3482.000000, reward total was -17.000000. running mean: -20.362005\n",
            "resetting env. episode 3483.000000, reward total was -21.000000. running mean: -20.368385\n",
            "resetting env. episode 3484.000000, reward total was -20.000000. running mean: -20.364701\n",
            "resetting env. episode 3485.000000, reward total was -20.000000. running mean: -20.361054\n",
            "resetting env. episode 3486.000000, reward total was -21.000000. running mean: -20.367444\n",
            "resetting env. episode 3487.000000, reward total was -21.000000. running mean: -20.373769\n",
            "resetting env. episode 3488.000000, reward total was -20.000000. running mean: -20.370031\n",
            "resetting env. episode 3489.000000, reward total was -21.000000. running mean: -20.376331\n",
            "resetting env. episode 3490.000000, reward total was -21.000000. running mean: -20.382568\n",
            "resetting env. episode 3491.000000, reward total was -21.000000. running mean: -20.388742\n",
            "resetting env. episode 3492.000000, reward total was -19.000000. running mean: -20.374855\n",
            "resetting env. episode 3493.000000, reward total was -21.000000. running mean: -20.381106\n",
            "resetting env. episode 3494.000000, reward total was -20.000000. running mean: -20.377295\n",
            "resetting env. episode 3495.000000, reward total was -20.000000. running mean: -20.373522\n",
            "resetting env. episode 3496.000000, reward total was -18.000000. running mean: -20.349787\n",
            "resetting env. episode 3497.000000, reward total was -21.000000. running mean: -20.356289\n",
            "resetting env. episode 3498.000000, reward total was -21.000000. running mean: -20.362726\n",
            "resetting env. episode 3499.000000, reward total was -20.000000. running mean: -20.359099\n",
            "resetting env. episode 3500.000000, reward total was -21.000000. running mean: -20.365508\n",
            "CPU times: user 2h 34min 54s, sys: 1h 11min 32s, total: 3h 46min 27s\n",
            "Wall time: 1h 59min 30s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cHYCDYwhlVLV"
      },
      "cell_type": "code",
      "source": [
        "#%time hist2 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "outputId": "9aa8ab79-1cb0-41e6-e43a-e7bc944051b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9AxOcQhIsKow"
      },
      "cell_type": "code",
      "source": [
        "#%time hist3 = train_model(env, model, total_episodes=1500)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2NblmwDsL3y"
      },
      "cell_type": "code",
      "source": [
        "#play_game(env, model)"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}