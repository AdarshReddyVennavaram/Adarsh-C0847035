{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "H=200_le_4_3500.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cWACPRL869I4"
      },
      "cell_type": "code",
      "source": [
        "!pip install gym >/dev/null"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Os6feRY6ec_"
      },
      "cell_type": "code",
      "source": [
        "!pip install JSAnimation >/dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wotUOa_e6edP"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from matplotlib import animation\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "\n",
        "def display_frames_as_gif(frames):\n",
        "    \"\"\"\n",
        "    Displays a list of frames as a gif, with controls\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "\n",
        "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
        "    HTML(anim.to_jshtml())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R66_INeZ9nYX"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 2: Playing Pong"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U gym>=0.21.0\n",
        "%pip install -U gym[atari,accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngMhg3fB9aA",
        "outputId": "a6a4ed09-f0d3-4c8e-c783-80df8609a3a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 45.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=b0c91e883cfc8760c44114b05cc88ae4dd4688ee7e34e379bfc46d66a5bb2f9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "MtT2GyK_6edc",
        "outputId": "dc2bda74-e6e6-41a7-a4bf-8d8d6c308d4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "env = gym.make('Pong-v0')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:318: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oRE6WmXQJ1Z0",
        "outputId": "b237174d-b345-4c11-c604-982f45241d52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.action_space"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(6)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "yl_9d4HFJ31W",
        "outputId": "0e4deb2d-9558-4eba-802b-94f7de0c44a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "env.observation_space"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(0, 255, (210, 160, 3), uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "trwRXI-h6eeI",
        "outputId": "dcb41d6c-feef-4818-cd5e-cd98d1bd8e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Run a demo of the environment\n",
        "observation = env.reset()\n",
        "cumulated_reward = 0\n",
        "\n",
        "frames = []\n",
        "for t in range(1000):\n",
        "#     print(observation)\n",
        "    frames.append(env.render(mode = 'rgb_array'))\n",
        "    # very stupid agent, just makes a random action within the allowd action space\n",
        "    action = env.action_space.sample()\n",
        "#     print(\"Action: {}\".format(t+1))    \n",
        "    observation, reward, done, info = env.step(action)\n",
        "#     print(reward)\n",
        "    cumulated_reward += reward\n",
        "    if done:\n",
        "        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "        break\n",
        "print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "\n",
        "env.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/core.py:44: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  \"The argument mode in render method is deprecated; \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
            "  \"Core environment is written in old step API which returns one bool instead of two. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -14.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "3zZTecVWLLes"
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x): \n",
        "  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n",
        "\n",
        "def prepro(I):\n",
        "  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
        "  I = I[35:195] # crop\n",
        "  I = I[::2,::2,0] # downsample by factor of 2\n",
        "  I[I == 144] = 0 # erase background (background type 1)\n",
        "  I[I == 109] = 0 # erase background (background type 2)\n",
        "  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
        "  return I.astype(np.float).ravel()\n",
        "\n",
        "def policy_forward(x):\n",
        "  h = np.dot(model['W1'], x)\n",
        "  h[h<0] = 0 # ReLU nonlinearity\n",
        "  logp = np.dot(model['W2'], h)\n",
        "  p = sigmoid(logp)\n",
        "  return p, h # return probability of taking action 2, and hidden state\n",
        "\n",
        "def model_step(model, observation, prev_x):\n",
        "  # preprocess the observation, set input to network to be difference image\n",
        "  cur_x = prepro(observation)\n",
        "  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "  prev_x = cur_x\n",
        "  \n",
        "  # forward the policy network and sample an action from the returned probability\n",
        "  aprob, _ = policy_forward(x)\n",
        "  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n",
        "  \n",
        "  return action, prev_x\n",
        "\n",
        "def play_game(env, model):\n",
        "  observation = env.reset()\n",
        "\n",
        "  frames = []\n",
        "  cumulated_reward = 0\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "\n",
        "  for t in range(1000):\n",
        "      frames.append(env.render(mode = 'rgb_array'))\n",
        "      action, prev_x = model_step(model, observation, prev_x)\n",
        "      observation, reward, done, info = env.step(action)\n",
        "      cumulated_reward += reward\n",
        "      if done:\n",
        "          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n",
        "          break\n",
        "  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n",
        "  display_frames_as_gif(frames)\n",
        "  env.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6gWvZQ7AQLQt"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 3: Policy Gradient from Scratch"
      ]
    },
    {
      "metadata": {
        "id": "eqFm7hqcItWl"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# model initialization\n",
        "H = 200 # number of hidden layer neurons\n",
        "D = 80 * 80 # input dimensionality: 80x80 grid\n",
        "model = {}\n",
        "model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n",
        "model['W2'] = np.random.randn(H) / np.sqrt(H)\n",
        "\n",
        "# import pickle\n",
        "# model = pickle.load(open('model.pkl', 'rb'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwjiwKisQM19"
      },
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 10 # every how many episodes to do a param update?\n",
        "# learning_rate = 1e-4\n",
        "learning_rate = 1e-4\n",
        " \n",
        "gamma = 0.99 # discount factor for reward\n",
        "decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n",
        "  \n",
        "grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n",
        "rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n",
        "\n",
        "def discount_rewards(r):\n",
        "  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "  discounted_r = np.zeros_like(r, dtype=np.float32)\n",
        "  running_add = 0\n",
        "  for t in reversed(range(0, r.size)):\n",
        "    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n",
        "    running_add = running_add * gamma + r[t]\n",
        "    discounted_r[t] = running_add\n",
        "  return discounted_r\n",
        "\n",
        "def policy_backward(epx, eph, epdlogp):\n",
        "  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n",
        "  dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "  dh = np.outer(epdlogp, model['W2'])\n",
        "  dh[eph <= 0] = 0 # backpro prelu\n",
        "  dW1 = np.dot(dh.T, epx)\n",
        "  return {'W1':dW1, 'W2':dW2}\n",
        "\n",
        "def train_model(env, model, total_episodes = 100):\n",
        "  hist = []\n",
        "  observation = env.reset()\n",
        "\n",
        "  prev_x = None # used in computing the difference frame\n",
        "  xs,hs,dlogps,drs = [],[],[],[]\n",
        "  running_reward = None\n",
        "  reward_sum = 0\n",
        "  episode_number = 0\n",
        "\n",
        "  while True:\n",
        "    # preprocess the observation, set input to network to be difference image\n",
        "    cur_x = prepro(observation)\n",
        "    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # forward the policy network and sample an action from the returned probability\n",
        "    aprob, h = policy_forward(x)\n",
        "    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n",
        "\n",
        "    # record various intermediates (needed later for backprop)\n",
        "    xs.append(x) # observation\n",
        "    hs.append(h) # hidden state\n",
        "    y = 1 if action == 2 else 0 # a \"fake label\"\n",
        "    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n",
        "\n",
        "    # step the environment and get new measurements\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    reward_sum += reward\n",
        "\n",
        "    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n",
        "\n",
        "    if done: # an episode finished\n",
        "      episode_number += 1\n",
        "\n",
        "      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n",
        "      epx = np.vstack(xs)\n",
        "      eph = np.vstack(hs)\n",
        "      epdlogp = np.vstack(dlogps)\n",
        "      epr = np.vstack(drs)\n",
        "      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n",
        "\n",
        "      # compute the discounted reward backwards through time\n",
        "      discounted_epr = discount_rewards(epr)\n",
        "      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n",
        "      discounted_epr -= np.mean(discounted_epr)\n",
        "      discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n",
        "      grad = policy_backward(epx, eph, epdlogp)\n",
        "      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n",
        "\n",
        "      # perform rmsprop parameter update every batch_size episodes\n",
        "      if episode_number % batch_size == 0:\n",
        "        for k,v in model.items():\n",
        "          g = grad_buffer[k] # gradient\n",
        "          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n",
        "          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n",
        "\n",
        "      # boring book-keeping\n",
        "      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "      hist.append((episode_number, reward_sum, running_reward))\n",
        "      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n",
        "      reward_sum = 0\n",
        "      observation = env.reset() # reset env\n",
        "      prev_x = None\n",
        "      if episode_number == total_episodes: return hist\n",
        "\n",
        "      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
        "        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6Ka_5Vl9Orm",
        "outputId": "d358b825-fc68-4298-85f5-6046fe1d28e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "%time hist1 = train_model(env, model, total_episodes=3500)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n",
            "resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n",
            "resetting env. episode 3.000000, reward total was -19.000000. running mean: -19.999900\n",
            "resetting env. episode 4.000000, reward total was -20.000000. running mean: -19.999901\n",
            "resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.009902\n",
            "resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.019803\n",
            "resetting env. episode 7.000000, reward total was -19.000000. running mean: -20.009605\n",
            "resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.009509\n",
            "resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.019414\n",
            "resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.029220\n",
            "resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.038927\n",
            "resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.038538\n",
            "resetting env. episode 13.000000, reward total was -19.000000. running mean: -20.028153\n",
            "resetting env. episode 14.000000, reward total was -18.000000. running mean: -20.007871\n",
            "resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.017793\n",
            "resetting env. episode 16.000000, reward total was -20.000000. running mean: -20.017615\n",
            "resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.017438\n",
            "resetting env. episode 18.000000, reward total was -19.000000. running mean: -20.007264\n",
            "resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.017191\n",
            "resetting env. episode 20.000000, reward total was -19.000000. running mean: -20.007020\n",
            "resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.016949\n",
            "resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.016780\n",
            "resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.026612\n",
            "resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.026346\n",
            "resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.036082\n",
            "resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.045722\n",
            "resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.045264\n",
            "resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.044812\n",
            "resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.044364\n",
            "resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.053920\n",
            "resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.053381\n",
            "resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.062847\n",
            "resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.072219\n",
            "resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.081496\n",
            "resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.090681\n",
            "resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.099775\n",
            "resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.108777\n",
            "resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.117689\n",
            "resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.126512\n",
            "resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.125247\n",
            "resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.133995\n",
            "resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.142655\n",
            "resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.151228\n",
            "resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.159716\n",
            "resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.168119\n",
            "resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.166437\n",
            "resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.174773\n",
            "resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.183025\n",
            "resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.191195\n",
            "resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.199283\n",
            "resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.207290\n",
            "resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.195217\n",
            "resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.203265\n",
            "resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.201233\n",
            "resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.209220\n",
            "resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.207128\n",
            "resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.215057\n",
            "resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.222906\n",
            "resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.230677\n",
            "resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.238370\n",
            "resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.245987\n",
            "resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.243527\n",
            "resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.251092\n",
            "resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.258581\n",
            "resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.265995\n",
            "resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.273335\n",
            "resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.280602\n",
            "resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.287796\n",
            "resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.294918\n",
            "resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.301968\n",
            "resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.298949\n",
            "resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.305959\n",
            "resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.312900\n",
            "resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.319771\n",
            "resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.316573\n",
            "resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.323407\n",
            "resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.330173\n",
            "resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.336871\n",
            "resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.343503\n",
            "resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.350068\n",
            "resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.356567\n",
            "resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.363001\n",
            "resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.359371\n",
            "resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.355778\n",
            "resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.362220\n",
            "resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.368598\n",
            "resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.374912\n",
            "resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.371163\n",
            "resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.377451\n",
            "resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.383676\n",
            "resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.389840\n",
            "resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.395941\n",
            "resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.401982\n",
            "resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.397962\n",
            "resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.403982\n",
            "resetting env. episode 96.000000, reward total was -19.000000. running mean: -20.389943\n",
            "resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.396043\n",
            "resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.402083\n",
            "resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.408062\n",
            "resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.403981\n",
            "resetting env. episode 101.000000, reward total was -19.000000. running mean: -20.389941\n",
            "resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.386042\n",
            "resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.382182\n",
            "resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.378360\n",
            "resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.384576\n",
            "resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.380730\n",
            "resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.386923\n",
            "resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.383054\n",
            "resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.379223\n",
            "resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.385431\n",
            "resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.391577\n",
            "resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.397661\n",
            "resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.403684\n",
            "resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.409648\n",
            "resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.415551\n",
            "resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.421396\n",
            "resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.417182\n",
            "resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.423010\n",
            "resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.428780\n",
            "resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.434492\n",
            "resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.440147\n",
            "resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.445746\n",
            "resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.441288\n",
            "resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.446875\n",
            "resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.442406\n",
            "resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.447982\n",
            "resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.443503\n",
            "resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.439068\n",
            "resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.424677\n",
            "resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.420430\n",
            "resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.426226\n",
            "resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.421964\n",
            "resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.417744\n",
            "resetting env. episode 134.000000, reward total was -17.000000. running mean: -20.383566\n",
            "resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.379731\n",
            "resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.385933\n",
            "resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.382074\n",
            "resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.388253\n",
            "resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.384371\n",
            "resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.380527\n",
            "resetting env. episode 141.000000, reward total was -20.000000. running mean: -20.376722\n",
            "resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.382955\n",
            "resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.389125\n",
            "resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.385234\n",
            "resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.391382\n",
            "resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.397468\n",
            "resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.403493\n",
            "resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.399458\n",
            "resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.395464\n",
            "resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.391509\n",
            "resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.397594\n",
            "resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.403618\n",
            "resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.409582\n",
            "resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.415486\n",
            "resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.411331\n",
            "resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.417218\n",
            "resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.423046\n",
            "resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.428815\n",
            "resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.434527\n",
            "resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.440182\n",
            "resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.445780\n",
            "resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.441322\n",
            "resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.446909\n",
            "resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.442440\n",
            "resetting env. episode 165.000000, reward total was -19.000000. running mean: -20.428015\n",
            "resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.423735\n",
            "resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.429498\n",
            "resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.435203\n",
            "resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.440851\n",
            "resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.436442\n",
            "resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.442078\n",
            "resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.447657\n",
            "resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.453181\n",
            "resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.458649\n",
            "resetting env. episode 175.000000, reward total was -18.000000. running mean: -20.434062\n",
            "resetting env. episode 176.000000, reward total was -20.000000. running mean: -20.429722\n",
            "resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.425424\n",
            "resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.431170\n",
            "resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.436858\n",
            "resetting env. episode 180.000000, reward total was -18.000000. running mean: -20.412490\n",
            "resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.418365\n",
            "resetting env. episode 182.000000, reward total was -19.000000. running mean: -20.404181\n",
            "resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.410140\n",
            "resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.416038\n",
            "resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.421878\n",
            "resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.417659\n",
            "resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.413482\n",
            "resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.419348\n",
            "resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.415154\n",
            "resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.421003\n",
            "resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.426793\n",
            "resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.432525\n",
            "resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.428199\n",
            "resetting env. episode 194.000000, reward total was -16.000000. running mean: -20.383917\n",
            "resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.380078\n",
            "resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.386277\n",
            "resetting env. episode 197.000000, reward total was -20.000000. running mean: -20.382415\n",
            "resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.388590\n",
            "resetting env. episode 199.000000, reward total was -19.000000. running mean: -20.374705\n",
            "resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.370958\n",
            "resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.377248\n",
            "resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.383475\n",
            "resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.389641\n",
            "resetting env. episode 204.000000, reward total was -19.000000. running mean: -20.375744\n",
            "resetting env. episode 205.000000, reward total was -18.000000. running mean: -20.351987\n",
            "resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.348467\n",
            "resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.354982\n",
            "resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.351432\n",
            "resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.357918\n",
            "resetting env. episode 210.000000, reward total was -19.000000. running mean: -20.344339\n",
            "resetting env. episode 211.000000, reward total was -19.000000. running mean: -20.330896\n",
            "resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.337587\n",
            "resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.344211\n",
            "resetting env. episode 214.000000, reward total was -19.000000. running mean: -20.330769\n",
            "resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.327461\n",
            "resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.324186\n",
            "resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.320945\n",
            "resetting env. episode 218.000000, reward total was -18.000000. running mean: -20.297735\n",
            "resetting env. episode 219.000000, reward total was -19.000000. running mean: -20.284758\n",
            "resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.291910\n",
            "resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.298991\n",
            "resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.306001\n",
            "resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.302941\n",
            "resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.309912\n",
            "resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.316813\n",
            "resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.313644\n",
            "resetting env. episode 227.000000, reward total was -20.000000. running mean: -20.310508\n",
            "resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.307403\n",
            "resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.314329\n",
            "resetting env. episode 230.000000, reward total was -19.000000. running mean: -20.301186\n",
            "resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.308174\n",
            "resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.305092\n",
            "resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.312041\n",
            "resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.318921\n",
            "resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.325731\n",
            "resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.332474\n",
            "resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.329149\n",
            "resetting env. episode 238.000000, reward total was -18.000000. running mean: -20.305858\n",
            "resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.312799\n",
            "resetting env. episode 240.000000, reward total was -19.000000. running mean: -20.299671\n",
            "resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.296675\n",
            "resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.293708\n",
            "resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.290771\n",
            "resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.297863\n",
            "resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.294884\n",
            "resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.301936\n",
            "resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.298916\n",
            "resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.295927\n",
            "resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.292968\n",
            "resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.290038\n",
            "resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.297138\n",
            "resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.304166\n",
            "resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.311125\n",
            "resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.308013\n",
            "resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.314933\n",
            "resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.321784\n",
            "resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.328566\n",
            "resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.325281\n",
            "resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.332028\n",
            "resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.328707\n",
            "resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.335420\n",
            "resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.342066\n",
            "resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.348646\n",
            "resetting env. episode 264.000000, reward total was -19.000000. running mean: -20.335159\n",
            "resetting env. episode 265.000000, reward total was -18.000000. running mean: -20.311807\n",
            "resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.308689\n",
            "resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.315602\n",
            "resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.322446\n",
            "resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.329222\n",
            "resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.315930\n",
            "resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.322770\n",
            "resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.329543\n",
            "resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.326247\n",
            "resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.332985\n",
            "resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.339655\n",
            "resetting env. episode 276.000000, reward total was -19.000000. running mean: -20.326258\n",
            "resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.332996\n",
            "resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.339666\n",
            "resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.336269\n",
            "resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.342907\n",
            "resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.349478\n",
            "resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.345983\n",
            "resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.342523\n",
            "resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.339098\n",
            "resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.345707\n",
            "resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.352250\n",
            "resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.348727\n",
            "resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.345240\n",
            "resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.351787\n",
            "resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.358270\n",
            "resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.364687\n",
            "resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.361040\n",
            "resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.367430\n",
            "resetting env. episode 294.000000, reward total was -19.000000. running mean: -20.353755\n",
            "resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.360218\n",
            "resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.366616\n",
            "resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.372949\n",
            "resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.379220\n",
            "resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.375428\n",
            "resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.371673\n",
            "resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.367957\n",
            "resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.374277\n",
            "resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.380534\n",
            "resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.386729\n",
            "resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.382862\n",
            "resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.389033\n",
            "resetting env. episode 307.000000, reward total was -18.000000. running mean: -20.365143\n",
            "resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.371491\n",
            "resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.367776\n",
            "resetting env. episode 310.000000, reward total was -19.000000. running mean: -20.354099\n",
            "resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.350558\n",
            "resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.347052\n",
            "resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.343582\n",
            "resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.340146\n",
            "resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.346744\n",
            "resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.343277\n",
            "resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.349844\n",
            "resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.356346\n",
            "resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.352782\n",
            "resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.349254\n",
            "resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.345762\n",
            "resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.352304\n",
            "resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.358781\n",
            "resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.365193\n",
            "resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.371541\n",
            "resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.377826\n",
            "resetting env. episode 327.000000, reward total was -19.000000. running mean: -20.364048\n",
            "resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.370407\n",
            "resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.376703\n",
            "resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.382936\n",
            "resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.389107\n",
            "resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.385216\n",
            "resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.381364\n",
            "resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.377550\n",
            "resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.373774\n",
            "resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.370037\n",
            "resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.366336\n",
            "resetting env. episode 338.000000, reward total was -19.000000. running mean: -20.352673\n",
            "resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.349146\n",
            "resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.355655\n",
            "resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.362098\n",
            "resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.358477\n",
            "resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.354893\n",
            "resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.361344\n",
            "resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.367730\n",
            "resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.374053\n",
            "resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.370312\n",
            "resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.356609\n",
            "resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.353043\n",
            "resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.339513\n",
            "resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.346118\n",
            "resetting env. episode 352.000000, reward total was -19.000000. running mean: -20.332656\n",
            "resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.339330\n",
            "resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.345937\n",
            "resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.352477\n",
            "resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.358952\n",
            "resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.355363\n",
            "resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.361809\n",
            "resetting env. episode 359.000000, reward total was -17.000000. running mean: -20.328191\n",
            "resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.334909\n",
            "resetting env. episode 361.000000, reward total was -19.000000. running mean: -20.321560\n",
            "resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.328345\n",
            "resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.325061\n",
            "resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.321810\n",
            "resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.318592\n",
            "resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.325406\n",
            "resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.332152\n",
            "resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.328831\n",
            "resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.335543\n",
            "resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.342187\n",
            "resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.348765\n",
            "resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.345278\n",
            "resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.351825\n",
            "resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.358307\n",
            "resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.354724\n",
            "resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.351176\n",
            "resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.347665\n",
            "resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.354188\n",
            "resetting env. episode 379.000000, reward total was -18.000000. running mean: -20.330646\n",
            "resetting env. episode 380.000000, reward total was -19.000000. running mean: -20.317340\n",
            "resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.324166\n",
            "resetting env. episode 382.000000, reward total was -18.000000. running mean: -20.300924\n",
            "resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.297915\n",
            "resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.294936\n",
            "resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.301987\n",
            "resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.298967\n",
            "resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.305977\n",
            "resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.312917\n",
            "resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.319788\n",
            "resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.326590\n",
            "resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.333324\n",
            "resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.329991\n",
            "resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.336691\n",
            "resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.333324\n",
            "resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.339991\n",
            "resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.346591\n",
            "resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.343125\n",
            "resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.349694\n",
            "resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.356197\n",
            "resetting env. episode 400.000000, reward total was -18.000000. running mean: -20.332635\n",
            "resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.329309\n",
            "resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.336016\n",
            "resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.332656\n",
            "resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.329329\n",
            "resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.336036\n",
            "resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.332675\n",
            "resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.329349\n",
            "resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.326055\n",
            "resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.332795\n",
            "resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.339467\n",
            "resetting env. episode 411.000000, reward total was -19.000000. running mean: -20.326072\n",
            "resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.332811\n",
            "resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.329483\n",
            "resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.336188\n",
            "resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.342826\n",
            "resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.339398\n",
            "resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.346004\n",
            "resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.342544\n",
            "resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.349119\n",
            "resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.355627\n",
            "resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.362071\n",
            "resetting env. episode 422.000000, reward total was -19.000000. running mean: -20.348450\n",
            "resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.344966\n",
            "resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.341516\n",
            "resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.338101\n",
            "resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.334720\n",
            "resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.341373\n",
            "resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.347959\n",
            "resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.344480\n",
            "resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.341035\n",
            "resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.347624\n",
            "resetting env. episode 432.000000, reward total was -19.000000. running mean: -20.334148\n",
            "resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.330807\n",
            "resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.327499\n",
            "resetting env. episode 435.000000, reward total was -19.000000. running mean: -20.314224\n",
            "resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.321081\n",
            "resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.317871\n",
            "resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.324692\n",
            "resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.331445\n",
            "resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.328131\n",
            "resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.324849\n",
            "resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.321601\n",
            "resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.318385\n",
            "resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.325201\n",
            "resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.321949\n",
            "resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.328729\n",
            "resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.335442\n",
            "resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.342088\n",
            "resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.348667\n",
            "resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.345180\n",
            "resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.351728\n",
            "resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.358211\n",
            "resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.364629\n",
            "resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.370983\n",
            "resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.377273\n",
            "resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.373500\n",
            "resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.369765\n",
            "resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.366067\n",
            "resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.362407\n",
            "resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.368783\n",
            "resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.375095\n",
            "resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.381344\n",
            "resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.387531\n",
            "resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.393655\n",
            "resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.399719\n",
            "resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.405721\n",
            "resetting env. episode 467.000000, reward total was -19.000000. running mean: -20.391664\n",
            "resetting env. episode 468.000000, reward total was -18.000000. running mean: -20.367748\n",
            "resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.374070\n",
            "resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.370329\n",
            "resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.376626\n",
            "resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.382860\n",
            "resetting env. episode 473.000000, reward total was -19.000000. running mean: -20.369031\n",
            "resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.365341\n",
            "resetting env. episode 475.000000, reward total was -19.000000. running mean: -20.351688\n",
            "resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.358171\n",
            "resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.364589\n",
            "resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.360943\n",
            "resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.367334\n",
            "resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.373660\n",
            "resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.379924\n",
            "resetting env. episode 482.000000, reward total was -19.000000. running mean: -20.366124\n",
            "resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.372463\n",
            "resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.378739\n",
            "resetting env. episode 485.000000, reward total was -17.000000. running mean: -20.344951\n",
            "resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.341502\n",
            "resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.348087\n",
            "resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.354606\n",
            "resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.361060\n",
            "resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.367449\n",
            "resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.373775\n",
            "resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.380037\n",
            "resetting env. episode 493.000000, reward total was -19.000000. running mean: -20.366237\n",
            "resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.372574\n",
            "resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.368848\n",
            "resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.375160\n",
            "resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.371408\n",
            "resetting env. episode 498.000000, reward total was -19.000000. running mean: -20.357694\n",
            "resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.364117\n",
            "resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.370476\n",
            "resetting env. episode 501.000000, reward total was -21.000000. running mean: -20.376771\n",
            "resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.383004\n",
            "resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.389174\n",
            "resetting env. episode 504.000000, reward total was -19.000000. running mean: -20.375282\n",
            "resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.381529\n",
            "resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.387714\n",
            "resetting env. episode 507.000000, reward total was -20.000000. running mean: -20.383837\n",
            "resetting env. episode 508.000000, reward total was -21.000000. running mean: -20.389998\n",
            "resetting env. episode 509.000000, reward total was -19.000000. running mean: -20.376098\n",
            "resetting env. episode 510.000000, reward total was -20.000000. running mean: -20.372337\n",
            "resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.378614\n",
            "resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.384828\n",
            "resetting env. episode 513.000000, reward total was -19.000000. running mean: -20.370980\n",
            "resetting env. episode 514.000000, reward total was -20.000000. running mean: -20.367270\n",
            "resetting env. episode 515.000000, reward total was -20.000000. running mean: -20.363597\n",
            "resetting env. episode 516.000000, reward total was -21.000000. running mean: -20.369961\n",
            "resetting env. episode 517.000000, reward total was -19.000000. running mean: -20.356261\n",
            "resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.362699\n",
            "resetting env. episode 519.000000, reward total was -21.000000. running mean: -20.369072\n",
            "resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.375381\n",
            "resetting env. episode 521.000000, reward total was -20.000000. running mean: -20.371627\n",
            "resetting env. episode 522.000000, reward total was -19.000000. running mean: -20.357911\n",
            "resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.364332\n",
            "resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.370689\n",
            "resetting env. episode 525.000000, reward total was -21.000000. running mean: -20.376982\n",
            "resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.383212\n",
            "resetting env. episode 527.000000, reward total was -21.000000. running mean: -20.389380\n",
            "resetting env. episode 528.000000, reward total was -20.000000. running mean: -20.385486\n",
            "resetting env. episode 529.000000, reward total was -21.000000. running mean: -20.391631\n",
            "resetting env. episode 530.000000, reward total was -21.000000. running mean: -20.397715\n",
            "resetting env. episode 531.000000, reward total was -20.000000. running mean: -20.393738\n",
            "resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.399800\n",
            "resetting env. episode 533.000000, reward total was -21.000000. running mean: -20.405802\n",
            "resetting env. episode 534.000000, reward total was -21.000000. running mean: -20.411744\n",
            "resetting env. episode 535.000000, reward total was -21.000000. running mean: -20.417627\n",
            "resetting env. episode 536.000000, reward total was -20.000000. running mean: -20.413451\n",
            "resetting env. episode 537.000000, reward total was -20.000000. running mean: -20.409316\n",
            "resetting env. episode 538.000000, reward total was -21.000000. running mean: -20.415223\n",
            "resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.421071\n",
            "resetting env. episode 540.000000, reward total was -20.000000. running mean: -20.416860\n",
            "resetting env. episode 541.000000, reward total was -18.000000. running mean: -20.392691\n",
            "resetting env. episode 542.000000, reward total was -19.000000. running mean: -20.378764\n",
            "resetting env. episode 543.000000, reward total was -18.000000. running mean: -20.354977\n",
            "resetting env. episode 544.000000, reward total was -20.000000. running mean: -20.351427\n",
            "resetting env. episode 545.000000, reward total was -20.000000. running mean: -20.347913\n",
            "resetting env. episode 546.000000, reward total was -20.000000. running mean: -20.344434\n",
            "resetting env. episode 547.000000, reward total was -20.000000. running mean: -20.340989\n",
            "resetting env. episode 548.000000, reward total was -20.000000. running mean: -20.337579\n",
            "resetting env. episode 549.000000, reward total was -20.000000. running mean: -20.334204\n",
            "resetting env. episode 550.000000, reward total was -20.000000. running mean: -20.330862\n",
            "resetting env. episode 551.000000, reward total was -20.000000. running mean: -20.327553\n",
            "resetting env. episode 552.000000, reward total was -18.000000. running mean: -20.304277\n",
            "resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.311235\n",
            "resetting env. episode 554.000000, reward total was -21.000000. running mean: -20.318122\n",
            "resetting env. episode 555.000000, reward total was -20.000000. running mean: -20.314941\n",
            "resetting env. episode 556.000000, reward total was -20.000000. running mean: -20.311792\n",
            "resetting env. episode 557.000000, reward total was -21.000000. running mean: -20.318674\n",
            "resetting env. episode 558.000000, reward total was -20.000000. running mean: -20.315487\n",
            "resetting env. episode 559.000000, reward total was -20.000000. running mean: -20.312332\n",
            "resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.319209\n",
            "resetting env. episode 561.000000, reward total was -19.000000. running mean: -20.306017\n",
            "resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.312957\n",
            "resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.319827\n",
            "resetting env. episode 564.000000, reward total was -20.000000. running mean: -20.316629\n",
            "resetting env. episode 565.000000, reward total was -21.000000. running mean: -20.323462\n",
            "resetting env. episode 566.000000, reward total was -21.000000. running mean: -20.330228\n",
            "resetting env. episode 567.000000, reward total was -21.000000. running mean: -20.336926\n",
            "resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.343556\n",
            "resetting env. episode 569.000000, reward total was -19.000000. running mean: -20.330121\n",
            "resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.336820\n",
            "resetting env. episode 571.000000, reward total was -21.000000. running mean: -20.343451\n",
            "resetting env. episode 572.000000, reward total was -20.000000. running mean: -20.340017\n",
            "resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.346617\n",
            "resetting env. episode 574.000000, reward total was -20.000000. running mean: -20.343150\n",
            "resetting env. episode 575.000000, reward total was -20.000000. running mean: -20.339719\n",
            "resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.346322\n",
            "resetting env. episode 577.000000, reward total was -20.000000. running mean: -20.342859\n",
            "resetting env. episode 578.000000, reward total was -21.000000. running mean: -20.349430\n",
            "resetting env. episode 579.000000, reward total was -20.000000. running mean: -20.345936\n",
            "resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.352476\n",
            "resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.358952\n",
            "resetting env. episode 582.000000, reward total was -20.000000. running mean: -20.355362\n",
            "resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.361808\n",
            "resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.368190\n",
            "resetting env. episode 585.000000, reward total was -21.000000. running mean: -20.374508\n",
            "resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.380763\n",
            "resetting env. episode 587.000000, reward total was -21.000000. running mean: -20.386956\n",
            "resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.383086\n",
            "resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.389255\n",
            "resetting env. episode 590.000000, reward total was -20.000000. running mean: -20.385363\n",
            "resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.391509\n",
            "resetting env. episode 592.000000, reward total was -20.000000. running mean: -20.387594\n",
            "resetting env. episode 593.000000, reward total was -20.000000. running mean: -20.383718\n",
            "resetting env. episode 594.000000, reward total was -20.000000. running mean: -20.379881\n",
            "resetting env. episode 595.000000, reward total was -20.000000. running mean: -20.376082\n",
            "resetting env. episode 596.000000, reward total was -21.000000. running mean: -20.382321\n",
            "resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.388498\n",
            "resetting env. episode 598.000000, reward total was -19.000000. running mean: -20.374613\n",
            "resetting env. episode 599.000000, reward total was -17.000000. running mean: -20.340867\n",
            "resetting env. episode 600.000000, reward total was -20.000000. running mean: -20.337458\n",
            "resetting env. episode 601.000000, reward total was -20.000000. running mean: -20.334084\n",
            "resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.340743\n",
            "resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.347335\n",
            "resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.353862\n",
            "resetting env. episode 605.000000, reward total was -20.000000. running mean: -20.350323\n",
            "resetting env. episode 606.000000, reward total was -21.000000. running mean: -20.356820\n",
            "resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.363252\n",
            "resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.359620\n",
            "resetting env. episode 609.000000, reward total was -20.000000. running mean: -20.356023\n",
            "resetting env. episode 610.000000, reward total was -21.000000. running mean: -20.362463\n",
            "resetting env. episode 611.000000, reward total was -20.000000. running mean: -20.358838\n",
            "resetting env. episode 612.000000, reward total was -18.000000. running mean: -20.335250\n",
            "resetting env. episode 613.000000, reward total was -21.000000. running mean: -20.341898\n",
            "resetting env. episode 614.000000, reward total was -20.000000. running mean: -20.338479\n",
            "resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.345094\n",
            "resetting env. episode 616.000000, reward total was -20.000000. running mean: -20.341643\n",
            "resetting env. episode 617.000000, reward total was -20.000000. running mean: -20.338226\n",
            "resetting env. episode 618.000000, reward total was -21.000000. running mean: -20.344844\n",
            "resetting env. episode 619.000000, reward total was -19.000000. running mean: -20.331396\n",
            "resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.328082\n",
            "resetting env. episode 621.000000, reward total was -20.000000. running mean: -20.324801\n",
            "resetting env. episode 622.000000, reward total was -20.000000. running mean: -20.321553\n",
            "resetting env. episode 623.000000, reward total was -20.000000. running mean: -20.318337\n",
            "resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.325154\n",
            "resetting env. episode 625.000000, reward total was -21.000000. running mean: -20.331903\n",
            "resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.338583\n",
            "resetting env. episode 627.000000, reward total was -20.000000. running mean: -20.335198\n",
            "resetting env. episode 628.000000, reward total was -21.000000. running mean: -20.341846\n",
            "resetting env. episode 629.000000, reward total was -21.000000. running mean: -20.348427\n",
            "resetting env. episode 630.000000, reward total was -19.000000. running mean: -20.334943\n",
            "resetting env. episode 631.000000, reward total was -19.000000. running mean: -20.321594\n",
            "resetting env. episode 632.000000, reward total was -20.000000. running mean: -20.318378\n",
            "resetting env. episode 633.000000, reward total was -20.000000. running mean: -20.315194\n",
            "resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.312042\n",
            "resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.318921\n",
            "resetting env. episode 636.000000, reward total was -20.000000. running mean: -20.315732\n",
            "resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.322575\n",
            "resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.329349\n",
            "resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.336056\n",
            "resetting env. episode 640.000000, reward total was -20.000000. running mean: -20.332695\n",
            "resetting env. episode 641.000000, reward total was -19.000000. running mean: -20.319368\n",
            "resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.326174\n",
            "resetting env. episode 643.000000, reward total was -20.000000. running mean: -20.322913\n",
            "resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.329684\n",
            "resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.336387\n",
            "resetting env. episode 646.000000, reward total was -20.000000. running mean: -20.333023\n",
            "resetting env. episode 647.000000, reward total was -20.000000. running mean: -20.329693\n",
            "resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.336396\n",
            "resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.343032\n",
            "resetting env. episode 650.000000, reward total was -20.000000. running mean: -20.339601\n",
            "resetting env. episode 651.000000, reward total was -20.000000. running mean: -20.336205\n",
            "resetting env. episode 652.000000, reward total was -20.000000. running mean: -20.332843\n",
            "resetting env. episode 653.000000, reward total was -20.000000. running mean: -20.329515\n",
            "resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.336220\n",
            "resetting env. episode 655.000000, reward total was -21.000000. running mean: -20.342858\n",
            "resetting env. episode 656.000000, reward total was -21.000000. running mean: -20.349429\n",
            "resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.355935\n",
            "resetting env. episode 658.000000, reward total was -20.000000. running mean: -20.352375\n",
            "resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.358852\n",
            "resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.365263\n",
            "resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.371611\n",
            "resetting env. episode 662.000000, reward total was -18.000000. running mean: -20.347894\n",
            "resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.354415\n",
            "resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.360871\n",
            "resetting env. episode 665.000000, reward total was -18.000000. running mean: -20.337263\n",
            "resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.343890\n",
            "resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.350451\n",
            "resetting env. episode 668.000000, reward total was -21.000000. running mean: -20.356947\n",
            "resetting env. episode 669.000000, reward total was -21.000000. running mean: -20.363377\n",
            "resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.369743\n",
            "resetting env. episode 671.000000, reward total was -20.000000. running mean: -20.366046\n",
            "resetting env. episode 672.000000, reward total was -19.000000. running mean: -20.352385\n",
            "resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.358862\n",
            "resetting env. episode 674.000000, reward total was -20.000000. running mean: -20.355273\n",
            "resetting env. episode 675.000000, reward total was -21.000000. running mean: -20.361720\n",
            "resetting env. episode 676.000000, reward total was -20.000000. running mean: -20.358103\n",
            "resetting env. episode 677.000000, reward total was -20.000000. running mean: -20.354522\n",
            "resetting env. episode 678.000000, reward total was -20.000000. running mean: -20.350977\n",
            "resetting env. episode 679.000000, reward total was -20.000000. running mean: -20.347467\n",
            "resetting env. episode 680.000000, reward total was -19.000000. running mean: -20.333992\n",
            "resetting env. episode 681.000000, reward total was -19.000000. running mean: -20.320652\n",
            "resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.327446\n",
            "resetting env. episode 683.000000, reward total was -20.000000. running mean: -20.324171\n",
            "resetting env. episode 684.000000, reward total was -20.000000. running mean: -20.320930\n",
            "resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.327720\n",
            "resetting env. episode 686.000000, reward total was -20.000000. running mean: -20.324443\n",
            "resetting env. episode 687.000000, reward total was -20.000000. running mean: -20.321199\n",
            "resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.317987\n",
            "resetting env. episode 689.000000, reward total was -19.000000. running mean: -20.304807\n",
            "resetting env. episode 690.000000, reward total was -20.000000. running mean: -20.301759\n",
            "resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.308741\n",
            "resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.315654\n",
            "resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.322497\n",
            "resetting env. episode 694.000000, reward total was -21.000000. running mean: -20.329272\n",
            "resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.335980\n",
            "resetting env. episode 696.000000, reward total was -20.000000. running mean: -20.332620\n",
            "resetting env. episode 697.000000, reward total was -20.000000. running mean: -20.329294\n",
            "resetting env. episode 698.000000, reward total was -20.000000. running mean: -20.326001\n",
            "resetting env. episode 699.000000, reward total was -19.000000. running mean: -20.312741\n",
            "resetting env. episode 700.000000, reward total was -20.000000. running mean: -20.309613\n",
            "resetting env. episode 701.000000, reward total was -20.000000. running mean: -20.306517\n",
            "resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.313452\n",
            "resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.320317\n",
            "resetting env. episode 704.000000, reward total was -21.000000. running mean: -20.327114\n",
            "resetting env. episode 705.000000, reward total was -20.000000. running mean: -20.323843\n",
            "resetting env. episode 706.000000, reward total was -19.000000. running mean: -20.310605\n",
            "resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.317499\n",
            "resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.324324\n",
            "resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.331080\n",
            "resetting env. episode 710.000000, reward total was -19.000000. running mean: -20.317770\n",
            "resetting env. episode 711.000000, reward total was -20.000000. running mean: -20.314592\n",
            "resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.321446\n",
            "resetting env. episode 713.000000, reward total was -19.000000. running mean: -20.308232\n",
            "resetting env. episode 714.000000, reward total was -21.000000. running mean: -20.315149\n",
            "resetting env. episode 715.000000, reward total was -19.000000. running mean: -20.301998\n",
            "resetting env. episode 716.000000, reward total was -20.000000. running mean: -20.298978\n",
            "resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.305988\n",
            "resetting env. episode 718.000000, reward total was -21.000000. running mean: -20.312928\n",
            "resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.319799\n",
            "resetting env. episode 720.000000, reward total was -18.000000. running mean: -20.296601\n",
            "resetting env. episode 721.000000, reward total was -20.000000. running mean: -20.293635\n",
            "resetting env. episode 722.000000, reward total was -18.000000. running mean: -20.270698\n",
            "resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.277991\n",
            "resetting env. episode 724.000000, reward total was -19.000000. running mean: -20.265212\n",
            "resetting env. episode 725.000000, reward total was -18.000000. running mean: -20.242559\n",
            "resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.250134\n",
            "resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.257633\n",
            "resetting env. episode 728.000000, reward total was -21.000000. running mean: -20.265056\n",
            "resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.272406\n",
            "resetting env. episode 730.000000, reward total was -21.000000. running mean: -20.279682\n",
            "resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.286885\n",
            "resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.294016\n",
            "resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.301076\n",
            "resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.308065\n",
            "resetting env. episode 735.000000, reward total was -19.000000. running mean: -20.294984\n",
            "resetting env. episode 736.000000, reward total was -19.000000. running mean: -20.282035\n",
            "resetting env. episode 737.000000, reward total was -20.000000. running mean: -20.279214\n",
            "resetting env. episode 738.000000, reward total was -20.000000. running mean: -20.276422\n",
            "resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.273658\n",
            "resetting env. episode 740.000000, reward total was -21.000000. running mean: -20.280921\n",
            "resetting env. episode 741.000000, reward total was -21.000000. running mean: -20.288112\n",
            "resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.295231\n",
            "resetting env. episode 743.000000, reward total was -19.000000. running mean: -20.282279\n",
            "resetting env. episode 744.000000, reward total was -19.000000. running mean: -20.269456\n",
            "resetting env. episode 745.000000, reward total was -20.000000. running mean: -20.266761\n",
            "resetting env. episode 746.000000, reward total was -21.000000. running mean: -20.274094\n",
            "resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.281353\n",
            "resetting env. episode 748.000000, reward total was -18.000000. running mean: -20.258539\n",
            "resetting env. episode 749.000000, reward total was -19.000000. running mean: -20.245954\n",
            "resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.253494\n",
            "resetting env. episode 751.000000, reward total was -20.000000. running mean: -20.250959\n",
            "resetting env. episode 752.000000, reward total was -20.000000. running mean: -20.248450\n",
            "resetting env. episode 753.000000, reward total was -19.000000. running mean: -20.235965\n",
            "resetting env. episode 754.000000, reward total was -21.000000. running mean: -20.243606\n",
            "resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.251169\n",
            "resetting env. episode 756.000000, reward total was -21.000000. running mean: -20.258658\n",
            "resetting env. episode 757.000000, reward total was -20.000000. running mean: -20.256071\n",
            "resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.263511\n",
            "resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.270875\n",
            "resetting env. episode 760.000000, reward total was -20.000000. running mean: -20.268167\n",
            "resetting env. episode 761.000000, reward total was -20.000000. running mean: -20.265485\n",
            "resetting env. episode 762.000000, reward total was -20.000000. running mean: -20.262830\n",
            "resetting env. episode 763.000000, reward total was -21.000000. running mean: -20.270202\n",
            "resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.277500\n",
            "resetting env. episode 765.000000, reward total was -20.000000. running mean: -20.274725\n",
            "resetting env. episode 766.000000, reward total was -21.000000. running mean: -20.281978\n",
            "resetting env. episode 767.000000, reward total was -21.000000. running mean: -20.289158\n",
            "resetting env. episode 768.000000, reward total was -21.000000. running mean: -20.296266\n",
            "resetting env. episode 769.000000, reward total was -21.000000. running mean: -20.303304\n",
            "resetting env. episode 770.000000, reward total was -19.000000. running mean: -20.290271\n",
            "resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.297368\n",
            "resetting env. episode 772.000000, reward total was -20.000000. running mean: -20.294394\n",
            "resetting env. episode 773.000000, reward total was -21.000000. running mean: -20.301450\n",
            "resetting env. episode 774.000000, reward total was -19.000000. running mean: -20.288436\n",
            "resetting env. episode 775.000000, reward total was -17.000000. running mean: -20.255551\n",
            "resetting env. episode 776.000000, reward total was -19.000000. running mean: -20.242996\n",
            "resetting env. episode 777.000000, reward total was -19.000000. running mean: -20.230566\n",
            "resetting env. episode 778.000000, reward total was -20.000000. running mean: -20.228260\n",
            "resetting env. episode 779.000000, reward total was -21.000000. running mean: -20.235978\n",
            "resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.243618\n",
            "resetting env. episode 781.000000, reward total was -21.000000. running mean: -20.251182\n",
            "resetting env. episode 782.000000, reward total was -21.000000. running mean: -20.258670\n",
            "resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.266083\n",
            "resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.273422\n",
            "resetting env. episode 785.000000, reward total was -20.000000. running mean: -20.270688\n",
            "resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.277981\n",
            "resetting env. episode 787.000000, reward total was -20.000000. running mean: -20.275201\n",
            "resetting env. episode 788.000000, reward total was -20.000000. running mean: -20.272449\n",
            "resetting env. episode 789.000000, reward total was -20.000000. running mean: -20.269725\n",
            "resetting env. episode 790.000000, reward total was -20.000000. running mean: -20.267028\n",
            "resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.274357\n",
            "resetting env. episode 792.000000, reward total was -19.000000. running mean: -20.261614\n",
            "resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.268998\n",
            "resetting env. episode 794.000000, reward total was -21.000000. running mean: -20.276308\n",
            "resetting env. episode 795.000000, reward total was -19.000000. running mean: -20.263545\n",
            "resetting env. episode 796.000000, reward total was -21.000000. running mean: -20.270909\n",
            "resetting env. episode 797.000000, reward total was -19.000000. running mean: -20.258200\n",
            "resetting env. episode 798.000000, reward total was -21.000000. running mean: -20.265618\n",
            "resetting env. episode 799.000000, reward total was -19.000000. running mean: -20.252962\n",
            "resetting env. episode 800.000000, reward total was -19.000000. running mean: -20.240432\n",
            "resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.248028\n",
            "resetting env. episode 802.000000, reward total was -21.000000. running mean: -20.255548\n",
            "resetting env. episode 803.000000, reward total was -21.000000. running mean: -20.262992\n",
            "resetting env. episode 804.000000, reward total was -19.000000. running mean: -20.250362\n",
            "resetting env. episode 805.000000, reward total was -21.000000. running mean: -20.257859\n",
            "resetting env. episode 806.000000, reward total was -21.000000. running mean: -20.265280\n",
            "resetting env. episode 807.000000, reward total was -19.000000. running mean: -20.252627\n",
            "resetting env. episode 808.000000, reward total was -21.000000. running mean: -20.260101\n",
            "resetting env. episode 809.000000, reward total was -21.000000. running mean: -20.267500\n",
            "resetting env. episode 810.000000, reward total was -20.000000. running mean: -20.264825\n",
            "resetting env. episode 811.000000, reward total was -21.000000. running mean: -20.272177\n",
            "resetting env. episode 812.000000, reward total was -20.000000. running mean: -20.269455\n",
            "resetting env. episode 813.000000, reward total was -20.000000. running mean: -20.266760\n",
            "resetting env. episode 814.000000, reward total was -20.000000. running mean: -20.264093\n",
            "resetting env. episode 815.000000, reward total was -19.000000. running mean: -20.251452\n",
            "resetting env. episode 816.000000, reward total was -20.000000. running mean: -20.248937\n",
            "resetting env. episode 817.000000, reward total was -21.000000. running mean: -20.256448\n",
            "resetting env. episode 818.000000, reward total was -21.000000. running mean: -20.263883\n",
            "resetting env. episode 819.000000, reward total was -21.000000. running mean: -20.271245\n",
            "resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.278532\n",
            "resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.285747\n",
            "resetting env. episode 822.000000, reward total was -21.000000. running mean: -20.292889\n",
            "resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.299961\n",
            "resetting env. episode 824.000000, reward total was -19.000000. running mean: -20.286961\n",
            "resetting env. episode 825.000000, reward total was -20.000000. running mean: -20.284091\n",
            "resetting env. episode 826.000000, reward total was -21.000000. running mean: -20.291250\n",
            "resetting env. episode 827.000000, reward total was -20.000000. running mean: -20.288338\n",
            "resetting env. episode 828.000000, reward total was -18.000000. running mean: -20.265455\n",
            "resetting env. episode 829.000000, reward total was -18.000000. running mean: -20.242800\n",
            "resetting env. episode 830.000000, reward total was -19.000000. running mean: -20.230372\n",
            "resetting env. episode 831.000000, reward total was -20.000000. running mean: -20.228068\n",
            "resetting env. episode 832.000000, reward total was -20.000000. running mean: -20.225788\n",
            "resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.233530\n",
            "resetting env. episode 834.000000, reward total was -21.000000. running mean: -20.241194\n",
            "resetting env. episode 835.000000, reward total was -21.000000. running mean: -20.248782\n",
            "resetting env. episode 836.000000, reward total was -21.000000. running mean: -20.256295\n",
            "resetting env. episode 837.000000, reward total was -21.000000. running mean: -20.263732\n",
            "resetting env. episode 838.000000, reward total was -21.000000. running mean: -20.271094\n",
            "resetting env. episode 839.000000, reward total was -21.000000. running mean: -20.278383\n",
            "resetting env. episode 840.000000, reward total was -21.000000. running mean: -20.285600\n",
            "resetting env. episode 841.000000, reward total was -20.000000. running mean: -20.282744\n",
            "resetting env. episode 842.000000, reward total was -20.000000. running mean: -20.279916\n",
            "resetting env. episode 843.000000, reward total was -20.000000. running mean: -20.277117\n",
            "resetting env. episode 844.000000, reward total was -21.000000. running mean: -20.284346\n",
            "resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.291502\n",
            "resetting env. episode 846.000000, reward total was -19.000000. running mean: -20.278587\n",
            "resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.285801\n",
            "resetting env. episode 848.000000, reward total was -21.000000. running mean: -20.292943\n",
            "resetting env. episode 849.000000, reward total was -18.000000. running mean: -20.270014\n",
            "resetting env. episode 850.000000, reward total was -20.000000. running mean: -20.267314\n",
            "resetting env. episode 851.000000, reward total was -20.000000. running mean: -20.264641\n",
            "resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.271994\n",
            "resetting env. episode 853.000000, reward total was -19.000000. running mean: -20.259274\n",
            "resetting env. episode 854.000000, reward total was -20.000000. running mean: -20.256682\n",
            "resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.264115\n",
            "resetting env. episode 856.000000, reward total was -20.000000. running mean: -20.261474\n",
            "resetting env. episode 857.000000, reward total was -19.000000. running mean: -20.248859\n",
            "resetting env. episode 858.000000, reward total was -21.000000. running mean: -20.256370\n",
            "resetting env. episode 859.000000, reward total was -20.000000. running mean: -20.253807\n",
            "resetting env. episode 860.000000, reward total was -20.000000. running mean: -20.251269\n",
            "resetting env. episode 861.000000, reward total was -20.000000. running mean: -20.248756\n",
            "resetting env. episode 862.000000, reward total was -21.000000. running mean: -20.256268\n",
            "resetting env. episode 863.000000, reward total was -17.000000. running mean: -20.223706\n",
            "resetting env. episode 864.000000, reward total was -21.000000. running mean: -20.231469\n",
            "resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.239154\n",
            "resetting env. episode 866.000000, reward total was -19.000000. running mean: -20.226762\n",
            "resetting env. episode 867.000000, reward total was -21.000000. running mean: -20.234495\n",
            "resetting env. episode 868.000000, reward total was -20.000000. running mean: -20.232150\n",
            "resetting env. episode 869.000000, reward total was -21.000000. running mean: -20.239828\n",
            "resetting env. episode 870.000000, reward total was -18.000000. running mean: -20.217430\n",
            "resetting env. episode 871.000000, reward total was -21.000000. running mean: -20.225256\n",
            "resetting env. episode 872.000000, reward total was -20.000000. running mean: -20.223003\n",
            "resetting env. episode 873.000000, reward total was -19.000000. running mean: -20.210773\n",
            "resetting env. episode 874.000000, reward total was -21.000000. running mean: -20.218665\n",
            "resetting env. episode 875.000000, reward total was -17.000000. running mean: -20.186479\n",
            "resetting env. episode 876.000000, reward total was -21.000000. running mean: -20.194614\n",
            "resetting env. episode 877.000000, reward total was -19.000000. running mean: -20.182668\n",
            "resetting env. episode 878.000000, reward total was -20.000000. running mean: -20.180841\n",
            "resetting env. episode 879.000000, reward total was -21.000000. running mean: -20.189033\n",
            "resetting env. episode 880.000000, reward total was -21.000000. running mean: -20.197142\n",
            "resetting env. episode 881.000000, reward total was -21.000000. running mean: -20.205171\n",
            "resetting env. episode 882.000000, reward total was -19.000000. running mean: -20.193119\n",
            "resetting env. episode 883.000000, reward total was -21.000000. running mean: -20.201188\n",
            "resetting env. episode 884.000000, reward total was -21.000000. running mean: -20.209176\n",
            "resetting env. episode 885.000000, reward total was -19.000000. running mean: -20.197084\n",
            "resetting env. episode 886.000000, reward total was -20.000000. running mean: -20.195114\n",
            "resetting env. episode 887.000000, reward total was -20.000000. running mean: -20.193162\n",
            "resetting env. episode 888.000000, reward total was -21.000000. running mean: -20.201231\n",
            "resetting env. episode 889.000000, reward total was -20.000000. running mean: -20.199219\n",
            "resetting env. episode 890.000000, reward total was -21.000000. running mean: -20.207226\n",
            "resetting env. episode 891.000000, reward total was -21.000000. running mean: -20.215154\n",
            "resetting env. episode 892.000000, reward total was -21.000000. running mean: -20.223003\n",
            "resetting env. episode 893.000000, reward total was -21.000000. running mean: -20.230773\n",
            "resetting env. episode 894.000000, reward total was -20.000000. running mean: -20.228465\n",
            "resetting env. episode 895.000000, reward total was -21.000000. running mean: -20.236180\n",
            "resetting env. episode 896.000000, reward total was -19.000000. running mean: -20.223818\n",
            "resetting env. episode 897.000000, reward total was -20.000000. running mean: -20.221580\n",
            "resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.229364\n",
            "resetting env. episode 899.000000, reward total was -20.000000. running mean: -20.227071\n",
            "resetting env. episode 900.000000, reward total was -21.000000. running mean: -20.234800\n",
            "resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.242452\n",
            "resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.250027\n",
            "resetting env. episode 903.000000, reward total was -19.000000. running mean: -20.237527\n",
            "resetting env. episode 904.000000, reward total was -19.000000. running mean: -20.225152\n",
            "resetting env. episode 905.000000, reward total was -21.000000. running mean: -20.232900\n",
            "resetting env. episode 906.000000, reward total was -21.000000. running mean: -20.240571\n",
            "resetting env. episode 907.000000, reward total was -21.000000. running mean: -20.248166\n",
            "resetting env. episode 908.000000, reward total was -20.000000. running mean: -20.245684\n",
            "resetting env. episode 909.000000, reward total was -20.000000. running mean: -20.243227\n",
            "resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.250795\n",
            "resetting env. episode 911.000000, reward total was -21.000000. running mean: -20.258287\n",
            "resetting env. episode 912.000000, reward total was -19.000000. running mean: -20.245704\n",
            "resetting env. episode 913.000000, reward total was -19.000000. running mean: -20.233247\n",
            "resetting env. episode 914.000000, reward total was -20.000000. running mean: -20.230915\n",
            "resetting env. episode 915.000000, reward total was -20.000000. running mean: -20.228605\n",
            "resetting env. episode 916.000000, reward total was -21.000000. running mean: -20.236319\n",
            "resetting env. episode 917.000000, reward total was -21.000000. running mean: -20.243956\n",
            "resetting env. episode 918.000000, reward total was -19.000000. running mean: -20.231517\n",
            "resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.239201\n",
            "resetting env. episode 920.000000, reward total was -21.000000. running mean: -20.246809\n",
            "resetting env. episode 921.000000, reward total was -19.000000. running mean: -20.234341\n",
            "resetting env. episode 922.000000, reward total was -21.000000. running mean: -20.241998\n",
            "resetting env. episode 923.000000, reward total was -20.000000. running mean: -20.239578\n",
            "resetting env. episode 924.000000, reward total was -21.000000. running mean: -20.247182\n",
            "resetting env. episode 925.000000, reward total was -19.000000. running mean: -20.234710\n",
            "resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.242363\n",
            "resetting env. episode 927.000000, reward total was -20.000000. running mean: -20.239940\n",
            "resetting env. episode 928.000000, reward total was -19.000000. running mean: -20.227540\n",
            "resetting env. episode 929.000000, reward total was -20.000000. running mean: -20.225265\n",
            "resetting env. episode 930.000000, reward total was -20.000000. running mean: -20.223012\n",
            "resetting env. episode 931.000000, reward total was -21.000000. running mean: -20.230782\n",
            "resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.238474\n",
            "resetting env. episode 933.000000, reward total was -19.000000. running mean: -20.226089\n",
            "resetting env. episode 934.000000, reward total was -21.000000. running mean: -20.233829\n",
            "resetting env. episode 935.000000, reward total was -18.000000. running mean: -20.211490\n",
            "resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.219375\n",
            "resetting env. episode 937.000000, reward total was -21.000000. running mean: -20.227182\n",
            "resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.234910\n",
            "resetting env. episode 939.000000, reward total was -21.000000. running mean: -20.242561\n",
            "resetting env. episode 940.000000, reward total was -20.000000. running mean: -20.240135\n",
            "resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.237734\n",
            "resetting env. episode 942.000000, reward total was -19.000000. running mean: -20.225356\n",
            "resetting env. episode 943.000000, reward total was -19.000000. running mean: -20.213103\n",
            "resetting env. episode 944.000000, reward total was -21.000000. running mean: -20.220972\n",
            "resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.218762\n",
            "resetting env. episode 946.000000, reward total was -19.000000. running mean: -20.206575\n",
            "resetting env. episode 947.000000, reward total was -21.000000. running mean: -20.214509\n",
            "resetting env. episode 948.000000, reward total was -20.000000. running mean: -20.212364\n",
            "resetting env. episode 949.000000, reward total was -20.000000. running mean: -20.210240\n",
            "resetting env. episode 950.000000, reward total was -21.000000. running mean: -20.218138\n",
            "resetting env. episode 951.000000, reward total was -20.000000. running mean: -20.215956\n",
            "resetting env. episode 952.000000, reward total was -20.000000. running mean: -20.213797\n",
            "resetting env. episode 953.000000, reward total was -21.000000. running mean: -20.221659\n",
            "resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.229442\n",
            "resetting env. episode 955.000000, reward total was -21.000000. running mean: -20.237148\n",
            "resetting env. episode 956.000000, reward total was -20.000000. running mean: -20.234776\n",
            "resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.242428\n",
            "resetting env. episode 958.000000, reward total was -20.000000. running mean: -20.240004\n",
            "resetting env. episode 959.000000, reward total was -20.000000. running mean: -20.237604\n",
            "resetting env. episode 960.000000, reward total was -21.000000. running mean: -20.245228\n",
            "resetting env. episode 961.000000, reward total was -20.000000. running mean: -20.242776\n",
            "resetting env. episode 962.000000, reward total was -19.000000. running mean: -20.230348\n",
            "resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.238045\n",
            "resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.245664\n",
            "resetting env. episode 965.000000, reward total was -21.000000. running mean: -20.253208\n",
            "resetting env. episode 966.000000, reward total was -19.000000. running mean: -20.240675\n",
            "resetting env. episode 967.000000, reward total was -20.000000. running mean: -20.238269\n",
            "resetting env. episode 968.000000, reward total was -21.000000. running mean: -20.245886\n",
            "resetting env. episode 969.000000, reward total was -21.000000. running mean: -20.253427\n",
            "resetting env. episode 970.000000, reward total was -21.000000. running mean: -20.260893\n",
            "resetting env. episode 971.000000, reward total was -20.000000. running mean: -20.258284\n",
            "resetting env. episode 972.000000, reward total was -20.000000. running mean: -20.255701\n",
            "resetting env. episode 973.000000, reward total was -20.000000. running mean: -20.253144\n",
            "resetting env. episode 974.000000, reward total was -20.000000. running mean: -20.250613\n",
            "resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.258107\n",
            "resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.265525\n",
            "resetting env. episode 977.000000, reward total was -19.000000. running mean: -20.252870\n",
            "resetting env. episode 978.000000, reward total was -21.000000. running mean: -20.260341\n",
            "resetting env. episode 979.000000, reward total was -21.000000. running mean: -20.267738\n",
            "resetting env. episode 980.000000, reward total was -21.000000. running mean: -20.275061\n",
            "resetting env. episode 981.000000, reward total was -20.000000. running mean: -20.272310\n",
            "resetting env. episode 982.000000, reward total was -20.000000. running mean: -20.269587\n",
            "resetting env. episode 983.000000, reward total was -21.000000. running mean: -20.276891\n",
            "resetting env. episode 984.000000, reward total was -20.000000. running mean: -20.274122\n",
            "resetting env. episode 985.000000, reward total was -21.000000. running mean: -20.281381\n",
            "resetting env. episode 986.000000, reward total was -19.000000. running mean: -20.268567\n",
            "resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.275882\n",
            "resetting env. episode 988.000000, reward total was -19.000000. running mean: -20.263123\n",
            "resetting env. episode 989.000000, reward total was -21.000000. running mean: -20.270491\n",
            "resetting env. episode 990.000000, reward total was -21.000000. running mean: -20.277787\n",
            "resetting env. episode 991.000000, reward total was -21.000000. running mean: -20.285009\n",
            "resetting env. episode 992.000000, reward total was -19.000000. running mean: -20.272159\n",
            "resetting env. episode 993.000000, reward total was -21.000000. running mean: -20.279437\n",
            "resetting env. episode 994.000000, reward total was -20.000000. running mean: -20.276643\n",
            "resetting env. episode 995.000000, reward total was -21.000000. running mean: -20.283876\n",
            "resetting env. episode 996.000000, reward total was -21.000000. running mean: -20.291037\n",
            "resetting env. episode 997.000000, reward total was -19.000000. running mean: -20.278127\n",
            "resetting env. episode 998.000000, reward total was -20.000000. running mean: -20.275346\n",
            "resetting env. episode 999.000000, reward total was -21.000000. running mean: -20.282592\n",
            "resetting env. episode 1000.000000, reward total was -18.000000. running mean: -20.259766\n",
            "resetting env. episode 1001.000000, reward total was -17.000000. running mean: -20.227169\n",
            "resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.234897\n",
            "resetting env. episode 1003.000000, reward total was -16.000000. running mean: -20.192548\n",
            "resetting env. episode 1004.000000, reward total was -20.000000. running mean: -20.190623\n",
            "resetting env. episode 1005.000000, reward total was -19.000000. running mean: -20.178716\n",
            "resetting env. episode 1006.000000, reward total was -21.000000. running mean: -20.186929\n",
            "resetting env. episode 1007.000000, reward total was -20.000000. running mean: -20.185060\n",
            "resetting env. episode 1008.000000, reward total was -18.000000. running mean: -20.163209\n",
            "resetting env. episode 1009.000000, reward total was -21.000000. running mean: -20.171577\n",
            "resetting env. episode 1010.000000, reward total was -20.000000. running mean: -20.169861\n",
            "resetting env. episode 1011.000000, reward total was -20.000000. running mean: -20.168163\n",
            "resetting env. episode 1012.000000, reward total was -20.000000. running mean: -20.166481\n",
            "resetting env. episode 1013.000000, reward total was -21.000000. running mean: -20.174816\n",
            "resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.183068\n",
            "resetting env. episode 1015.000000, reward total was -20.000000. running mean: -20.181238\n",
            "resetting env. episode 1016.000000, reward total was -19.000000. running mean: -20.169425\n",
            "resetting env. episode 1017.000000, reward total was -20.000000. running mean: -20.167731\n",
            "resetting env. episode 1018.000000, reward total was -20.000000. running mean: -20.166054\n",
            "resetting env. episode 1019.000000, reward total was -21.000000. running mean: -20.174393\n",
            "resetting env. episode 1020.000000, reward total was -20.000000. running mean: -20.172649\n",
            "resetting env. episode 1021.000000, reward total was -21.000000. running mean: -20.180923\n",
            "resetting env. episode 1022.000000, reward total was -20.000000. running mean: -20.179113\n",
            "resetting env. episode 1023.000000, reward total was -21.000000. running mean: -20.187322\n",
            "resetting env. episode 1024.000000, reward total was -21.000000. running mean: -20.195449\n",
            "resetting env. episode 1025.000000, reward total was -21.000000. running mean: -20.203495\n",
            "resetting env. episode 1026.000000, reward total was -21.000000. running mean: -20.211460\n",
            "resetting env. episode 1027.000000, reward total was -21.000000. running mean: -20.219345\n",
            "resetting env. episode 1028.000000, reward total was -20.000000. running mean: -20.217152\n",
            "resetting env. episode 1029.000000, reward total was -21.000000. running mean: -20.224980\n",
            "resetting env. episode 1030.000000, reward total was -20.000000. running mean: -20.222730\n",
            "resetting env. episode 1031.000000, reward total was -21.000000. running mean: -20.230503\n",
            "resetting env. episode 1032.000000, reward total was -21.000000. running mean: -20.238198\n",
            "resetting env. episode 1033.000000, reward total was -20.000000. running mean: -20.235816\n",
            "resetting env. episode 1034.000000, reward total was -20.000000. running mean: -20.233458\n",
            "resetting env. episode 1035.000000, reward total was -21.000000. running mean: -20.241123\n",
            "resetting env. episode 1036.000000, reward total was -19.000000. running mean: -20.228712\n",
            "resetting env. episode 1037.000000, reward total was -19.000000. running mean: -20.216425\n",
            "resetting env. episode 1038.000000, reward total was -21.000000. running mean: -20.224261\n",
            "resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.232018\n",
            "resetting env. episode 1040.000000, reward total was -21.000000. running mean: -20.239698\n",
            "resetting env. episode 1041.000000, reward total was -21.000000. running mean: -20.247301\n",
            "resetting env. episode 1042.000000, reward total was -20.000000. running mean: -20.244828\n",
            "resetting env. episode 1043.000000, reward total was -20.000000. running mean: -20.242380\n",
            "resetting env. episode 1044.000000, reward total was -21.000000. running mean: -20.249956\n",
            "resetting env. episode 1045.000000, reward total was -21.000000. running mean: -20.257456\n",
            "resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.264882\n",
            "resetting env. episode 1047.000000, reward total was -21.000000. running mean: -20.272233\n",
            "resetting env. episode 1048.000000, reward total was -21.000000. running mean: -20.279511\n",
            "resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.286715\n",
            "resetting env. episode 1050.000000, reward total was -20.000000. running mean: -20.283848\n",
            "resetting env. episode 1051.000000, reward total was -21.000000. running mean: -20.291010\n",
            "resetting env. episode 1052.000000, reward total was -20.000000. running mean: -20.288100\n",
            "resetting env. episode 1053.000000, reward total was -21.000000. running mean: -20.295219\n",
            "resetting env. episode 1054.000000, reward total was -20.000000. running mean: -20.292267\n",
            "resetting env. episode 1055.000000, reward total was -21.000000. running mean: -20.299344\n",
            "resetting env. episode 1056.000000, reward total was -21.000000. running mean: -20.306350\n",
            "resetting env. episode 1057.000000, reward total was -20.000000. running mean: -20.303287\n",
            "resetting env. episode 1058.000000, reward total was -20.000000. running mean: -20.300254\n",
            "resetting env. episode 1059.000000, reward total was -21.000000. running mean: -20.307251\n",
            "resetting env. episode 1060.000000, reward total was -20.000000. running mean: -20.304179\n",
            "resetting env. episode 1061.000000, reward total was -19.000000. running mean: -20.291137\n",
            "resetting env. episode 1062.000000, reward total was -19.000000. running mean: -20.278226\n",
            "resetting env. episode 1063.000000, reward total was -21.000000. running mean: -20.285444\n",
            "resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.292589\n",
            "resetting env. episode 1065.000000, reward total was -21.000000. running mean: -20.299663\n",
            "resetting env. episode 1066.000000, reward total was -20.000000. running mean: -20.296667\n",
            "resetting env. episode 1067.000000, reward total was -21.000000. running mean: -20.303700\n",
            "resetting env. episode 1068.000000, reward total was -21.000000. running mean: -20.310663\n",
            "resetting env. episode 1069.000000, reward total was -21.000000. running mean: -20.317556\n",
            "resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.324381\n",
            "resetting env. episode 1071.000000, reward total was -19.000000. running mean: -20.311137\n",
            "resetting env. episode 1072.000000, reward total was -19.000000. running mean: -20.298026\n",
            "resetting env. episode 1073.000000, reward total was -20.000000. running mean: -20.295045\n",
            "resetting env. episode 1074.000000, reward total was -20.000000. running mean: -20.292095\n",
            "resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.299174\n",
            "resetting env. episode 1076.000000, reward total was -21.000000. running mean: -20.306182\n",
            "resetting env. episode 1077.000000, reward total was -20.000000. running mean: -20.303120\n",
            "resetting env. episode 1078.000000, reward total was -19.000000. running mean: -20.290089\n",
            "resetting env. episode 1079.000000, reward total was -19.000000. running mean: -20.277188\n",
            "resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.284416\n",
            "resetting env. episode 1081.000000, reward total was -19.000000. running mean: -20.271572\n",
            "resetting env. episode 1082.000000, reward total was -19.000000. running mean: -20.258856\n",
            "resetting env. episode 1083.000000, reward total was -20.000000. running mean: -20.256268\n",
            "resetting env. episode 1084.000000, reward total was -20.000000. running mean: -20.253705\n",
            "resetting env. episode 1085.000000, reward total was -20.000000. running mean: -20.251168\n",
            "resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.258656\n",
            "resetting env. episode 1087.000000, reward total was -21.000000. running mean: -20.266070\n",
            "resetting env. episode 1088.000000, reward total was -20.000000. running mean: -20.263409\n",
            "resetting env. episode 1089.000000, reward total was -21.000000. running mean: -20.270775\n",
            "resetting env. episode 1090.000000, reward total was -21.000000. running mean: -20.278067\n",
            "resetting env. episode 1091.000000, reward total was -21.000000. running mean: -20.285287\n",
            "resetting env. episode 1092.000000, reward total was -21.000000. running mean: -20.292434\n",
            "resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.299510\n",
            "resetting env. episode 1094.000000, reward total was -20.000000. running mean: -20.296514\n",
            "resetting env. episode 1095.000000, reward total was -19.000000. running mean: -20.283549\n",
            "resetting env. episode 1096.000000, reward total was -20.000000. running mean: -20.280714\n",
            "resetting env. episode 1097.000000, reward total was -19.000000. running mean: -20.267907\n",
            "resetting env. episode 1098.000000, reward total was -21.000000. running mean: -20.275228\n",
            "resetting env. episode 1099.000000, reward total was -21.000000. running mean: -20.282475\n",
            "resetting env. episode 1100.000000, reward total was -20.000000. running mean: -20.279651\n",
            "resetting env. episode 1101.000000, reward total was -20.000000. running mean: -20.276854\n",
            "resetting env. episode 1102.000000, reward total was -18.000000. running mean: -20.254086\n",
            "resetting env. episode 1103.000000, reward total was -20.000000. running mean: -20.251545\n",
            "resetting env. episode 1104.000000, reward total was -20.000000. running mean: -20.249029\n",
            "resetting env. episode 1105.000000, reward total was -20.000000. running mean: -20.246539\n",
            "resetting env. episode 1106.000000, reward total was -21.000000. running mean: -20.254074\n",
            "resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.261533\n",
            "resetting env. episode 1108.000000, reward total was -20.000000. running mean: -20.258917\n",
            "resetting env. episode 1109.000000, reward total was -21.000000. running mean: -20.266328\n",
            "resetting env. episode 1110.000000, reward total was -20.000000. running mean: -20.263665\n",
            "resetting env. episode 1111.000000, reward total was -20.000000. running mean: -20.261028\n",
            "resetting env. episode 1112.000000, reward total was -20.000000. running mean: -20.258418\n",
            "resetting env. episode 1113.000000, reward total was -21.000000. running mean: -20.265834\n",
            "resetting env. episode 1114.000000, reward total was -20.000000. running mean: -20.263176\n",
            "resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.270544\n",
            "resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.277838\n",
            "resetting env. episode 1117.000000, reward total was -21.000000. running mean: -20.285060\n",
            "resetting env. episode 1118.000000, reward total was -20.000000. running mean: -20.282209\n",
            "resetting env. episode 1119.000000, reward total was -21.000000. running mean: -20.289387\n",
            "resetting env. episode 1120.000000, reward total was -20.000000. running mean: -20.286493\n",
            "resetting env. episode 1121.000000, reward total was -21.000000. running mean: -20.293628\n",
            "resetting env. episode 1122.000000, reward total was -21.000000. running mean: -20.300692\n",
            "resetting env. episode 1123.000000, reward total was -21.000000. running mean: -20.307685\n",
            "resetting env. episode 1124.000000, reward total was -20.000000. running mean: -20.304608\n",
            "resetting env. episode 1125.000000, reward total was -20.000000. running mean: -20.301562\n",
            "resetting env. episode 1126.000000, reward total was -21.000000. running mean: -20.308547\n",
            "resetting env. episode 1127.000000, reward total was -18.000000. running mean: -20.285461\n",
            "resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.292607\n",
            "resetting env. episode 1129.000000, reward total was -20.000000. running mean: -20.289681\n",
            "resetting env. episode 1130.000000, reward total was -19.000000. running mean: -20.276784\n",
            "resetting env. episode 1131.000000, reward total was -21.000000. running mean: -20.284016\n",
            "resetting env. episode 1132.000000, reward total was -19.000000. running mean: -20.271176\n",
            "resetting env. episode 1133.000000, reward total was -20.000000. running mean: -20.268464\n",
            "resetting env. episode 1134.000000, reward total was -21.000000. running mean: -20.275779\n",
            "resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.283022\n",
            "resetting env. episode 1136.000000, reward total was -21.000000. running mean: -20.290191\n",
            "resetting env. episode 1137.000000, reward total was -19.000000. running mean: -20.277289\n",
            "resetting env. episode 1138.000000, reward total was -21.000000. running mean: -20.284517\n",
            "resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.291671\n",
            "resetting env. episode 1140.000000, reward total was -20.000000. running mean: -20.288755\n",
            "resetting env. episode 1141.000000, reward total was -20.000000. running mean: -20.285867\n",
            "resetting env. episode 1142.000000, reward total was -19.000000. running mean: -20.273008\n",
            "resetting env. episode 1143.000000, reward total was -19.000000. running mean: -20.260278\n",
            "resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.267676\n",
            "resetting env. episode 1145.000000, reward total was -21.000000. running mean: -20.274999\n",
            "resetting env. episode 1146.000000, reward total was -21.000000. running mean: -20.282249\n",
            "resetting env. episode 1147.000000, reward total was -20.000000. running mean: -20.279426\n",
            "resetting env. episode 1148.000000, reward total was -20.000000. running mean: -20.276632\n",
            "resetting env. episode 1149.000000, reward total was -19.000000. running mean: -20.263866\n",
            "resetting env. episode 1150.000000, reward total was -19.000000. running mean: -20.251227\n",
            "resetting env. episode 1151.000000, reward total was -18.000000. running mean: -20.228715\n",
            "resetting env. episode 1152.000000, reward total was -20.000000. running mean: -20.226428\n",
            "resetting env. episode 1153.000000, reward total was -20.000000. running mean: -20.224163\n",
            "resetting env. episode 1154.000000, reward total was -20.000000. running mean: -20.221922\n",
            "resetting env. episode 1155.000000, reward total was -21.000000. running mean: -20.229703\n",
            "resetting env. episode 1156.000000, reward total was -19.000000. running mean: -20.217406\n",
            "resetting env. episode 1157.000000, reward total was -21.000000. running mean: -20.225231\n",
            "resetting env. episode 1158.000000, reward total was -20.000000. running mean: -20.222979\n",
            "resetting env. episode 1159.000000, reward total was -20.000000. running mean: -20.220749\n",
            "resetting env. episode 1160.000000, reward total was -21.000000. running mean: -20.228542\n",
            "resetting env. episode 1161.000000, reward total was -20.000000. running mean: -20.226256\n",
            "resetting env. episode 1162.000000, reward total was -21.000000. running mean: -20.233994\n",
            "resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.241654\n",
            "resetting env. episode 1164.000000, reward total was -21.000000. running mean: -20.249237\n",
            "resetting env. episode 1165.000000, reward total was -20.000000. running mean: -20.246745\n",
            "resetting env. episode 1166.000000, reward total was -20.000000. running mean: -20.244278\n",
            "resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.251835\n",
            "resetting env. episode 1168.000000, reward total was -20.000000. running mean: -20.249316\n",
            "resetting env. episode 1169.000000, reward total was -20.000000. running mean: -20.246823\n",
            "resetting env. episode 1170.000000, reward total was -20.000000. running mean: -20.244355\n",
            "resetting env. episode 1171.000000, reward total was -21.000000. running mean: -20.251912\n",
            "resetting env. episode 1172.000000, reward total was -20.000000. running mean: -20.249392\n",
            "resetting env. episode 1173.000000, reward total was -19.000000. running mean: -20.236898\n",
            "resetting env. episode 1174.000000, reward total was -19.000000. running mean: -20.224529\n",
            "resetting env. episode 1175.000000, reward total was -21.000000. running mean: -20.232284\n",
            "resetting env. episode 1176.000000, reward total was -21.000000. running mean: -20.239961\n",
            "resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.247562\n",
            "resetting env. episode 1178.000000, reward total was -20.000000. running mean: -20.245086\n",
            "resetting env. episode 1179.000000, reward total was -19.000000. running mean: -20.232635\n",
            "resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.240309\n",
            "resetting env. episode 1181.000000, reward total was -20.000000. running mean: -20.237906\n",
            "resetting env. episode 1182.000000, reward total was -21.000000. running mean: -20.245527\n",
            "resetting env. episode 1183.000000, reward total was -20.000000. running mean: -20.243071\n",
            "resetting env. episode 1184.000000, reward total was -20.000000. running mean: -20.240641\n",
            "resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.248234\n",
            "resetting env. episode 1186.000000, reward total was -21.000000. running mean: -20.255752\n",
            "resetting env. episode 1187.000000, reward total was -21.000000. running mean: -20.263195\n",
            "resetting env. episode 1188.000000, reward total was -21.000000. running mean: -20.270563\n",
            "resetting env. episode 1189.000000, reward total was -20.000000. running mean: -20.267857\n",
            "resetting env. episode 1190.000000, reward total was -21.000000. running mean: -20.275178\n",
            "resetting env. episode 1191.000000, reward total was -20.000000. running mean: -20.272427\n",
            "resetting env. episode 1192.000000, reward total was -19.000000. running mean: -20.259702\n",
            "resetting env. episode 1193.000000, reward total was -21.000000. running mean: -20.267105\n",
            "resetting env. episode 1194.000000, reward total was -21.000000. running mean: -20.274434\n",
            "resetting env. episode 1195.000000, reward total was -19.000000. running mean: -20.261690\n",
            "resetting env. episode 1196.000000, reward total was -21.000000. running mean: -20.269073\n",
            "resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.276382\n",
            "resetting env. episode 1198.000000, reward total was -20.000000. running mean: -20.273618\n",
            "resetting env. episode 1199.000000, reward total was -21.000000. running mean: -20.280882\n",
            "resetting env. episode 1200.000000, reward total was -20.000000. running mean: -20.278073\n",
            "resetting env. episode 1201.000000, reward total was -21.000000. running mean: -20.285293\n",
            "resetting env. episode 1202.000000, reward total was -20.000000. running mean: -20.282440\n",
            "resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.289615\n",
            "resetting env. episode 1204.000000, reward total was -21.000000. running mean: -20.296719\n",
            "resetting env. episode 1205.000000, reward total was -19.000000. running mean: -20.283752\n",
            "resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.290915\n",
            "resetting env. episode 1207.000000, reward total was -20.000000. running mean: -20.288005\n",
            "resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.295125\n",
            "resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.302174\n",
            "resetting env. episode 1210.000000, reward total was -21.000000. running mean: -20.309152\n",
            "resetting env. episode 1211.000000, reward total was -20.000000. running mean: -20.306061\n",
            "resetting env. episode 1212.000000, reward total was -20.000000. running mean: -20.303000\n",
            "resetting env. episode 1213.000000, reward total was -20.000000. running mean: -20.299970\n",
            "resetting env. episode 1214.000000, reward total was -21.000000. running mean: -20.306970\n",
            "resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.313901\n",
            "resetting env. episode 1216.000000, reward total was -20.000000. running mean: -20.310762\n",
            "resetting env. episode 1217.000000, reward total was -21.000000. running mean: -20.317654\n",
            "resetting env. episode 1218.000000, reward total was -21.000000. running mean: -20.324478\n",
            "resetting env. episode 1219.000000, reward total was -21.000000. running mean: -20.331233\n",
            "resetting env. episode 1220.000000, reward total was -20.000000. running mean: -20.327921\n",
            "resetting env. episode 1221.000000, reward total was -18.000000. running mean: -20.304641\n",
            "resetting env. episode 1222.000000, reward total was -19.000000. running mean: -20.291595\n",
            "resetting env. episode 1223.000000, reward total was -20.000000. running mean: -20.288679\n",
            "resetting env. episode 1224.000000, reward total was -21.000000. running mean: -20.295792\n",
            "resetting env. episode 1225.000000, reward total was -20.000000. running mean: -20.292834\n",
            "resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.299906\n",
            "resetting env. episode 1227.000000, reward total was -21.000000. running mean: -20.306907\n",
            "resetting env. episode 1228.000000, reward total was -20.000000. running mean: -20.303838\n",
            "resetting env. episode 1229.000000, reward total was -21.000000. running mean: -20.310799\n",
            "resetting env. episode 1230.000000, reward total was -18.000000. running mean: -20.287691\n",
            "resetting env. episode 1231.000000, reward total was -21.000000. running mean: -20.294814\n",
            "resetting env. episode 1232.000000, reward total was -20.000000. running mean: -20.291866\n",
            "resetting env. episode 1233.000000, reward total was -20.000000. running mean: -20.288948\n",
            "resetting env. episode 1234.000000, reward total was -20.000000. running mean: -20.286058\n",
            "resetting env. episode 1235.000000, reward total was -21.000000. running mean: -20.293198\n",
            "resetting env. episode 1236.000000, reward total was -21.000000. running mean: -20.300266\n",
            "resetting env. episode 1237.000000, reward total was -21.000000. running mean: -20.307263\n",
            "resetting env. episode 1238.000000, reward total was -21.000000. running mean: -20.314190\n",
            "resetting env. episode 1239.000000, reward total was -18.000000. running mean: -20.291048\n",
            "resetting env. episode 1240.000000, reward total was -21.000000. running mean: -20.298138\n",
            "resetting env. episode 1241.000000, reward total was -21.000000. running mean: -20.305157\n",
            "resetting env. episode 1242.000000, reward total was -21.000000. running mean: -20.312105\n",
            "resetting env. episode 1243.000000, reward total was -21.000000. running mean: -20.318984\n",
            "resetting env. episode 1244.000000, reward total was -20.000000. running mean: -20.315794\n",
            "resetting env. episode 1245.000000, reward total was -21.000000. running mean: -20.322636\n",
            "resetting env. episode 1246.000000, reward total was -20.000000. running mean: -20.319410\n",
            "resetting env. episode 1247.000000, reward total was -19.000000. running mean: -20.306216\n",
            "resetting env. episode 1248.000000, reward total was -21.000000. running mean: -20.313154\n",
            "resetting env. episode 1249.000000, reward total was -21.000000. running mean: -20.320022\n",
            "resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.326822\n",
            "resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.333554\n",
            "resetting env. episode 1252.000000, reward total was -18.000000. running mean: -20.310218\n",
            "resetting env. episode 1253.000000, reward total was -18.000000. running mean: -20.287116\n",
            "resetting env. episode 1254.000000, reward total was -21.000000. running mean: -20.294245\n",
            "resetting env. episode 1255.000000, reward total was -18.000000. running mean: -20.271302\n",
            "resetting env. episode 1256.000000, reward total was -20.000000. running mean: -20.268589\n",
            "resetting env. episode 1257.000000, reward total was -20.000000. running mean: -20.265903\n",
            "resetting env. episode 1258.000000, reward total was -20.000000. running mean: -20.263244\n",
            "resetting env. episode 1259.000000, reward total was -19.000000. running mean: -20.250612\n",
            "resetting env. episode 1260.000000, reward total was -20.000000. running mean: -20.248106\n",
            "resetting env. episode 1261.000000, reward total was -20.000000. running mean: -20.245625\n",
            "resetting env. episode 1262.000000, reward total was -20.000000. running mean: -20.243168\n",
            "resetting env. episode 1263.000000, reward total was -21.000000. running mean: -20.250737\n",
            "resetting env. episode 1264.000000, reward total was -19.000000. running mean: -20.238229\n",
            "resetting env. episode 1265.000000, reward total was -19.000000. running mean: -20.225847\n",
            "resetting env. episode 1266.000000, reward total was -19.000000. running mean: -20.213589\n",
            "resetting env. episode 1267.000000, reward total was -21.000000. running mean: -20.221453\n",
            "resetting env. episode 1268.000000, reward total was -20.000000. running mean: -20.219238\n",
            "resetting env. episode 1269.000000, reward total was -19.000000. running mean: -20.207046\n",
            "resetting env. episode 1270.000000, reward total was -21.000000. running mean: -20.214975\n",
            "resetting env. episode 1271.000000, reward total was -19.000000. running mean: -20.202826\n",
            "resetting env. episode 1272.000000, reward total was -18.000000. running mean: -20.180797\n",
            "resetting env. episode 1273.000000, reward total was -21.000000. running mean: -20.188989\n",
            "resetting env. episode 1274.000000, reward total was -21.000000. running mean: -20.197100\n",
            "resetting env. episode 1275.000000, reward total was -20.000000. running mean: -20.195129\n",
            "resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.203177\n",
            "resetting env. episode 1277.000000, reward total was -21.000000. running mean: -20.211145\n",
            "resetting env. episode 1278.000000, reward total was -20.000000. running mean: -20.209034\n",
            "resetting env. episode 1279.000000, reward total was -20.000000. running mean: -20.206944\n",
            "resetting env. episode 1280.000000, reward total was -21.000000. running mean: -20.214874\n",
            "resetting env. episode 1281.000000, reward total was -20.000000. running mean: -20.212725\n",
            "resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.220598\n",
            "resetting env. episode 1283.000000, reward total was -21.000000. running mean: -20.228392\n",
            "resetting env. episode 1284.000000, reward total was -20.000000. running mean: -20.226108\n",
            "resetting env. episode 1285.000000, reward total was -19.000000. running mean: -20.213847\n",
            "resetting env. episode 1286.000000, reward total was -20.000000. running mean: -20.211709\n",
            "resetting env. episode 1287.000000, reward total was -20.000000. running mean: -20.209592\n",
            "resetting env. episode 1288.000000, reward total was -18.000000. running mean: -20.187496\n",
            "resetting env. episode 1289.000000, reward total was -21.000000. running mean: -20.195621\n",
            "resetting env. episode 1290.000000, reward total was -20.000000. running mean: -20.193665\n",
            "resetting env. episode 1291.000000, reward total was -20.000000. running mean: -20.191728\n",
            "resetting env. episode 1292.000000, reward total was -19.000000. running mean: -20.179811\n",
            "resetting env. episode 1293.000000, reward total was -19.000000. running mean: -20.168013\n",
            "resetting env. episode 1294.000000, reward total was -21.000000. running mean: -20.176332\n",
            "resetting env. episode 1295.000000, reward total was -19.000000. running mean: -20.164569\n",
            "resetting env. episode 1296.000000, reward total was -20.000000. running mean: -20.162923\n",
            "resetting env. episode 1297.000000, reward total was -19.000000. running mean: -20.151294\n",
            "resetting env. episode 1298.000000, reward total was -20.000000. running mean: -20.149781\n",
            "resetting env. episode 1299.000000, reward total was -20.000000. running mean: -20.148283\n",
            "resetting env. episode 1300.000000, reward total was -20.000000. running mean: -20.146801\n",
            "resetting env. episode 1301.000000, reward total was -20.000000. running mean: -20.145333\n",
            "resetting env. episode 1302.000000, reward total was -20.000000. running mean: -20.143879\n",
            "resetting env. episode 1303.000000, reward total was -20.000000. running mean: -20.142440\n",
            "resetting env. episode 1304.000000, reward total was -20.000000. running mean: -20.141016\n",
            "resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.149606\n",
            "resetting env. episode 1306.000000, reward total was -21.000000. running mean: -20.158110\n",
            "resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.166529\n",
            "resetting env. episode 1308.000000, reward total was -20.000000. running mean: -20.164863\n",
            "resetting env. episode 1309.000000, reward total was -20.000000. running mean: -20.163215\n",
            "resetting env. episode 1310.000000, reward total was -18.000000. running mean: -20.141583\n",
            "resetting env. episode 1311.000000, reward total was -21.000000. running mean: -20.150167\n",
            "resetting env. episode 1312.000000, reward total was -20.000000. running mean: -20.148665\n",
            "resetting env. episode 1313.000000, reward total was -20.000000. running mean: -20.147179\n",
            "resetting env. episode 1314.000000, reward total was -20.000000. running mean: -20.145707\n",
            "resetting env. episode 1315.000000, reward total was -21.000000. running mean: -20.154250\n",
            "resetting env. episode 1316.000000, reward total was -20.000000. running mean: -20.152707\n",
            "resetting env. episode 1317.000000, reward total was -21.000000. running mean: -20.161180\n",
            "resetting env. episode 1318.000000, reward total was -20.000000. running mean: -20.159568\n",
            "resetting env. episode 1319.000000, reward total was -21.000000. running mean: -20.167973\n",
            "resetting env. episode 1320.000000, reward total was -20.000000. running mean: -20.166293\n",
            "resetting env. episode 1321.000000, reward total was -21.000000. running mean: -20.174630\n",
            "resetting env. episode 1322.000000, reward total was -20.000000. running mean: -20.172884\n",
            "resetting env. episode 1323.000000, reward total was -21.000000. running mean: -20.181155\n",
            "resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.189343\n",
            "resetting env. episode 1325.000000, reward total was -18.000000. running mean: -20.167450\n",
            "resetting env. episode 1326.000000, reward total was -20.000000. running mean: -20.165775\n",
            "resetting env. episode 1327.000000, reward total was -21.000000. running mean: -20.174118\n",
            "resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.182376\n",
            "resetting env. episode 1329.000000, reward total was -19.000000. running mean: -20.170553\n",
            "resetting env. episode 1330.000000, reward total was -20.000000. running mean: -20.168847\n",
            "resetting env. episode 1331.000000, reward total was -21.000000. running mean: -20.177159\n",
            "resetting env. episode 1332.000000, reward total was -20.000000. running mean: -20.175387\n",
            "resetting env. episode 1333.000000, reward total was -18.000000. running mean: -20.153633\n",
            "resetting env. episode 1334.000000, reward total was -19.000000. running mean: -20.142097\n",
            "resetting env. episode 1335.000000, reward total was -21.000000. running mean: -20.150676\n",
            "resetting env. episode 1336.000000, reward total was -20.000000. running mean: -20.149169\n",
            "resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.157677\n",
            "resetting env. episode 1338.000000, reward total was -18.000000. running mean: -20.136101\n",
            "resetting env. episode 1339.000000, reward total was -21.000000. running mean: -20.144740\n",
            "resetting env. episode 1340.000000, reward total was -21.000000. running mean: -20.153292\n",
            "resetting env. episode 1341.000000, reward total was -20.000000. running mean: -20.151759\n",
            "resetting env. episode 1342.000000, reward total was -19.000000. running mean: -20.140242\n",
            "resetting env. episode 1343.000000, reward total was -21.000000. running mean: -20.148839\n",
            "resetting env. episode 1344.000000, reward total was -20.000000. running mean: -20.147351\n",
            "resetting env. episode 1345.000000, reward total was -21.000000. running mean: -20.155877\n",
            "resetting env. episode 1346.000000, reward total was -21.000000. running mean: -20.164319\n",
            "resetting env. episode 1347.000000, reward total was -21.000000. running mean: -20.172675\n",
            "resetting env. episode 1348.000000, reward total was -20.000000. running mean: -20.170949\n",
            "resetting env. episode 1349.000000, reward total was -21.000000. running mean: -20.179239\n",
            "resetting env. episode 1350.000000, reward total was -21.000000. running mean: -20.187447\n",
            "resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.195572\n",
            "resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.203617\n",
            "resetting env. episode 1353.000000, reward total was -20.000000. running mean: -20.201580\n",
            "resetting env. episode 1354.000000, reward total was -20.000000. running mean: -20.199565\n",
            "resetting env. episode 1355.000000, reward total was -21.000000. running mean: -20.207569\n",
            "resetting env. episode 1356.000000, reward total was -21.000000. running mean: -20.215493\n",
            "resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.223338\n",
            "resetting env. episode 1358.000000, reward total was -20.000000. running mean: -20.221105\n",
            "resetting env. episode 1359.000000, reward total was -20.000000. running mean: -20.218894\n",
            "resetting env. episode 1360.000000, reward total was -20.000000. running mean: -20.216705\n",
            "resetting env. episode 1361.000000, reward total was -21.000000. running mean: -20.224538\n",
            "resetting env. episode 1362.000000, reward total was -21.000000. running mean: -20.232293\n",
            "resetting env. episode 1363.000000, reward total was -21.000000. running mean: -20.239970\n",
            "resetting env. episode 1364.000000, reward total was -20.000000. running mean: -20.237570\n",
            "resetting env. episode 1365.000000, reward total was -20.000000. running mean: -20.235194\n",
            "resetting env. episode 1366.000000, reward total was -21.000000. running mean: -20.242842\n",
            "resetting env. episode 1367.000000, reward total was -21.000000. running mean: -20.250414\n",
            "resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.257910\n",
            "resetting env. episode 1369.000000, reward total was -21.000000. running mean: -20.265331\n",
            "resetting env. episode 1370.000000, reward total was -19.000000. running mean: -20.252677\n",
            "resetting env. episode 1371.000000, reward total was -21.000000. running mean: -20.260151\n",
            "resetting env. episode 1372.000000, reward total was -20.000000. running mean: -20.257549\n",
            "resetting env. episode 1373.000000, reward total was -19.000000. running mean: -20.244974\n",
            "resetting env. episode 1374.000000, reward total was -18.000000. running mean: -20.222524\n",
            "resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.230299\n",
            "resetting env. episode 1376.000000, reward total was -21.000000. running mean: -20.237996\n",
            "resetting env. episode 1377.000000, reward total was -20.000000. running mean: -20.235616\n",
            "resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.243260\n",
            "resetting env. episode 1379.000000, reward total was -21.000000. running mean: -20.250827\n",
            "resetting env. episode 1380.000000, reward total was -21.000000. running mean: -20.258319\n",
            "resetting env. episode 1381.000000, reward total was -20.000000. running mean: -20.255735\n",
            "resetting env. episode 1382.000000, reward total was -20.000000. running mean: -20.253178\n",
            "resetting env. episode 1383.000000, reward total was -21.000000. running mean: -20.260646\n",
            "resetting env. episode 1384.000000, reward total was -20.000000. running mean: -20.258040\n",
            "resetting env. episode 1385.000000, reward total was -19.000000. running mean: -20.245459\n",
            "resetting env. episode 1386.000000, reward total was -20.000000. running mean: -20.243005\n",
            "resetting env. episode 1387.000000, reward total was -20.000000. running mean: -20.240575\n",
            "resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.248169\n",
            "resetting env. episode 1389.000000, reward total was -20.000000. running mean: -20.245687\n",
            "resetting env. episode 1390.000000, reward total was -19.000000. running mean: -20.233231\n",
            "resetting env. episode 1391.000000, reward total was -19.000000. running mean: -20.220898\n",
            "resetting env. episode 1392.000000, reward total was -21.000000. running mean: -20.228689\n",
            "resetting env. episode 1393.000000, reward total was -20.000000. running mean: -20.226402\n",
            "resetting env. episode 1394.000000, reward total was -19.000000. running mean: -20.214138\n",
            "resetting env. episode 1395.000000, reward total was -19.000000. running mean: -20.201997\n",
            "resetting env. episode 1396.000000, reward total was -20.000000. running mean: -20.199977\n",
            "resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.207977\n",
            "resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.215897\n",
            "resetting env. episode 1399.000000, reward total was -20.000000. running mean: -20.213738\n",
            "resetting env. episode 1400.000000, reward total was -20.000000. running mean: -20.211601\n",
            "resetting env. episode 1401.000000, reward total was -19.000000. running mean: -20.199485\n",
            "resetting env. episode 1402.000000, reward total was -21.000000. running mean: -20.207490\n",
            "resetting env. episode 1403.000000, reward total was -20.000000. running mean: -20.205415\n",
            "resetting env. episode 1404.000000, reward total was -21.000000. running mean: -20.213361\n",
            "resetting env. episode 1405.000000, reward total was -20.000000. running mean: -20.211228\n",
            "resetting env. episode 1406.000000, reward total was -20.000000. running mean: -20.209115\n",
            "resetting env. episode 1407.000000, reward total was -21.000000. running mean: -20.217024\n",
            "resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.224854\n",
            "resetting env. episode 1409.000000, reward total was -21.000000. running mean: -20.232605\n",
            "resetting env. episode 1410.000000, reward total was -20.000000. running mean: -20.230279\n",
            "resetting env. episode 1411.000000, reward total was -20.000000. running mean: -20.227976\n",
            "resetting env. episode 1412.000000, reward total was -21.000000. running mean: -20.235697\n",
            "resetting env. episode 1413.000000, reward total was -21.000000. running mean: -20.243340\n",
            "resetting env. episode 1414.000000, reward total was -21.000000. running mean: -20.250906\n",
            "resetting env. episode 1415.000000, reward total was -20.000000. running mean: -20.248397\n",
            "resetting env. episode 1416.000000, reward total was -21.000000. running mean: -20.255913\n",
            "resetting env. episode 1417.000000, reward total was -21.000000. running mean: -20.263354\n",
            "resetting env. episode 1418.000000, reward total was -21.000000. running mean: -20.270721\n",
            "resetting env. episode 1419.000000, reward total was -21.000000. running mean: -20.278013\n",
            "resetting env. episode 1420.000000, reward total was -21.000000. running mean: -20.285233\n",
            "resetting env. episode 1421.000000, reward total was -21.000000. running mean: -20.292381\n",
            "resetting env. episode 1422.000000, reward total was -19.000000. running mean: -20.279457\n",
            "resetting env. episode 1423.000000, reward total was -17.000000. running mean: -20.246663\n",
            "resetting env. episode 1424.000000, reward total was -20.000000. running mean: -20.244196\n",
            "resetting env. episode 1425.000000, reward total was -20.000000. running mean: -20.241754\n",
            "resetting env. episode 1426.000000, reward total was -21.000000. running mean: -20.249336\n",
            "resetting env. episode 1427.000000, reward total was -20.000000. running mean: -20.246843\n",
            "resetting env. episode 1428.000000, reward total was -18.000000. running mean: -20.224375\n",
            "resetting env. episode 1429.000000, reward total was -20.000000. running mean: -20.222131\n",
            "resetting env. episode 1430.000000, reward total was -20.000000. running mean: -20.219910\n",
            "resetting env. episode 1431.000000, reward total was -19.000000. running mean: -20.207711\n",
            "resetting env. episode 1432.000000, reward total was -21.000000. running mean: -20.215633\n",
            "resetting env. episode 1433.000000, reward total was -21.000000. running mean: -20.223477\n",
            "resetting env. episode 1434.000000, reward total was -21.000000. running mean: -20.231242\n",
            "resetting env. episode 1435.000000, reward total was -20.000000. running mean: -20.228930\n",
            "resetting env. episode 1436.000000, reward total was -21.000000. running mean: -20.236641\n",
            "resetting env. episode 1437.000000, reward total was -20.000000. running mean: -20.234274\n",
            "resetting env. episode 1438.000000, reward total was -16.000000. running mean: -20.191931\n",
            "resetting env. episode 1439.000000, reward total was -20.000000. running mean: -20.190012\n",
            "resetting env. episode 1440.000000, reward total was -20.000000. running mean: -20.188112\n",
            "resetting env. episode 1441.000000, reward total was -19.000000. running mean: -20.176231\n",
            "resetting env. episode 1442.000000, reward total was -21.000000. running mean: -20.184469\n",
            "resetting env. episode 1443.000000, reward total was -19.000000. running mean: -20.172624\n",
            "resetting env. episode 1444.000000, reward total was -20.000000. running mean: -20.170898\n",
            "resetting env. episode 1445.000000, reward total was -21.000000. running mean: -20.179189\n",
            "resetting env. episode 1446.000000, reward total was -20.000000. running mean: -20.177397\n",
            "resetting env. episode 1447.000000, reward total was -21.000000. running mean: -20.185623\n",
            "resetting env. episode 1448.000000, reward total was -21.000000. running mean: -20.193767\n",
            "resetting env. episode 1449.000000, reward total was -20.000000. running mean: -20.191829\n",
            "resetting env. episode 1450.000000, reward total was -21.000000. running mean: -20.199911\n",
            "resetting env. episode 1451.000000, reward total was -18.000000. running mean: -20.177912\n",
            "resetting env. episode 1452.000000, reward total was -19.000000. running mean: -20.166132\n",
            "resetting env. episode 1453.000000, reward total was -21.000000. running mean: -20.174471\n",
            "resetting env. episode 1454.000000, reward total was -20.000000. running mean: -20.172726\n",
            "resetting env. episode 1455.000000, reward total was -20.000000. running mean: -20.170999\n",
            "resetting env. episode 1456.000000, reward total was -20.000000. running mean: -20.169289\n",
            "resetting env. episode 1457.000000, reward total was -20.000000. running mean: -20.167596\n",
            "resetting env. episode 1458.000000, reward total was -21.000000. running mean: -20.175920\n",
            "resetting env. episode 1459.000000, reward total was -21.000000. running mean: -20.184161\n",
            "resetting env. episode 1460.000000, reward total was -21.000000. running mean: -20.192319\n",
            "resetting env. episode 1461.000000, reward total was -20.000000. running mean: -20.190396\n",
            "resetting env. episode 1462.000000, reward total was -19.000000. running mean: -20.178492\n",
            "resetting env. episode 1463.000000, reward total was -21.000000. running mean: -20.186707\n",
            "resetting env. episode 1464.000000, reward total was -21.000000. running mean: -20.194840\n",
            "resetting env. episode 1465.000000, reward total was -21.000000. running mean: -20.202892\n",
            "resetting env. episode 1466.000000, reward total was -21.000000. running mean: -20.210863\n",
            "resetting env. episode 1467.000000, reward total was -21.000000. running mean: -20.218754\n",
            "resetting env. episode 1468.000000, reward total was -21.000000. running mean: -20.226567\n",
            "resetting env. episode 1469.000000, reward total was -19.000000. running mean: -20.214301\n",
            "resetting env. episode 1470.000000, reward total was -20.000000. running mean: -20.212158\n",
            "resetting env. episode 1471.000000, reward total was -21.000000. running mean: -20.220037\n",
            "resetting env. episode 1472.000000, reward total was -21.000000. running mean: -20.227836\n",
            "resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.235558\n",
            "resetting env. episode 1474.000000, reward total was -21.000000. running mean: -20.243202\n",
            "resetting env. episode 1475.000000, reward total was -20.000000. running mean: -20.240770\n",
            "resetting env. episode 1476.000000, reward total was -20.000000. running mean: -20.238363\n",
            "resetting env. episode 1477.000000, reward total was -20.000000. running mean: -20.235979\n",
            "resetting env. episode 1478.000000, reward total was -19.000000. running mean: -20.223619\n",
            "resetting env. episode 1479.000000, reward total was -18.000000. running mean: -20.201383\n",
            "resetting env. episode 1480.000000, reward total was -21.000000. running mean: -20.209369\n",
            "resetting env. episode 1481.000000, reward total was -21.000000. running mean: -20.217275\n",
            "resetting env. episode 1482.000000, reward total was -21.000000. running mean: -20.225103\n",
            "resetting env. episode 1483.000000, reward total was -20.000000. running mean: -20.222852\n",
            "resetting env. episode 1484.000000, reward total was -21.000000. running mean: -20.230623\n",
            "resetting env. episode 1485.000000, reward total was -21.000000. running mean: -20.238317\n",
            "resetting env. episode 1486.000000, reward total was -20.000000. running mean: -20.235934\n",
            "resetting env. episode 1487.000000, reward total was -19.000000. running mean: -20.223574\n",
            "resetting env. episode 1488.000000, reward total was -20.000000. running mean: -20.221339\n",
            "resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.229125\n",
            "resetting env. episode 1490.000000, reward total was -20.000000. running mean: -20.226834\n",
            "resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.234566\n",
            "resetting env. episode 1492.000000, reward total was -20.000000. running mean: -20.232220\n",
            "resetting env. episode 1493.000000, reward total was -20.000000. running mean: -20.229898\n",
            "resetting env. episode 1494.000000, reward total was -21.000000. running mean: -20.237599\n",
            "resetting env. episode 1495.000000, reward total was -21.000000. running mean: -20.245223\n",
            "resetting env. episode 1496.000000, reward total was -21.000000. running mean: -20.252771\n",
            "resetting env. episode 1497.000000, reward total was -19.000000. running mean: -20.240243\n",
            "resetting env. episode 1498.000000, reward total was -21.000000. running mean: -20.247840\n",
            "resetting env. episode 1499.000000, reward total was -20.000000. running mean: -20.245362\n",
            "resetting env. episode 1500.000000, reward total was -21.000000. running mean: -20.252908\n",
            "resetting env. episode 1501.000000, reward total was -19.000000. running mean: -20.240379\n",
            "resetting env. episode 1502.000000, reward total was -21.000000. running mean: -20.247976\n",
            "resetting env. episode 1503.000000, reward total was -21.000000. running mean: -20.255496\n",
            "resetting env. episode 1504.000000, reward total was -20.000000. running mean: -20.252941\n",
            "resetting env. episode 1505.000000, reward total was -20.000000. running mean: -20.250411\n",
            "resetting env. episode 1506.000000, reward total was -21.000000. running mean: -20.257907\n",
            "resetting env. episode 1507.000000, reward total was -20.000000. running mean: -20.255328\n",
            "resetting env. episode 1508.000000, reward total was -21.000000. running mean: -20.262775\n",
            "resetting env. episode 1509.000000, reward total was -21.000000. running mean: -20.270147\n",
            "resetting env. episode 1510.000000, reward total was -18.000000. running mean: -20.247446\n",
            "resetting env. episode 1511.000000, reward total was -18.000000. running mean: -20.224971\n",
            "resetting env. episode 1512.000000, reward total was -20.000000. running mean: -20.222722\n",
            "resetting env. episode 1513.000000, reward total was -21.000000. running mean: -20.230494\n",
            "resetting env. episode 1514.000000, reward total was -19.000000. running mean: -20.218189\n",
            "resetting env. episode 1515.000000, reward total was -19.000000. running mean: -20.206008\n",
            "resetting env. episode 1516.000000, reward total was -21.000000. running mean: -20.213947\n",
            "resetting env. episode 1517.000000, reward total was -19.000000. running mean: -20.201808\n",
            "resetting env. episode 1518.000000, reward total was -21.000000. running mean: -20.209790\n",
            "resetting env. episode 1519.000000, reward total was -21.000000. running mean: -20.217692\n",
            "resetting env. episode 1520.000000, reward total was -20.000000. running mean: -20.215515\n",
            "resetting env. episode 1521.000000, reward total was -20.000000. running mean: -20.213360\n",
            "resetting env. episode 1522.000000, reward total was -20.000000. running mean: -20.211226\n",
            "resetting env. episode 1523.000000, reward total was -20.000000. running mean: -20.209114\n",
            "resetting env. episode 1524.000000, reward total was -21.000000. running mean: -20.217023\n",
            "resetting env. episode 1525.000000, reward total was -21.000000. running mean: -20.224853\n",
            "resetting env. episode 1526.000000, reward total was -20.000000. running mean: -20.222604\n",
            "resetting env. episode 1527.000000, reward total was -20.000000. running mean: -20.220378\n",
            "resetting env. episode 1528.000000, reward total was -21.000000. running mean: -20.228174\n",
            "resetting env. episode 1529.000000, reward total was -21.000000. running mean: -20.235893\n",
            "resetting env. episode 1530.000000, reward total was -19.000000. running mean: -20.223534\n",
            "resetting env. episode 1531.000000, reward total was -21.000000. running mean: -20.231298\n",
            "resetting env. episode 1532.000000, reward total was -21.000000. running mean: -20.238985\n",
            "resetting env. episode 1533.000000, reward total was -20.000000. running mean: -20.236595\n",
            "resetting env. episode 1534.000000, reward total was -18.000000. running mean: -20.214230\n",
            "resetting env. episode 1535.000000, reward total was -19.000000. running mean: -20.202087\n",
            "resetting env. episode 1536.000000, reward total was -19.000000. running mean: -20.190066\n",
            "resetting env. episode 1537.000000, reward total was -20.000000. running mean: -20.188166\n",
            "resetting env. episode 1538.000000, reward total was -21.000000. running mean: -20.196284\n",
            "resetting env. episode 1539.000000, reward total was -19.000000. running mean: -20.184321\n",
            "resetting env. episode 1540.000000, reward total was -20.000000. running mean: -20.182478\n",
            "resetting env. episode 1541.000000, reward total was -21.000000. running mean: -20.190653\n",
            "resetting env. episode 1542.000000, reward total was -20.000000. running mean: -20.188747\n",
            "resetting env. episode 1543.000000, reward total was -21.000000. running mean: -20.196859\n",
            "resetting env. episode 1544.000000, reward total was -21.000000. running mean: -20.204891\n",
            "resetting env. episode 1545.000000, reward total was -20.000000. running mean: -20.202842\n",
            "resetting env. episode 1546.000000, reward total was -21.000000. running mean: -20.210813\n",
            "resetting env. episode 1547.000000, reward total was -21.000000. running mean: -20.218705\n",
            "resetting env. episode 1548.000000, reward total was -18.000000. running mean: -20.196518\n",
            "resetting env. episode 1549.000000, reward total was -20.000000. running mean: -20.194553\n",
            "resetting env. episode 1550.000000, reward total was -19.000000. running mean: -20.182607\n",
            "resetting env. episode 1551.000000, reward total was -18.000000. running mean: -20.160781\n",
            "resetting env. episode 1552.000000, reward total was -21.000000. running mean: -20.169174\n",
            "resetting env. episode 1553.000000, reward total was -21.000000. running mean: -20.177482\n",
            "resetting env. episode 1554.000000, reward total was -21.000000. running mean: -20.185707\n",
            "resetting env. episode 1555.000000, reward total was -19.000000. running mean: -20.173850\n",
            "resetting env. episode 1556.000000, reward total was -19.000000. running mean: -20.162111\n",
            "resetting env. episode 1557.000000, reward total was -18.000000. running mean: -20.140490\n",
            "resetting env. episode 1558.000000, reward total was -19.000000. running mean: -20.129085\n",
            "resetting env. episode 1559.000000, reward total was -20.000000. running mean: -20.127795\n",
            "resetting env. episode 1560.000000, reward total was -21.000000. running mean: -20.136517\n",
            "resetting env. episode 1561.000000, reward total was -21.000000. running mean: -20.145151\n",
            "resetting env. episode 1562.000000, reward total was -20.000000. running mean: -20.143700\n",
            "resetting env. episode 1563.000000, reward total was -21.000000. running mean: -20.152263\n",
            "resetting env. episode 1564.000000, reward total was -21.000000. running mean: -20.160740\n",
            "resetting env. episode 1565.000000, reward total was -21.000000. running mean: -20.169133\n",
            "resetting env. episode 1566.000000, reward total was -20.000000. running mean: -20.167442\n",
            "resetting env. episode 1567.000000, reward total was -20.000000. running mean: -20.165767\n",
            "resetting env. episode 1568.000000, reward total was -19.000000. running mean: -20.154109\n",
            "resetting env. episode 1569.000000, reward total was -18.000000. running mean: -20.132568\n",
            "resetting env. episode 1570.000000, reward total was -20.000000. running mean: -20.131243\n",
            "resetting env. episode 1571.000000, reward total was -20.000000. running mean: -20.129930\n",
            "resetting env. episode 1572.000000, reward total was -21.000000. running mean: -20.138631\n",
            "resetting env. episode 1573.000000, reward total was -20.000000. running mean: -20.137245\n",
            "resetting env. episode 1574.000000, reward total was -21.000000. running mean: -20.145872\n",
            "resetting env. episode 1575.000000, reward total was -20.000000. running mean: -20.144413\n",
            "resetting env. episode 1576.000000, reward total was -20.000000. running mean: -20.142969\n",
            "resetting env. episode 1577.000000, reward total was -21.000000. running mean: -20.151540\n",
            "resetting env. episode 1578.000000, reward total was -19.000000. running mean: -20.140024\n",
            "resetting env. episode 1579.000000, reward total was -21.000000. running mean: -20.148624\n",
            "resetting env. episode 1580.000000, reward total was -20.000000. running mean: -20.147138\n",
            "resetting env. episode 1581.000000, reward total was -20.000000. running mean: -20.145666\n",
            "resetting env. episode 1582.000000, reward total was -19.000000. running mean: -20.134210\n",
            "resetting env. episode 1583.000000, reward total was -19.000000. running mean: -20.122868\n",
            "resetting env. episode 1584.000000, reward total was -20.000000. running mean: -20.121639\n",
            "resetting env. episode 1585.000000, reward total was -19.000000. running mean: -20.110423\n",
            "resetting env. episode 1586.000000, reward total was -20.000000. running mean: -20.109318\n",
            "resetting env. episode 1587.000000, reward total was -21.000000. running mean: -20.118225\n",
            "resetting env. episode 1588.000000, reward total was -20.000000. running mean: -20.117043\n",
            "resetting env. episode 1589.000000, reward total was -20.000000. running mean: -20.115872\n",
            "resetting env. episode 1590.000000, reward total was -21.000000. running mean: -20.124714\n",
            "resetting env. episode 1591.000000, reward total was -21.000000. running mean: -20.133467\n",
            "resetting env. episode 1592.000000, reward total was -20.000000. running mean: -20.132132\n",
            "resetting env. episode 1593.000000, reward total was -20.000000. running mean: -20.130811\n",
            "resetting env. episode 1594.000000, reward total was -19.000000. running mean: -20.119503\n",
            "resetting env. episode 1595.000000, reward total was -21.000000. running mean: -20.128307\n",
            "resetting env. episode 1596.000000, reward total was -19.000000. running mean: -20.117024\n",
            "resetting env. episode 1597.000000, reward total was -20.000000. running mean: -20.115854\n",
            "resetting env. episode 1598.000000, reward total was -21.000000. running mean: -20.124696\n",
            "resetting env. episode 1599.000000, reward total was -19.000000. running mean: -20.113449\n",
            "resetting env. episode 1600.000000, reward total was -21.000000. running mean: -20.122314\n",
            "resetting env. episode 1601.000000, reward total was -21.000000. running mean: -20.131091\n",
            "resetting env. episode 1602.000000, reward total was -20.000000. running mean: -20.129780\n",
            "resetting env. episode 1603.000000, reward total was -19.000000. running mean: -20.118482\n",
            "resetting env. episode 1604.000000, reward total was -21.000000. running mean: -20.127298\n",
            "resetting env. episode 1605.000000, reward total was -20.000000. running mean: -20.126025\n",
            "resetting env. episode 1606.000000, reward total was -20.000000. running mean: -20.124764\n",
            "resetting env. episode 1607.000000, reward total was -20.000000. running mean: -20.123517\n",
            "resetting env. episode 1608.000000, reward total was -20.000000. running mean: -20.122281\n",
            "resetting env. episode 1609.000000, reward total was -20.000000. running mean: -20.121059\n",
            "resetting env. episode 1610.000000, reward total was -20.000000. running mean: -20.119848\n",
            "resetting env. episode 1611.000000, reward total was -20.000000. running mean: -20.118650\n",
            "resetting env. episode 1612.000000, reward total was -18.000000. running mean: -20.097463\n",
            "resetting env. episode 1613.000000, reward total was -21.000000. running mean: -20.106488\n",
            "resetting env. episode 1614.000000, reward total was -19.000000. running mean: -20.095424\n",
            "resetting env. episode 1615.000000, reward total was -20.000000. running mean: -20.094469\n",
            "resetting env. episode 1616.000000, reward total was -21.000000. running mean: -20.103525\n",
            "resetting env. episode 1617.000000, reward total was -18.000000. running mean: -20.082489\n",
            "resetting env. episode 1618.000000, reward total was -21.000000. running mean: -20.091665\n",
            "resetting env. episode 1619.000000, reward total was -21.000000. running mean: -20.100748\n",
            "resetting env. episode 1620.000000, reward total was -18.000000. running mean: -20.079740\n",
            "resetting env. episode 1621.000000, reward total was -20.000000. running mean: -20.078943\n",
            "resetting env. episode 1622.000000, reward total was -20.000000. running mean: -20.078154\n",
            "resetting env. episode 1623.000000, reward total was -21.000000. running mean: -20.087372\n",
            "resetting env. episode 1624.000000, reward total was -21.000000. running mean: -20.096498\n",
            "resetting env. episode 1625.000000, reward total was -21.000000. running mean: -20.105533\n",
            "resetting env. episode 1626.000000, reward total was -20.000000. running mean: -20.104478\n",
            "resetting env. episode 1627.000000, reward total was -21.000000. running mean: -20.113433\n",
            "resetting env. episode 1628.000000, reward total was -21.000000. running mean: -20.122299\n",
            "resetting env. episode 1629.000000, reward total was -19.000000. running mean: -20.111076\n",
            "resetting env. episode 1630.000000, reward total was -20.000000. running mean: -20.109965\n",
            "resetting env. episode 1631.000000, reward total was -20.000000. running mean: -20.108865\n",
            "resetting env. episode 1632.000000, reward total was -21.000000. running mean: -20.117777\n",
            "resetting env. episode 1633.000000, reward total was -21.000000. running mean: -20.126599\n",
            "resetting env. episode 1634.000000, reward total was -21.000000. running mean: -20.135333\n",
            "resetting env. episode 1635.000000, reward total was -18.000000. running mean: -20.113980\n",
            "resetting env. episode 1636.000000, reward total was -21.000000. running mean: -20.122840\n",
            "resetting env. episode 1637.000000, reward total was -20.000000. running mean: -20.121612\n",
            "resetting env. episode 1638.000000, reward total was -20.000000. running mean: -20.120395\n",
            "resetting env. episode 1639.000000, reward total was -20.000000. running mean: -20.119191\n",
            "resetting env. episode 1640.000000, reward total was -21.000000. running mean: -20.128000\n",
            "resetting env. episode 1641.000000, reward total was -21.000000. running mean: -20.136720\n",
            "resetting env. episode 1642.000000, reward total was -20.000000. running mean: -20.135352\n",
            "resetting env. episode 1643.000000, reward total was -21.000000. running mean: -20.143999\n",
            "resetting env. episode 1644.000000, reward total was -20.000000. running mean: -20.142559\n",
            "resetting env. episode 1645.000000, reward total was -20.000000. running mean: -20.141133\n",
            "resetting env. episode 1646.000000, reward total was -21.000000. running mean: -20.149722\n",
            "resetting env. episode 1647.000000, reward total was -20.000000. running mean: -20.148225\n",
            "resetting env. episode 1648.000000, reward total was -20.000000. running mean: -20.146742\n",
            "resetting env. episode 1649.000000, reward total was -21.000000. running mean: -20.155275\n",
            "resetting env. episode 1650.000000, reward total was -20.000000. running mean: -20.153722\n",
            "resetting env. episode 1651.000000, reward total was -19.000000. running mean: -20.142185\n",
            "resetting env. episode 1652.000000, reward total was -21.000000. running mean: -20.150763\n",
            "resetting env. episode 1653.000000, reward total was -21.000000. running mean: -20.159256\n",
            "resetting env. episode 1654.000000, reward total was -21.000000. running mean: -20.167663\n",
            "resetting env. episode 1655.000000, reward total was -21.000000. running mean: -20.175986\n",
            "resetting env. episode 1656.000000, reward total was -21.000000. running mean: -20.184227\n",
            "resetting env. episode 1657.000000, reward total was -20.000000. running mean: -20.182384\n",
            "resetting env. episode 1658.000000, reward total was -18.000000. running mean: -20.160560\n",
            "resetting env. episode 1659.000000, reward total was -21.000000. running mean: -20.168955\n",
            "resetting env. episode 1660.000000, reward total was -21.000000. running mean: -20.177265\n",
            "resetting env. episode 1661.000000, reward total was -21.000000. running mean: -20.185493\n",
            "resetting env. episode 1662.000000, reward total was -21.000000. running mean: -20.193638\n",
            "resetting env. episode 1663.000000, reward total was -21.000000. running mean: -20.201701\n",
            "resetting env. episode 1664.000000, reward total was -21.000000. running mean: -20.209684\n",
            "resetting env. episode 1665.000000, reward total was -21.000000. running mean: -20.217587\n",
            "resetting env. episode 1666.000000, reward total was -19.000000. running mean: -20.205412\n",
            "resetting env. episode 1667.000000, reward total was -21.000000. running mean: -20.213357\n",
            "resetting env. episode 1668.000000, reward total was -19.000000. running mean: -20.201224\n",
            "resetting env. episode 1669.000000, reward total was -21.000000. running mean: -20.209212\n",
            "resetting env. episode 1670.000000, reward total was -20.000000. running mean: -20.207120\n",
            "resetting env. episode 1671.000000, reward total was -21.000000. running mean: -20.215048\n",
            "resetting env. episode 1672.000000, reward total was -21.000000. running mean: -20.222898\n",
            "resetting env. episode 1673.000000, reward total was -20.000000. running mean: -20.220669\n",
            "resetting env. episode 1674.000000, reward total was -21.000000. running mean: -20.228462\n",
            "resetting env. episode 1675.000000, reward total was -20.000000. running mean: -20.226178\n",
            "resetting env. episode 1676.000000, reward total was -21.000000. running mean: -20.233916\n",
            "resetting env. episode 1677.000000, reward total was -21.000000. running mean: -20.241577\n",
            "resetting env. episode 1678.000000, reward total was -21.000000. running mean: -20.249161\n",
            "resetting env. episode 1679.000000, reward total was -21.000000. running mean: -20.256669\n",
            "resetting env. episode 1680.000000, reward total was -21.000000. running mean: -20.264103\n",
            "resetting env. episode 1681.000000, reward total was -20.000000. running mean: -20.261462\n",
            "resetting env. episode 1682.000000, reward total was -20.000000. running mean: -20.258847\n",
            "resetting env. episode 1683.000000, reward total was -21.000000. running mean: -20.266258\n",
            "resetting env. episode 1684.000000, reward total was -21.000000. running mean: -20.273596\n",
            "resetting env. episode 1685.000000, reward total was -21.000000. running mean: -20.280860\n",
            "resetting env. episode 1686.000000, reward total was -20.000000. running mean: -20.278051\n",
            "resetting env. episode 1687.000000, reward total was -21.000000. running mean: -20.285271\n",
            "resetting env. episode 1688.000000, reward total was -21.000000. running mean: -20.292418\n",
            "resetting env. episode 1689.000000, reward total was -20.000000. running mean: -20.289494\n",
            "resetting env. episode 1690.000000, reward total was -20.000000. running mean: -20.286599\n",
            "resetting env. episode 1691.000000, reward total was -21.000000. running mean: -20.293733\n",
            "resetting env. episode 1692.000000, reward total was -20.000000. running mean: -20.290796\n",
            "resetting env. episode 1693.000000, reward total was -19.000000. running mean: -20.277888\n",
            "resetting env. episode 1694.000000, reward total was -21.000000. running mean: -20.285109\n",
            "resetting env. episode 1695.000000, reward total was -21.000000. running mean: -20.292258\n",
            "resetting env. episode 1696.000000, reward total was -19.000000. running mean: -20.279335\n",
            "resetting env. episode 1697.000000, reward total was -17.000000. running mean: -20.246542\n",
            "resetting env. episode 1698.000000, reward total was -21.000000. running mean: -20.254076\n",
            "resetting env. episode 1699.000000, reward total was -21.000000. running mean: -20.261536\n",
            "resetting env. episode 1700.000000, reward total was -21.000000. running mean: -20.268920\n",
            "resetting env. episode 1701.000000, reward total was -21.000000. running mean: -20.276231\n",
            "resetting env. episode 1702.000000, reward total was -21.000000. running mean: -20.283469\n",
            "resetting env. episode 1703.000000, reward total was -21.000000. running mean: -20.290634\n",
            "resetting env. episode 1704.000000, reward total was -20.000000. running mean: -20.287728\n",
            "resetting env. episode 1705.000000, reward total was -20.000000. running mean: -20.284850\n",
            "resetting env. episode 1706.000000, reward total was -21.000000. running mean: -20.292002\n",
            "resetting env. episode 1707.000000, reward total was -20.000000. running mean: -20.289082\n",
            "resetting env. episode 1708.000000, reward total was -20.000000. running mean: -20.286191\n",
            "resetting env. episode 1709.000000, reward total was -19.000000. running mean: -20.273329\n",
            "resetting env. episode 1710.000000, reward total was -21.000000. running mean: -20.280596\n",
            "resetting env. episode 1711.000000, reward total was -21.000000. running mean: -20.287790\n",
            "resetting env. episode 1712.000000, reward total was -20.000000. running mean: -20.284912\n",
            "resetting env. episode 1713.000000, reward total was -21.000000. running mean: -20.292063\n",
            "resetting env. episode 1714.000000, reward total was -21.000000. running mean: -20.299142\n",
            "resetting env. episode 1715.000000, reward total was -20.000000. running mean: -20.296151\n",
            "resetting env. episode 1716.000000, reward total was -18.000000. running mean: -20.273189\n",
            "resetting env. episode 1717.000000, reward total was -20.000000. running mean: -20.270457\n",
            "resetting env. episode 1718.000000, reward total was -20.000000. running mean: -20.267753\n",
            "resetting env. episode 1719.000000, reward total was -19.000000. running mean: -20.255075\n",
            "resetting env. episode 1720.000000, reward total was -21.000000. running mean: -20.262525\n",
            "resetting env. episode 1721.000000, reward total was -21.000000. running mean: -20.269899\n",
            "resetting env. episode 1722.000000, reward total was -21.000000. running mean: -20.277200\n",
            "resetting env. episode 1723.000000, reward total was -19.000000. running mean: -20.264428\n",
            "resetting env. episode 1724.000000, reward total was -19.000000. running mean: -20.251784\n",
            "resetting env. episode 1725.000000, reward total was -19.000000. running mean: -20.239266\n",
            "resetting env. episode 1726.000000, reward total was -20.000000. running mean: -20.236874\n",
            "resetting env. episode 1727.000000, reward total was -20.000000. running mean: -20.234505\n",
            "resetting env. episode 1728.000000, reward total was -18.000000. running mean: -20.212160\n",
            "resetting env. episode 1729.000000, reward total was -19.000000. running mean: -20.200038\n",
            "resetting env. episode 1730.000000, reward total was -19.000000. running mean: -20.188038\n",
            "resetting env. episode 1731.000000, reward total was -21.000000. running mean: -20.196157\n",
            "resetting env. episode 1732.000000, reward total was -21.000000. running mean: -20.204196\n",
            "resetting env. episode 1733.000000, reward total was -21.000000. running mean: -20.212154\n",
            "resetting env. episode 1734.000000, reward total was -21.000000. running mean: -20.220032\n",
            "resetting env. episode 1735.000000, reward total was -20.000000. running mean: -20.217832\n",
            "resetting env. episode 1736.000000, reward total was -20.000000. running mean: -20.215654\n",
            "resetting env. episode 1737.000000, reward total was -20.000000. running mean: -20.213497\n",
            "resetting env. episode 1738.000000, reward total was -20.000000. running mean: -20.211362\n",
            "resetting env. episode 1739.000000, reward total was -21.000000. running mean: -20.219249\n",
            "resetting env. episode 1740.000000, reward total was -20.000000. running mean: -20.217056\n",
            "resetting env. episode 1741.000000, reward total was -20.000000. running mean: -20.214886\n",
            "resetting env. episode 1742.000000, reward total was -21.000000. running mean: -20.222737\n",
            "resetting env. episode 1743.000000, reward total was -21.000000. running mean: -20.230509\n",
            "resetting env. episode 1744.000000, reward total was -21.000000. running mean: -20.238204\n",
            "resetting env. episode 1745.000000, reward total was -20.000000. running mean: -20.235822\n",
            "resetting env. episode 1746.000000, reward total was -20.000000. running mean: -20.233464\n",
            "resetting env. episode 1747.000000, reward total was -20.000000. running mean: -20.231129\n",
            "resetting env. episode 1748.000000, reward total was -21.000000. running mean: -20.238818\n",
            "resetting env. episode 1749.000000, reward total was -18.000000. running mean: -20.216430\n",
            "resetting env. episode 1750.000000, reward total was -21.000000. running mean: -20.224266\n",
            "resetting env. episode 1751.000000, reward total was -20.000000. running mean: -20.222023\n",
            "resetting env. episode 1752.000000, reward total was -20.000000. running mean: -20.219803\n",
            "resetting env. episode 1753.000000, reward total was -19.000000. running mean: -20.207605\n",
            "resetting env. episode 1754.000000, reward total was -21.000000. running mean: -20.215529\n",
            "resetting env. episode 1755.000000, reward total was -21.000000. running mean: -20.223373\n",
            "resetting env. episode 1756.000000, reward total was -21.000000. running mean: -20.231140\n",
            "resetting env. episode 1757.000000, reward total was -20.000000. running mean: -20.228828\n",
            "resetting env. episode 1758.000000, reward total was -21.000000. running mean: -20.236540\n",
            "resetting env. episode 1759.000000, reward total was -21.000000. running mean: -20.244174\n",
            "resetting env. episode 1760.000000, reward total was -20.000000. running mean: -20.241733\n",
            "resetting env. episode 1761.000000, reward total was -21.000000. running mean: -20.249315\n",
            "resetting env. episode 1762.000000, reward total was -21.000000. running mean: -20.256822\n",
            "resetting env. episode 1763.000000, reward total was -19.000000. running mean: -20.244254\n",
            "resetting env. episode 1764.000000, reward total was -20.000000. running mean: -20.241812\n",
            "resetting env. episode 1765.000000, reward total was -21.000000. running mean: -20.249393\n",
            "resetting env. episode 1766.000000, reward total was -20.000000. running mean: -20.246899\n",
            "resetting env. episode 1767.000000, reward total was -21.000000. running mean: -20.254430\n",
            "resetting env. episode 1768.000000, reward total was -21.000000. running mean: -20.261886\n",
            "resetting env. episode 1769.000000, reward total was -20.000000. running mean: -20.259267\n",
            "resetting env. episode 1770.000000, reward total was -20.000000. running mean: -20.256675\n",
            "resetting env. episode 1771.000000, reward total was -21.000000. running mean: -20.264108\n",
            "resetting env. episode 1772.000000, reward total was -17.000000. running mean: -20.231467\n",
            "resetting env. episode 1773.000000, reward total was -20.000000. running mean: -20.229152\n",
            "resetting env. episode 1774.000000, reward total was -21.000000. running mean: -20.236861\n",
            "resetting env. episode 1775.000000, reward total was -21.000000. running mean: -20.244492\n",
            "resetting env. episode 1776.000000, reward total was -20.000000. running mean: -20.242047\n",
            "resetting env. episode 1777.000000, reward total was -21.000000. running mean: -20.249627\n",
            "resetting env. episode 1778.000000, reward total was -18.000000. running mean: -20.227130\n",
            "resetting env. episode 1779.000000, reward total was -20.000000. running mean: -20.224859\n",
            "resetting env. episode 1780.000000, reward total was -19.000000. running mean: -20.212610\n",
            "resetting env. episode 1781.000000, reward total was -21.000000. running mean: -20.220484\n",
            "resetting env. episode 1782.000000, reward total was -20.000000. running mean: -20.218280\n",
            "resetting env. episode 1783.000000, reward total was -19.000000. running mean: -20.206097\n",
            "resetting env. episode 1784.000000, reward total was -21.000000. running mean: -20.214036\n",
            "resetting env. episode 1785.000000, reward total was -21.000000. running mean: -20.221895\n",
            "resetting env. episode 1786.000000, reward total was -21.000000. running mean: -20.229676\n",
            "resetting env. episode 1787.000000, reward total was -21.000000. running mean: -20.237380\n",
            "resetting env. episode 1788.000000, reward total was -21.000000. running mean: -20.245006\n",
            "resetting env. episode 1789.000000, reward total was -20.000000. running mean: -20.242556\n",
            "resetting env. episode 1790.000000, reward total was -19.000000. running mean: -20.230130\n",
            "resetting env. episode 1791.000000, reward total was -21.000000. running mean: -20.237829\n",
            "resetting env. episode 1792.000000, reward total was -21.000000. running mean: -20.245451\n",
            "resetting env. episode 1793.000000, reward total was -20.000000. running mean: -20.242996\n",
            "resetting env. episode 1794.000000, reward total was -21.000000. running mean: -20.250566\n",
            "resetting env. episode 1795.000000, reward total was -20.000000. running mean: -20.248061\n",
            "resetting env. episode 1796.000000, reward total was -21.000000. running mean: -20.255580\n",
            "resetting env. episode 1797.000000, reward total was -20.000000. running mean: -20.253024\n",
            "resetting env. episode 1798.000000, reward total was -20.000000. running mean: -20.250494\n",
            "resetting env. episode 1799.000000, reward total was -21.000000. running mean: -20.257989\n",
            "resetting env. episode 1800.000000, reward total was -21.000000. running mean: -20.265409\n",
            "resetting env. episode 1801.000000, reward total was -20.000000. running mean: -20.262755\n",
            "resetting env. episode 1802.000000, reward total was -21.000000. running mean: -20.270127\n",
            "resetting env. episode 1803.000000, reward total was -20.000000. running mean: -20.267426\n",
            "resetting env. episode 1804.000000, reward total was -21.000000. running mean: -20.274752\n",
            "resetting env. episode 1805.000000, reward total was -21.000000. running mean: -20.282004\n",
            "resetting env. episode 1806.000000, reward total was -21.000000. running mean: -20.289184\n",
            "resetting env. episode 1807.000000, reward total was -21.000000. running mean: -20.296292\n",
            "resetting env. episode 1808.000000, reward total was -21.000000. running mean: -20.303330\n",
            "resetting env. episode 1809.000000, reward total was -21.000000. running mean: -20.310296\n",
            "resetting env. episode 1810.000000, reward total was -21.000000. running mean: -20.317193\n",
            "resetting env. episode 1811.000000, reward total was -20.000000. running mean: -20.314021\n",
            "resetting env. episode 1812.000000, reward total was -21.000000. running mean: -20.320881\n",
            "resetting env. episode 1813.000000, reward total was -19.000000. running mean: -20.307672\n",
            "resetting env. episode 1814.000000, reward total was -20.000000. running mean: -20.304596\n",
            "resetting env. episode 1815.000000, reward total was -21.000000. running mean: -20.311550\n",
            "resetting env. episode 1816.000000, reward total was -21.000000. running mean: -20.318434\n",
            "resetting env. episode 1817.000000, reward total was -20.000000. running mean: -20.315250\n",
            "resetting env. episode 1818.000000, reward total was -21.000000. running mean: -20.322097\n",
            "resetting env. episode 1819.000000, reward total was -18.000000. running mean: -20.298876\n",
            "resetting env. episode 1820.000000, reward total was -18.000000. running mean: -20.275888\n",
            "resetting env. episode 1821.000000, reward total was -21.000000. running mean: -20.283129\n",
            "resetting env. episode 1822.000000, reward total was -20.000000. running mean: -20.280297\n",
            "resetting env. episode 1823.000000, reward total was -18.000000. running mean: -20.257494\n",
            "resetting env. episode 1824.000000, reward total was -20.000000. running mean: -20.254920\n",
            "resetting env. episode 1825.000000, reward total was -20.000000. running mean: -20.252370\n",
            "resetting env. episode 1826.000000, reward total was -21.000000. running mean: -20.259847\n",
            "resetting env. episode 1827.000000, reward total was -21.000000. running mean: -20.267248\n",
            "resetting env. episode 1828.000000, reward total was -21.000000. running mean: -20.274576\n",
            "resetting env. episode 1829.000000, reward total was -21.000000. running mean: -20.281830\n",
            "resetting env. episode 1830.000000, reward total was -20.000000. running mean: -20.279012\n",
            "resetting env. episode 1831.000000, reward total was -20.000000. running mean: -20.276221\n",
            "resetting env. episode 1832.000000, reward total was -20.000000. running mean: -20.273459\n",
            "resetting env. episode 1833.000000, reward total was -20.000000. running mean: -20.270725\n",
            "resetting env. episode 1834.000000, reward total was -20.000000. running mean: -20.268017\n",
            "resetting env. episode 1835.000000, reward total was -19.000000. running mean: -20.255337\n",
            "resetting env. episode 1836.000000, reward total was -20.000000. running mean: -20.252784\n",
            "resetting env. episode 1837.000000, reward total was -21.000000. running mean: -20.260256\n",
            "resetting env. episode 1838.000000, reward total was -21.000000. running mean: -20.267653\n",
            "resetting env. episode 1839.000000, reward total was -20.000000. running mean: -20.264977\n",
            "resetting env. episode 1840.000000, reward total was -20.000000. running mean: -20.262327\n",
            "resetting env. episode 1841.000000, reward total was -21.000000. running mean: -20.269704\n",
            "resetting env. episode 1842.000000, reward total was -19.000000. running mean: -20.257007\n",
            "resetting env. episode 1843.000000, reward total was -20.000000. running mean: -20.254437\n",
            "resetting env. episode 1844.000000, reward total was -20.000000. running mean: -20.251892\n",
            "resetting env. episode 1845.000000, reward total was -21.000000. running mean: -20.259374\n",
            "resetting env. episode 1846.000000, reward total was -20.000000. running mean: -20.256780\n",
            "resetting env. episode 1847.000000, reward total was -20.000000. running mean: -20.254212\n",
            "resetting env. episode 1848.000000, reward total was -20.000000. running mean: -20.251670\n",
            "resetting env. episode 1849.000000, reward total was -21.000000. running mean: -20.259153\n",
            "resetting env. episode 1850.000000, reward total was -21.000000. running mean: -20.266562\n",
            "resetting env. episode 1851.000000, reward total was -19.000000. running mean: -20.253896\n",
            "resetting env. episode 1852.000000, reward total was -21.000000. running mean: -20.261357\n",
            "resetting env. episode 1853.000000, reward total was -21.000000. running mean: -20.268743\n",
            "resetting env. episode 1854.000000, reward total was -21.000000. running mean: -20.276056\n",
            "resetting env. episode 1855.000000, reward total was -19.000000. running mean: -20.263295\n",
            "resetting env. episode 1856.000000, reward total was -19.000000. running mean: -20.250663\n",
            "resetting env. episode 1857.000000, reward total was -19.000000. running mean: -20.238156\n",
            "resetting env. episode 1858.000000, reward total was -20.000000. running mean: -20.235774\n",
            "resetting env. episode 1859.000000, reward total was -21.000000. running mean: -20.243417\n",
            "resetting env. episode 1860.000000, reward total was -20.000000. running mean: -20.240982\n",
            "resetting env. episode 1861.000000, reward total was -21.000000. running mean: -20.248573\n",
            "resetting env. episode 1862.000000, reward total was -21.000000. running mean: -20.256087\n",
            "resetting env. episode 1863.000000, reward total was -21.000000. running mean: -20.263526\n",
            "resetting env. episode 1864.000000, reward total was -21.000000. running mean: -20.270891\n",
            "resetting env. episode 1865.000000, reward total was -20.000000. running mean: -20.268182\n",
            "resetting env. episode 1866.000000, reward total was -20.000000. running mean: -20.265500\n",
            "resetting env. episode 1867.000000, reward total was -20.000000. running mean: -20.262845\n",
            "resetting env. episode 1868.000000, reward total was -19.000000. running mean: -20.250217\n",
            "resetting env. episode 1869.000000, reward total was -19.000000. running mean: -20.237714\n",
            "resetting env. episode 1870.000000, reward total was -19.000000. running mean: -20.225337\n",
            "resetting env. episode 1871.000000, reward total was -20.000000. running mean: -20.223084\n",
            "resetting env. episode 1872.000000, reward total was -20.000000. running mean: -20.220853\n",
            "resetting env. episode 1873.000000, reward total was -20.000000. running mean: -20.218645\n",
            "resetting env. episode 1874.000000, reward total was -21.000000. running mean: -20.226458\n",
            "resetting env. episode 1875.000000, reward total was -21.000000. running mean: -20.234194\n",
            "resetting env. episode 1876.000000, reward total was -19.000000. running mean: -20.221852\n",
            "resetting env. episode 1877.000000, reward total was -19.000000. running mean: -20.209633\n",
            "resetting env. episode 1878.000000, reward total was -20.000000. running mean: -20.207537\n",
            "resetting env. episode 1879.000000, reward total was -20.000000. running mean: -20.205461\n",
            "resetting env. episode 1880.000000, reward total was -21.000000. running mean: -20.213407\n",
            "resetting env. episode 1881.000000, reward total was -19.000000. running mean: -20.201273\n",
            "resetting env. episode 1882.000000, reward total was -21.000000. running mean: -20.209260\n",
            "resetting env. episode 1883.000000, reward total was -21.000000. running mean: -20.217167\n",
            "resetting env. episode 1884.000000, reward total was -21.000000. running mean: -20.224996\n",
            "resetting env. episode 1885.000000, reward total was -20.000000. running mean: -20.222746\n",
            "resetting env. episode 1886.000000, reward total was -18.000000. running mean: -20.200518\n",
            "resetting env. episode 1887.000000, reward total was -21.000000. running mean: -20.208513\n",
            "resetting env. episode 1888.000000, reward total was -21.000000. running mean: -20.216428\n",
            "resetting env. episode 1889.000000, reward total was -21.000000. running mean: -20.224264\n",
            "resetting env. episode 1890.000000, reward total was -21.000000. running mean: -20.232021\n",
            "resetting env. episode 1891.000000, reward total was -21.000000. running mean: -20.239701\n",
            "resetting env. episode 1892.000000, reward total was -19.000000. running mean: -20.227304\n",
            "resetting env. episode 1893.000000, reward total was -21.000000. running mean: -20.235031\n",
            "resetting env. episode 1894.000000, reward total was -20.000000. running mean: -20.232680\n",
            "resetting env. episode 1895.000000, reward total was -21.000000. running mean: -20.240354\n",
            "resetting env. episode 1896.000000, reward total was -19.000000. running mean: -20.227950\n",
            "resetting env. episode 1897.000000, reward total was -21.000000. running mean: -20.235671\n",
            "resetting env. episode 1898.000000, reward total was -20.000000. running mean: -20.233314\n",
            "resetting env. episode 1899.000000, reward total was -21.000000. running mean: -20.240981\n",
            "resetting env. episode 1900.000000, reward total was -21.000000. running mean: -20.248571\n",
            "resetting env. episode 1901.000000, reward total was -18.000000. running mean: -20.226085\n",
            "resetting env. episode 1902.000000, reward total was -21.000000. running mean: -20.233824\n",
            "resetting env. episode 1903.000000, reward total was -21.000000. running mean: -20.241486\n",
            "resetting env. episode 1904.000000, reward total was -20.000000. running mean: -20.239071\n",
            "resetting env. episode 1905.000000, reward total was -21.000000. running mean: -20.246681\n",
            "resetting env. episode 1906.000000, reward total was -21.000000. running mean: -20.254214\n",
            "resetting env. episode 1907.000000, reward total was -21.000000. running mean: -20.261672\n",
            "resetting env. episode 1908.000000, reward total was -20.000000. running mean: -20.259055\n",
            "resetting env. episode 1909.000000, reward total was -21.000000. running mean: -20.266464\n",
            "resetting env. episode 1910.000000, reward total was -20.000000. running mean: -20.263800\n",
            "resetting env. episode 1911.000000, reward total was -21.000000. running mean: -20.271162\n",
            "resetting env. episode 1912.000000, reward total was -21.000000. running mean: -20.278450\n",
            "resetting env. episode 1913.000000, reward total was -20.000000. running mean: -20.275666\n",
            "resetting env. episode 1914.000000, reward total was -21.000000. running mean: -20.282909\n",
            "resetting env. episode 1915.000000, reward total was -21.000000. running mean: -20.290080\n",
            "resetting env. episode 1916.000000, reward total was -21.000000. running mean: -20.297179\n",
            "resetting env. episode 1917.000000, reward total was -19.000000. running mean: -20.284207\n",
            "resetting env. episode 1918.000000, reward total was -21.000000. running mean: -20.291365\n",
            "resetting env. episode 1919.000000, reward total was -20.000000. running mean: -20.288452\n",
            "resetting env. episode 1920.000000, reward total was -19.000000. running mean: -20.275567\n",
            "resetting env. episode 1921.000000, reward total was -21.000000. running mean: -20.282811\n",
            "resetting env. episode 1922.000000, reward total was -20.000000. running mean: -20.279983\n",
            "resetting env. episode 1923.000000, reward total was -20.000000. running mean: -20.277183\n",
            "resetting env. episode 1924.000000, reward total was -21.000000. running mean: -20.284412\n",
            "resetting env. episode 1925.000000, reward total was -18.000000. running mean: -20.261567\n",
            "resetting env. episode 1926.000000, reward total was -21.000000. running mean: -20.268952\n",
            "resetting env. episode 1927.000000, reward total was -21.000000. running mean: -20.276262\n",
            "resetting env. episode 1928.000000, reward total was -20.000000. running mean: -20.273500\n",
            "resetting env. episode 1929.000000, reward total was -19.000000. running mean: -20.260765\n",
            "resetting env. episode 1930.000000, reward total was -21.000000. running mean: -20.268157\n",
            "resetting env. episode 1931.000000, reward total was -20.000000. running mean: -20.265475\n",
            "resetting env. episode 1932.000000, reward total was -20.000000. running mean: -20.262821\n",
            "resetting env. episode 1933.000000, reward total was -20.000000. running mean: -20.260192\n",
            "resetting env. episode 1934.000000, reward total was -21.000000. running mean: -20.267591\n",
            "resetting env. episode 1935.000000, reward total was -20.000000. running mean: -20.264915\n",
            "resetting env. episode 1936.000000, reward total was -20.000000. running mean: -20.262266\n",
            "resetting env. episode 1937.000000, reward total was -20.000000. running mean: -20.259643\n",
            "resetting env. episode 1938.000000, reward total was -20.000000. running mean: -20.257046\n",
            "resetting env. episode 1939.000000, reward total was -21.000000. running mean: -20.264476\n",
            "resetting env. episode 1940.000000, reward total was -20.000000. running mean: -20.261831\n",
            "resetting env. episode 1941.000000, reward total was -21.000000. running mean: -20.269213\n",
            "resetting env. episode 1942.000000, reward total was -20.000000. running mean: -20.266521\n",
            "resetting env. episode 1943.000000, reward total was -21.000000. running mean: -20.273856\n",
            "resetting env. episode 1944.000000, reward total was -21.000000. running mean: -20.281117\n",
            "resetting env. episode 1945.000000, reward total was -21.000000. running mean: -20.288306\n",
            "resetting env. episode 1946.000000, reward total was -21.000000. running mean: -20.295423\n",
            "resetting env. episode 1947.000000, reward total was -20.000000. running mean: -20.292469\n",
            "resetting env. episode 1948.000000, reward total was -18.000000. running mean: -20.269544\n",
            "resetting env. episode 1949.000000, reward total was -21.000000. running mean: -20.276848\n",
            "resetting env. episode 1950.000000, reward total was -19.000000. running mean: -20.264080\n",
            "resetting env. episode 1951.000000, reward total was -21.000000. running mean: -20.271439\n",
            "resetting env. episode 1952.000000, reward total was -19.000000. running mean: -20.258725\n",
            "resetting env. episode 1953.000000, reward total was -19.000000. running mean: -20.246137\n",
            "resetting env. episode 1954.000000, reward total was -21.000000. running mean: -20.253676\n",
            "resetting env. episode 1955.000000, reward total was -21.000000. running mean: -20.261139\n",
            "resetting env. episode 1956.000000, reward total was -21.000000. running mean: -20.268528\n",
            "resetting env. episode 1957.000000, reward total was -19.000000. running mean: -20.255843\n",
            "resetting env. episode 1958.000000, reward total was -21.000000. running mean: -20.263284\n",
            "resetting env. episode 1959.000000, reward total was -21.000000. running mean: -20.270651\n",
            "resetting env. episode 1960.000000, reward total was -20.000000. running mean: -20.267945\n",
            "resetting env. episode 1961.000000, reward total was -21.000000. running mean: -20.275265\n",
            "resetting env. episode 1962.000000, reward total was -21.000000. running mean: -20.282513\n",
            "resetting env. episode 1963.000000, reward total was -21.000000. running mean: -20.289688\n",
            "resetting env. episode 1964.000000, reward total was -21.000000. running mean: -20.296791\n",
            "resetting env. episode 1965.000000, reward total was -18.000000. running mean: -20.273823\n",
            "resetting env. episode 1966.000000, reward total was -20.000000. running mean: -20.271085\n",
            "resetting env. episode 1967.000000, reward total was -20.000000. running mean: -20.268374\n",
            "resetting env. episode 1968.000000, reward total was -19.000000. running mean: -20.255690\n",
            "resetting env. episode 1969.000000, reward total was -19.000000. running mean: -20.243133\n",
            "resetting env. episode 1970.000000, reward total was -21.000000. running mean: -20.250702\n",
            "resetting env. episode 1971.000000, reward total was -19.000000. running mean: -20.238195\n",
            "resetting env. episode 1972.000000, reward total was -21.000000. running mean: -20.245813\n",
            "resetting env. episode 1973.000000, reward total was -21.000000. running mean: -20.253355\n",
            "resetting env. episode 1974.000000, reward total was -20.000000. running mean: -20.250821\n",
            "resetting env. episode 1975.000000, reward total was -18.000000. running mean: -20.228313\n",
            "resetting env. episode 1976.000000, reward total was -21.000000. running mean: -20.236030\n",
            "resetting env. episode 1977.000000, reward total was -20.000000. running mean: -20.233670\n",
            "resetting env. episode 1978.000000, reward total was -20.000000. running mean: -20.231333\n",
            "resetting env. episode 1979.000000, reward total was -21.000000. running mean: -20.239020\n",
            "resetting env. episode 1980.000000, reward total was -19.000000. running mean: -20.226629\n",
            "resetting env. episode 1981.000000, reward total was -20.000000. running mean: -20.224363\n",
            "resetting env. episode 1982.000000, reward total was -20.000000. running mean: -20.222119\n",
            "resetting env. episode 1983.000000, reward total was -21.000000. running mean: -20.229898\n",
            "resetting env. episode 1984.000000, reward total was -21.000000. running mean: -20.237599\n",
            "resetting env. episode 1985.000000, reward total was -21.000000. running mean: -20.245223\n",
            "resetting env. episode 1986.000000, reward total was -20.000000. running mean: -20.242771\n",
            "resetting env. episode 1987.000000, reward total was -20.000000. running mean: -20.240343\n",
            "resetting env. episode 1988.000000, reward total was -19.000000. running mean: -20.227940\n",
            "resetting env. episode 1989.000000, reward total was -21.000000. running mean: -20.235660\n",
            "resetting env. episode 1990.000000, reward total was -21.000000. running mean: -20.243304\n",
            "resetting env. episode 1991.000000, reward total was -19.000000. running mean: -20.230871\n",
            "resetting env. episode 1992.000000, reward total was -19.000000. running mean: -20.218562\n",
            "resetting env. episode 1993.000000, reward total was -19.000000. running mean: -20.206376\n",
            "resetting env. episode 1994.000000, reward total was -21.000000. running mean: -20.214313\n",
            "resetting env. episode 1995.000000, reward total was -20.000000. running mean: -20.212170\n",
            "resetting env. episode 1996.000000, reward total was -20.000000. running mean: -20.210048\n",
            "resetting env. episode 1997.000000, reward total was -21.000000. running mean: -20.217947\n",
            "resetting env. episode 1998.000000, reward total was -19.000000. running mean: -20.205768\n",
            "resetting env. episode 1999.000000, reward total was -19.000000. running mean: -20.193710\n",
            "resetting env. episode 2000.000000, reward total was -18.000000. running mean: -20.171773\n",
            "resetting env. episode 2001.000000, reward total was -21.000000. running mean: -20.180055\n",
            "resetting env. episode 2002.000000, reward total was -20.000000. running mean: -20.178255\n",
            "resetting env. episode 2003.000000, reward total was -21.000000. running mean: -20.186472\n",
            "resetting env. episode 2004.000000, reward total was -20.000000. running mean: -20.184608\n",
            "resetting env. episode 2005.000000, reward total was -21.000000. running mean: -20.192762\n",
            "resetting env. episode 2006.000000, reward total was -19.000000. running mean: -20.180834\n",
            "resetting env. episode 2007.000000, reward total was -21.000000. running mean: -20.189026\n",
            "resetting env. episode 2008.000000, reward total was -21.000000. running mean: -20.197135\n",
            "resetting env. episode 2009.000000, reward total was -20.000000. running mean: -20.195164\n",
            "resetting env. episode 2010.000000, reward total was -18.000000. running mean: -20.173212\n",
            "resetting env. episode 2011.000000, reward total was -21.000000. running mean: -20.181480\n",
            "resetting env. episode 2012.000000, reward total was -20.000000. running mean: -20.179665\n",
            "resetting env. episode 2013.000000, reward total was -20.000000. running mean: -20.177869\n",
            "resetting env. episode 2014.000000, reward total was -20.000000. running mean: -20.176090\n",
            "resetting env. episode 2015.000000, reward total was -20.000000. running mean: -20.174329\n",
            "resetting env. episode 2016.000000, reward total was -20.000000. running mean: -20.172586\n",
            "resetting env. episode 2017.000000, reward total was -21.000000. running mean: -20.180860\n",
            "resetting env. episode 2018.000000, reward total was -21.000000. running mean: -20.189051\n",
            "resetting env. episode 2019.000000, reward total was -20.000000. running mean: -20.187161\n",
            "resetting env. episode 2020.000000, reward total was -19.000000. running mean: -20.175289\n",
            "resetting env. episode 2021.000000, reward total was -21.000000. running mean: -20.183536\n",
            "resetting env. episode 2022.000000, reward total was -21.000000. running mean: -20.191701\n",
            "resetting env. episode 2023.000000, reward total was -21.000000. running mean: -20.199784\n",
            "resetting env. episode 2024.000000, reward total was -20.000000. running mean: -20.197786\n",
            "resetting env. episode 2025.000000, reward total was -21.000000. running mean: -20.205808\n",
            "resetting env. episode 2026.000000, reward total was -19.000000. running mean: -20.193750\n",
            "resetting env. episode 2027.000000, reward total was -20.000000. running mean: -20.191813\n",
            "resetting env. episode 2028.000000, reward total was -21.000000. running mean: -20.199895\n",
            "resetting env. episode 2029.000000, reward total was -21.000000. running mean: -20.207896\n",
            "resetting env. episode 2030.000000, reward total was -20.000000. running mean: -20.205817\n",
            "resetting env. episode 2031.000000, reward total was -20.000000. running mean: -20.203759\n",
            "resetting env. episode 2032.000000, reward total was -19.000000. running mean: -20.191721\n",
            "resetting env. episode 2033.000000, reward total was -21.000000. running mean: -20.199804\n",
            "resetting env. episode 2034.000000, reward total was -21.000000. running mean: -20.207806\n",
            "resetting env. episode 2035.000000, reward total was -21.000000. running mean: -20.215728\n",
            "resetting env. episode 2036.000000, reward total was -20.000000. running mean: -20.213570\n",
            "resetting env. episode 2037.000000, reward total was -18.000000. running mean: -20.191435\n",
            "resetting env. episode 2038.000000, reward total was -21.000000. running mean: -20.199520\n",
            "resetting env. episode 2039.000000, reward total was -19.000000. running mean: -20.187525\n",
            "resetting env. episode 2040.000000, reward total was -21.000000. running mean: -20.195650\n",
            "resetting env. episode 2041.000000, reward total was -21.000000. running mean: -20.203693\n",
            "resetting env. episode 2042.000000, reward total was -21.000000. running mean: -20.211656\n",
            "resetting env. episode 2043.000000, reward total was -21.000000. running mean: -20.219540\n",
            "resetting env. episode 2044.000000, reward total was -20.000000. running mean: -20.217344\n",
            "resetting env. episode 2045.000000, reward total was -21.000000. running mean: -20.225171\n",
            "resetting env. episode 2046.000000, reward total was -20.000000. running mean: -20.222919\n",
            "resetting env. episode 2047.000000, reward total was -20.000000. running mean: -20.220690\n",
            "resetting env. episode 2048.000000, reward total was -19.000000. running mean: -20.208483\n",
            "resetting env. episode 2049.000000, reward total was -20.000000. running mean: -20.206398\n",
            "resetting env. episode 2050.000000, reward total was -21.000000. running mean: -20.214334\n",
            "resetting env. episode 2051.000000, reward total was -19.000000. running mean: -20.202191\n",
            "resetting env. episode 2052.000000, reward total was -21.000000. running mean: -20.210169\n",
            "resetting env. episode 2053.000000, reward total was -21.000000. running mean: -20.218067\n",
            "resetting env. episode 2054.000000, reward total was -20.000000. running mean: -20.215887\n",
            "resetting env. episode 2055.000000, reward total was -19.000000. running mean: -20.203728\n",
            "resetting env. episode 2056.000000, reward total was -21.000000. running mean: -20.211691\n",
            "resetting env. episode 2057.000000, reward total was -21.000000. running mean: -20.219574\n",
            "resetting env. episode 2058.000000, reward total was -21.000000. running mean: -20.227378\n",
            "resetting env. episode 2059.000000, reward total was -20.000000. running mean: -20.225104\n",
            "resetting env. episode 2060.000000, reward total was -21.000000. running mean: -20.232853\n",
            "resetting env. episode 2061.000000, reward total was -21.000000. running mean: -20.240525\n",
            "resetting env. episode 2062.000000, reward total was -21.000000. running mean: -20.248119\n",
            "resetting env. episode 2063.000000, reward total was -20.000000. running mean: -20.245638\n",
            "resetting env. episode 2064.000000, reward total was -20.000000. running mean: -20.243182\n",
            "resetting env. episode 2065.000000, reward total was -21.000000. running mean: -20.250750\n",
            "resetting env. episode 2066.000000, reward total was -21.000000. running mean: -20.258243\n",
            "resetting env. episode 2067.000000, reward total was -20.000000. running mean: -20.255660\n",
            "resetting env. episode 2068.000000, reward total was -17.000000. running mean: -20.223103\n",
            "resetting env. episode 2069.000000, reward total was -21.000000. running mean: -20.230872\n",
            "resetting env. episode 2070.000000, reward total was -20.000000. running mean: -20.228564\n",
            "resetting env. episode 2071.000000, reward total was -19.000000. running mean: -20.216278\n",
            "resetting env. episode 2072.000000, reward total was -20.000000. running mean: -20.214115\n",
            "resetting env. episode 2073.000000, reward total was -20.000000. running mean: -20.211974\n",
            "resetting env. episode 2074.000000, reward total was -21.000000. running mean: -20.219854\n",
            "resetting env. episode 2075.000000, reward total was -21.000000. running mean: -20.227656\n",
            "resetting env. episode 2076.000000, reward total was -19.000000. running mean: -20.215379\n",
            "resetting env. episode 2077.000000, reward total was -21.000000. running mean: -20.223226\n",
            "resetting env. episode 2078.000000, reward total was -21.000000. running mean: -20.230993\n",
            "resetting env. episode 2079.000000, reward total was -20.000000. running mean: -20.228683\n",
            "resetting env. episode 2080.000000, reward total was -21.000000. running mean: -20.236396\n",
            "resetting env. episode 2081.000000, reward total was -20.000000. running mean: -20.234033\n",
            "resetting env. episode 2082.000000, reward total was -21.000000. running mean: -20.241692\n",
            "resetting env. episode 2083.000000, reward total was -21.000000. running mean: -20.249275\n",
            "resetting env. episode 2084.000000, reward total was -20.000000. running mean: -20.246783\n",
            "resetting env. episode 2085.000000, reward total was -21.000000. running mean: -20.254315\n",
            "resetting env. episode 2086.000000, reward total was -21.000000. running mean: -20.261772\n",
            "resetting env. episode 2087.000000, reward total was -21.000000. running mean: -20.269154\n",
            "resetting env. episode 2088.000000, reward total was -20.000000. running mean: -20.266462\n",
            "resetting env. episode 2089.000000, reward total was -19.000000. running mean: -20.253798\n",
            "resetting env. episode 2090.000000, reward total was -21.000000. running mean: -20.261260\n",
            "resetting env. episode 2091.000000, reward total was -19.000000. running mean: -20.248647\n",
            "resetting env. episode 2092.000000, reward total was -21.000000. running mean: -20.256161\n",
            "resetting env. episode 2093.000000, reward total was -20.000000. running mean: -20.253599\n",
            "resetting env. episode 2094.000000, reward total was -20.000000. running mean: -20.251063\n",
            "resetting env. episode 2095.000000, reward total was -21.000000. running mean: -20.258552\n",
            "resetting env. episode 2096.000000, reward total was -21.000000. running mean: -20.265967\n",
            "resetting env. episode 2097.000000, reward total was -21.000000. running mean: -20.273307\n",
            "resetting env. episode 2098.000000, reward total was -20.000000. running mean: -20.270574\n",
            "resetting env. episode 2099.000000, reward total was -21.000000. running mean: -20.277868\n",
            "resetting env. episode 2100.000000, reward total was -20.000000. running mean: -20.275090\n",
            "resetting env. episode 2101.000000, reward total was -21.000000. running mean: -20.282339\n",
            "resetting env. episode 2102.000000, reward total was -18.000000. running mean: -20.259515\n",
            "resetting env. episode 2103.000000, reward total was -17.000000. running mean: -20.226920\n",
            "resetting env. episode 2104.000000, reward total was -21.000000. running mean: -20.234651\n",
            "resetting env. episode 2105.000000, reward total was -19.000000. running mean: -20.222305\n",
            "resetting env. episode 2106.000000, reward total was -20.000000. running mean: -20.220082\n",
            "resetting env. episode 2107.000000, reward total was -20.000000. running mean: -20.217881\n",
            "resetting env. episode 2108.000000, reward total was -21.000000. running mean: -20.225702\n",
            "resetting env. episode 2109.000000, reward total was -19.000000. running mean: -20.213445\n",
            "resetting env. episode 2110.000000, reward total was -20.000000. running mean: -20.211310\n",
            "resetting env. episode 2111.000000, reward total was -21.000000. running mean: -20.219197\n",
            "resetting env. episode 2112.000000, reward total was -20.000000. running mean: -20.217005\n",
            "resetting env. episode 2113.000000, reward total was -21.000000. running mean: -20.224835\n",
            "resetting env. episode 2114.000000, reward total was -20.000000. running mean: -20.222587\n",
            "resetting env. episode 2115.000000, reward total was -21.000000. running mean: -20.230361\n",
            "resetting env. episode 2116.000000, reward total was -19.000000. running mean: -20.218057\n",
            "resetting env. episode 2117.000000, reward total was -21.000000. running mean: -20.225877\n",
            "resetting env. episode 2118.000000, reward total was -21.000000. running mean: -20.233618\n",
            "resetting env. episode 2119.000000, reward total was -21.000000. running mean: -20.241282\n",
            "resetting env. episode 2120.000000, reward total was -20.000000. running mean: -20.238869\n",
            "resetting env. episode 2121.000000, reward total was -20.000000. running mean: -20.236480\n",
            "resetting env. episode 2122.000000, reward total was -20.000000. running mean: -20.234116\n",
            "resetting env. episode 2123.000000, reward total was -20.000000. running mean: -20.231774\n",
            "resetting env. episode 2124.000000, reward total was -20.000000. running mean: -20.229457\n",
            "resetting env. episode 2125.000000, reward total was -21.000000. running mean: -20.237162\n",
            "resetting env. episode 2126.000000, reward total was -20.000000. running mean: -20.234791\n",
            "resetting env. episode 2127.000000, reward total was -21.000000. running mean: -20.242443\n",
            "resetting env. episode 2128.000000, reward total was -20.000000. running mean: -20.240018\n",
            "resetting env. episode 2129.000000, reward total was -21.000000. running mean: -20.247618\n",
            "resetting env. episode 2130.000000, reward total was -19.000000. running mean: -20.235142\n",
            "resetting env. episode 2131.000000, reward total was -21.000000. running mean: -20.242790\n",
            "resetting env. episode 2132.000000, reward total was -21.000000. running mean: -20.250363\n",
            "resetting env. episode 2133.000000, reward total was -19.000000. running mean: -20.237859\n",
            "resetting env. episode 2134.000000, reward total was -19.000000. running mean: -20.225480\n",
            "resetting env. episode 2135.000000, reward total was -21.000000. running mean: -20.233225\n",
            "resetting env. episode 2136.000000, reward total was -21.000000. running mean: -20.240893\n",
            "resetting env. episode 2137.000000, reward total was -21.000000. running mean: -20.248484\n",
            "resetting env. episode 2138.000000, reward total was -20.000000. running mean: -20.245999\n",
            "resetting env. episode 2139.000000, reward total was -18.000000. running mean: -20.223539\n",
            "resetting env. episode 2140.000000, reward total was -21.000000. running mean: -20.231304\n",
            "resetting env. episode 2141.000000, reward total was -21.000000. running mean: -20.238991\n",
            "resetting env. episode 2142.000000, reward total was -20.000000. running mean: -20.236601\n",
            "resetting env. episode 2143.000000, reward total was -21.000000. running mean: -20.244235\n",
            "resetting env. episode 2144.000000, reward total was -20.000000. running mean: -20.241793\n",
            "resetting env. episode 2145.000000, reward total was -21.000000. running mean: -20.249375\n",
            "resetting env. episode 2146.000000, reward total was -21.000000. running mean: -20.256881\n",
            "resetting env. episode 2147.000000, reward total was -20.000000. running mean: -20.254312\n",
            "resetting env. episode 2148.000000, reward total was -20.000000. running mean: -20.251769\n",
            "resetting env. episode 2149.000000, reward total was -20.000000. running mean: -20.249251\n",
            "resetting env. episode 2150.000000, reward total was -21.000000. running mean: -20.256759\n",
            "resetting env. episode 2151.000000, reward total was -20.000000. running mean: -20.254191\n",
            "resetting env. episode 2152.000000, reward total was -21.000000. running mean: -20.261649\n",
            "resetting env. episode 2153.000000, reward total was -19.000000. running mean: -20.249033\n",
            "resetting env. episode 2154.000000, reward total was -21.000000. running mean: -20.256543\n",
            "resetting env. episode 2155.000000, reward total was -21.000000. running mean: -20.263977\n",
            "resetting env. episode 2156.000000, reward total was -21.000000. running mean: -20.271337\n",
            "resetting env. episode 2157.000000, reward total was -19.000000. running mean: -20.258624\n",
            "resetting env. episode 2158.000000, reward total was -21.000000. running mean: -20.266038\n",
            "resetting env. episode 2159.000000, reward total was -20.000000. running mean: -20.263377\n",
            "resetting env. episode 2160.000000, reward total was -21.000000. running mean: -20.270744\n",
            "resetting env. episode 2161.000000, reward total was -18.000000. running mean: -20.248036\n",
            "resetting env. episode 2162.000000, reward total was -21.000000. running mean: -20.255556\n",
            "resetting env. episode 2163.000000, reward total was -16.000000. running mean: -20.213000\n",
            "resetting env. episode 2164.000000, reward total was -17.000000. running mean: -20.180870\n",
            "resetting env. episode 2165.000000, reward total was -18.000000. running mean: -20.159062\n",
            "resetting env. episode 2166.000000, reward total was -20.000000. running mean: -20.157471\n",
            "resetting env. episode 2167.000000, reward total was -20.000000. running mean: -20.155896\n",
            "resetting env. episode 2168.000000, reward total was -21.000000. running mean: -20.164337\n",
            "resetting env. episode 2169.000000, reward total was -20.000000. running mean: -20.162694\n",
            "resetting env. episode 2170.000000, reward total was -21.000000. running mean: -20.171067\n",
            "resetting env. episode 2171.000000, reward total was -20.000000. running mean: -20.169356\n",
            "resetting env. episode 2172.000000, reward total was -19.000000. running mean: -20.157663\n",
            "resetting env. episode 2173.000000, reward total was -21.000000. running mean: -20.166086\n",
            "resetting env. episode 2174.000000, reward total was -21.000000. running mean: -20.174425\n",
            "resetting env. episode 2175.000000, reward total was -21.000000. running mean: -20.182681\n",
            "resetting env. episode 2176.000000, reward total was -21.000000. running mean: -20.190854\n",
            "resetting env. episode 2177.000000, reward total was -21.000000. running mean: -20.198946\n",
            "resetting env. episode 2178.000000, reward total was -20.000000. running mean: -20.196956\n",
            "resetting env. episode 2179.000000, reward total was -21.000000. running mean: -20.204987\n",
            "resetting env. episode 2180.000000, reward total was -21.000000. running mean: -20.212937\n",
            "resetting env. episode 2181.000000, reward total was -21.000000. running mean: -20.220807\n",
            "resetting env. episode 2182.000000, reward total was -19.000000. running mean: -20.208599\n",
            "resetting env. episode 2183.000000, reward total was -21.000000. running mean: -20.216513\n",
            "resetting env. episode 2184.000000, reward total was -21.000000. running mean: -20.224348\n",
            "resetting env. episode 2185.000000, reward total was -21.000000. running mean: -20.232105\n",
            "resetting env. episode 2186.000000, reward total was -21.000000. running mean: -20.239784\n",
            "resetting env. episode 2187.000000, reward total was -20.000000. running mean: -20.237386\n",
            "resetting env. episode 2188.000000, reward total was -21.000000. running mean: -20.245012\n",
            "resetting env. episode 2189.000000, reward total was -18.000000. running mean: -20.222562\n",
            "resetting env. episode 2190.000000, reward total was -20.000000. running mean: -20.220336\n",
            "resetting env. episode 2191.000000, reward total was -18.000000. running mean: -20.198133\n",
            "resetting env. episode 2192.000000, reward total was -20.000000. running mean: -20.196152\n",
            "resetting env. episode 2193.000000, reward total was -21.000000. running mean: -20.204190\n",
            "resetting env. episode 2194.000000, reward total was -21.000000. running mean: -20.212148\n",
            "resetting env. episode 2195.000000, reward total was -19.000000. running mean: -20.200027\n",
            "resetting env. episode 2196.000000, reward total was -20.000000. running mean: -20.198026\n",
            "resetting env. episode 2197.000000, reward total was -21.000000. running mean: -20.206046\n",
            "resetting env. episode 2198.000000, reward total was -21.000000. running mean: -20.213986\n",
            "resetting env. episode 2199.000000, reward total was -21.000000. running mean: -20.221846\n",
            "resetting env. episode 2200.000000, reward total was -21.000000. running mean: -20.229627\n",
            "resetting env. episode 2201.000000, reward total was -19.000000. running mean: -20.217331\n",
            "resetting env. episode 2202.000000, reward total was -20.000000. running mean: -20.215158\n",
            "resetting env. episode 2203.000000, reward total was -18.000000. running mean: -20.193006\n",
            "resetting env. episode 2204.000000, reward total was -20.000000. running mean: -20.191076\n",
            "resetting env. episode 2205.000000, reward total was -19.000000. running mean: -20.179165\n",
            "resetting env. episode 2206.000000, reward total was -19.000000. running mean: -20.167374\n",
            "resetting env. episode 2207.000000, reward total was -21.000000. running mean: -20.175700\n",
            "resetting env. episode 2208.000000, reward total was -21.000000. running mean: -20.183943\n",
            "resetting env. episode 2209.000000, reward total was -20.000000. running mean: -20.182104\n",
            "resetting env. episode 2210.000000, reward total was -20.000000. running mean: -20.180283\n",
            "resetting env. episode 2211.000000, reward total was -20.000000. running mean: -20.178480\n",
            "resetting env. episode 2212.000000, reward total was -20.000000. running mean: -20.176695\n",
            "resetting env. episode 2213.000000, reward total was -21.000000. running mean: -20.184928\n",
            "resetting env. episode 2214.000000, reward total was -21.000000. running mean: -20.193079\n",
            "resetting env. episode 2215.000000, reward total was -21.000000. running mean: -20.201148\n",
            "resetting env. episode 2216.000000, reward total was -20.000000. running mean: -20.199136\n",
            "resetting env. episode 2217.000000, reward total was -18.000000. running mean: -20.177145\n",
            "resetting env. episode 2218.000000, reward total was -18.000000. running mean: -20.155374\n",
            "resetting env. episode 2219.000000, reward total was -20.000000. running mean: -20.153820\n",
            "resetting env. episode 2220.000000, reward total was -21.000000. running mean: -20.162282\n",
            "resetting env. episode 2221.000000, reward total was -20.000000. running mean: -20.160659\n",
            "resetting env. episode 2222.000000, reward total was -21.000000. running mean: -20.169052\n",
            "resetting env. episode 2223.000000, reward total was -20.000000. running mean: -20.167362\n",
            "resetting env. episode 2224.000000, reward total was -19.000000. running mean: -20.155688\n",
            "resetting env. episode 2225.000000, reward total was -21.000000. running mean: -20.164131\n",
            "resetting env. episode 2226.000000, reward total was -19.000000. running mean: -20.152490\n",
            "resetting env. episode 2227.000000, reward total was -20.000000. running mean: -20.150965\n",
            "resetting env. episode 2228.000000, reward total was -21.000000. running mean: -20.159455\n",
            "resetting env. episode 2229.000000, reward total was -21.000000. running mean: -20.167861\n",
            "resetting env. episode 2230.000000, reward total was -20.000000. running mean: -20.166182\n",
            "resetting env. episode 2231.000000, reward total was -21.000000. running mean: -20.174520\n",
            "resetting env. episode 2232.000000, reward total was -21.000000. running mean: -20.182775\n",
            "resetting env. episode 2233.000000, reward total was -20.000000. running mean: -20.180947\n",
            "resetting env. episode 2234.000000, reward total was -20.000000. running mean: -20.179138\n",
            "resetting env. episode 2235.000000, reward total was -18.000000. running mean: -20.157347\n",
            "resetting env. episode 2236.000000, reward total was -21.000000. running mean: -20.165773\n",
            "resetting env. episode 2237.000000, reward total was -21.000000. running mean: -20.174115\n",
            "resetting env. episode 2238.000000, reward total was -20.000000. running mean: -20.172374\n",
            "resetting env. episode 2239.000000, reward total was -20.000000. running mean: -20.170650\n",
            "resetting env. episode 2240.000000, reward total was -20.000000. running mean: -20.168944\n",
            "resetting env. episode 2241.000000, reward total was -21.000000. running mean: -20.177255\n",
            "resetting env. episode 2242.000000, reward total was -21.000000. running mean: -20.185482\n",
            "resetting env. episode 2243.000000, reward total was -21.000000. running mean: -20.193627\n",
            "resetting env. episode 2244.000000, reward total was -21.000000. running mean: -20.201691\n",
            "resetting env. episode 2245.000000, reward total was -21.000000. running mean: -20.209674\n",
            "resetting env. episode 2246.000000, reward total was -21.000000. running mean: -20.217577\n",
            "resetting env. episode 2247.000000, reward total was -17.000000. running mean: -20.185401\n",
            "resetting env. episode 2248.000000, reward total was -20.000000. running mean: -20.183547\n",
            "resetting env. episode 2249.000000, reward total was -21.000000. running mean: -20.191712\n",
            "resetting env. episode 2250.000000, reward total was -21.000000. running mean: -20.199795\n",
            "resetting env. episode 2251.000000, reward total was -20.000000. running mean: -20.197797\n",
            "resetting env. episode 2252.000000, reward total was -20.000000. running mean: -20.195819\n",
            "resetting env. episode 2253.000000, reward total was -21.000000. running mean: -20.203861\n",
            "resetting env. episode 2254.000000, reward total was -20.000000. running mean: -20.201822\n",
            "resetting env. episode 2255.000000, reward total was -21.000000. running mean: -20.209804\n",
            "resetting env. episode 2256.000000, reward total was -18.000000. running mean: -20.187706\n",
            "resetting env. episode 2257.000000, reward total was -19.000000. running mean: -20.175829\n",
            "resetting env. episode 2258.000000, reward total was -18.000000. running mean: -20.154071\n",
            "resetting env. episode 2259.000000, reward total was -21.000000. running mean: -20.162530\n",
            "resetting env. episode 2260.000000, reward total was -20.000000. running mean: -20.160905\n",
            "resetting env. episode 2261.000000, reward total was -19.000000. running mean: -20.149295\n",
            "resetting env. episode 2262.000000, reward total was -20.000000. running mean: -20.147803\n",
            "resetting env. episode 2263.000000, reward total was -21.000000. running mean: -20.156325\n",
            "resetting env. episode 2264.000000, reward total was -21.000000. running mean: -20.164761\n",
            "resetting env. episode 2265.000000, reward total was -21.000000. running mean: -20.173114\n",
            "resetting env. episode 2266.000000, reward total was -21.000000. running mean: -20.181383\n",
            "resetting env. episode 2267.000000, reward total was -21.000000. running mean: -20.189569\n",
            "resetting env. episode 2268.000000, reward total was -20.000000. running mean: -20.187673\n",
            "resetting env. episode 2269.000000, reward total was -19.000000. running mean: -20.175796\n",
            "resetting env. episode 2270.000000, reward total was -20.000000. running mean: -20.174038\n",
            "resetting env. episode 2271.000000, reward total was -20.000000. running mean: -20.172298\n",
            "resetting env. episode 2272.000000, reward total was -20.000000. running mean: -20.170575\n",
            "resetting env. episode 2273.000000, reward total was -21.000000. running mean: -20.178869\n",
            "resetting env. episode 2274.000000, reward total was -21.000000. running mean: -20.187081\n",
            "resetting env. episode 2275.000000, reward total was -21.000000. running mean: -20.195210\n",
            "resetting env. episode 2276.000000, reward total was -21.000000. running mean: -20.203258\n",
            "resetting env. episode 2277.000000, reward total was -21.000000. running mean: -20.211225\n",
            "resetting env. episode 2278.000000, reward total was -17.000000. running mean: -20.179113\n",
            "resetting env. episode 2279.000000, reward total was -19.000000. running mean: -20.167322\n",
            "resetting env. episode 2280.000000, reward total was -21.000000. running mean: -20.175648\n",
            "resetting env. episode 2281.000000, reward total was -20.000000. running mean: -20.173892\n",
            "resetting env. episode 2282.000000, reward total was -19.000000. running mean: -20.162153\n",
            "resetting env. episode 2283.000000, reward total was -21.000000. running mean: -20.170532\n",
            "resetting env. episode 2284.000000, reward total was -20.000000. running mean: -20.168826\n",
            "resetting env. episode 2285.000000, reward total was -21.000000. running mean: -20.177138\n",
            "resetting env. episode 2286.000000, reward total was -20.000000. running mean: -20.175367\n",
            "resetting env. episode 2287.000000, reward total was -20.000000. running mean: -20.173613\n",
            "resetting env. episode 2288.000000, reward total was -21.000000. running mean: -20.181877\n",
            "resetting env. episode 2289.000000, reward total was -19.000000. running mean: -20.170058\n",
            "resetting env. episode 2290.000000, reward total was -20.000000. running mean: -20.168357\n",
            "resetting env. episode 2291.000000, reward total was -20.000000. running mean: -20.166674\n",
            "resetting env. episode 2292.000000, reward total was -21.000000. running mean: -20.175007\n",
            "resetting env. episode 2293.000000, reward total was -20.000000. running mean: -20.173257\n",
            "resetting env. episode 2294.000000, reward total was -18.000000. running mean: -20.151524\n",
            "resetting env. episode 2295.000000, reward total was -20.000000. running mean: -20.150009\n",
            "resetting env. episode 2296.000000, reward total was -20.000000. running mean: -20.148509\n",
            "resetting env. episode 2297.000000, reward total was -20.000000. running mean: -20.147024\n",
            "resetting env. episode 2298.000000, reward total was -19.000000. running mean: -20.135554\n",
            "resetting env. episode 2299.000000, reward total was -21.000000. running mean: -20.144198\n",
            "resetting env. episode 2300.000000, reward total was -19.000000. running mean: -20.132756\n",
            "resetting env. episode 2301.000000, reward total was -20.000000. running mean: -20.131429\n",
            "resetting env. episode 2302.000000, reward total was -21.000000. running mean: -20.140114\n",
            "resetting env. episode 2303.000000, reward total was -21.000000. running mean: -20.148713\n",
            "resetting env. episode 2304.000000, reward total was -19.000000. running mean: -20.137226\n",
            "resetting env. episode 2305.000000, reward total was -19.000000. running mean: -20.125854\n",
            "resetting env. episode 2306.000000, reward total was -18.000000. running mean: -20.104595\n",
            "resetting env. episode 2307.000000, reward total was -20.000000. running mean: -20.103549\n",
            "resetting env. episode 2308.000000, reward total was -20.000000. running mean: -20.102514\n",
            "resetting env. episode 2309.000000, reward total was -21.000000. running mean: -20.111489\n",
            "resetting env. episode 2310.000000, reward total was -21.000000. running mean: -20.120374\n",
            "resetting env. episode 2311.000000, reward total was -21.000000. running mean: -20.129170\n",
            "resetting env. episode 2312.000000, reward total was -21.000000. running mean: -20.137878\n",
            "resetting env. episode 2313.000000, reward total was -20.000000. running mean: -20.136500\n",
            "resetting env. episode 2314.000000, reward total was -21.000000. running mean: -20.145135\n",
            "resetting env. episode 2315.000000, reward total was -21.000000. running mean: -20.153683\n",
            "resetting env. episode 2316.000000, reward total was -20.000000. running mean: -20.152146\n",
            "resetting env. episode 2317.000000, reward total was -21.000000. running mean: -20.160625\n",
            "resetting env. episode 2318.000000, reward total was -20.000000. running mean: -20.159019\n",
            "resetting env. episode 2319.000000, reward total was -18.000000. running mean: -20.137429\n",
            "resetting env. episode 2320.000000, reward total was -18.000000. running mean: -20.116054\n",
            "resetting env. episode 2321.000000, reward total was -20.000000. running mean: -20.114894\n",
            "resetting env. episode 2322.000000, reward total was -21.000000. running mean: -20.123745\n",
            "resetting env. episode 2323.000000, reward total was -21.000000. running mean: -20.132507\n",
            "resetting env. episode 2324.000000, reward total was -21.000000. running mean: -20.141182\n",
            "resetting env. episode 2325.000000, reward total was -19.000000. running mean: -20.129770\n",
            "resetting env. episode 2326.000000, reward total was -20.000000. running mean: -20.128473\n",
            "resetting env. episode 2327.000000, reward total was -21.000000. running mean: -20.137188\n",
            "resetting env. episode 2328.000000, reward total was -20.000000. running mean: -20.135816\n",
            "resetting env. episode 2329.000000, reward total was -20.000000. running mean: -20.134458\n",
            "resetting env. episode 2330.000000, reward total was -21.000000. running mean: -20.143113\n",
            "resetting env. episode 2331.000000, reward total was -20.000000. running mean: -20.141682\n",
            "resetting env. episode 2332.000000, reward total was -21.000000. running mean: -20.150265\n",
            "resetting env. episode 2333.000000, reward total was -21.000000. running mean: -20.158763\n",
            "resetting env. episode 2334.000000, reward total was -21.000000. running mean: -20.167175\n",
            "resetting env. episode 2335.000000, reward total was -21.000000. running mean: -20.175503\n",
            "resetting env. episode 2336.000000, reward total was -20.000000. running mean: -20.173748\n",
            "resetting env. episode 2337.000000, reward total was -21.000000. running mean: -20.182011\n",
            "resetting env. episode 2338.000000, reward total was -20.000000. running mean: -20.180191\n",
            "resetting env. episode 2339.000000, reward total was -20.000000. running mean: -20.178389\n",
            "resetting env. episode 2340.000000, reward total was -19.000000. running mean: -20.166605\n",
            "resetting env. episode 2341.000000, reward total was -21.000000. running mean: -20.174939\n",
            "resetting env. episode 2342.000000, reward total was -21.000000. running mean: -20.183190\n",
            "resetting env. episode 2343.000000, reward total was -20.000000. running mean: -20.181358\n",
            "resetting env. episode 2344.000000, reward total was -20.000000. running mean: -20.179544\n",
            "resetting env. episode 2345.000000, reward total was -19.000000. running mean: -20.167749\n",
            "resetting env. episode 2346.000000, reward total was -21.000000. running mean: -20.176071\n",
            "resetting env. episode 2347.000000, reward total was -19.000000. running mean: -20.164310\n",
            "resetting env. episode 2348.000000, reward total was -20.000000. running mean: -20.162667\n",
            "resetting env. episode 2349.000000, reward total was -20.000000. running mean: -20.161041\n",
            "resetting env. episode 2350.000000, reward total was -20.000000. running mean: -20.159430\n",
            "resetting env. episode 2351.000000, reward total was -20.000000. running mean: -20.157836\n",
            "resetting env. episode 2352.000000, reward total was -21.000000. running mean: -20.166258\n",
            "resetting env. episode 2353.000000, reward total was -20.000000. running mean: -20.164595\n",
            "resetting env. episode 2354.000000, reward total was -21.000000. running mean: -20.172949\n",
            "resetting env. episode 2355.000000, reward total was -21.000000. running mean: -20.181220\n",
            "resetting env. episode 2356.000000, reward total was -19.000000. running mean: -20.169407\n",
            "resetting env. episode 2357.000000, reward total was -20.000000. running mean: -20.167713\n",
            "resetting env. episode 2358.000000, reward total was -19.000000. running mean: -20.156036\n",
            "resetting env. episode 2359.000000, reward total was -21.000000. running mean: -20.164476\n",
            "resetting env. episode 2360.000000, reward total was -18.000000. running mean: -20.142831\n",
            "resetting env. episode 2361.000000, reward total was -21.000000. running mean: -20.151403\n",
            "resetting env. episode 2362.000000, reward total was -21.000000. running mean: -20.159889\n",
            "resetting env. episode 2363.000000, reward total was -20.000000. running mean: -20.158290\n",
            "resetting env. episode 2364.000000, reward total was -20.000000. running mean: -20.156707\n",
            "resetting env. episode 2365.000000, reward total was -21.000000. running mean: -20.165140\n",
            "resetting env. episode 2366.000000, reward total was -20.000000. running mean: -20.163488\n",
            "resetting env. episode 2367.000000, reward total was -20.000000. running mean: -20.161854\n",
            "resetting env. episode 2368.000000, reward total was -20.000000. running mean: -20.160235\n",
            "resetting env. episode 2369.000000, reward total was -19.000000. running mean: -20.148633\n",
            "resetting env. episode 2370.000000, reward total was -19.000000. running mean: -20.137146\n",
            "resetting env. episode 2371.000000, reward total was -20.000000. running mean: -20.135775\n",
            "resetting env. episode 2372.000000, reward total was -18.000000. running mean: -20.114417\n",
            "resetting env. episode 2373.000000, reward total was -21.000000. running mean: -20.123273\n",
            "resetting env. episode 2374.000000, reward total was -21.000000. running mean: -20.132040\n",
            "resetting env. episode 2375.000000, reward total was -21.000000. running mean: -20.140720\n",
            "resetting env. episode 2376.000000, reward total was -21.000000. running mean: -20.149313\n",
            "resetting env. episode 2377.000000, reward total was -18.000000. running mean: -20.127820\n",
            "resetting env. episode 2378.000000, reward total was -21.000000. running mean: -20.136541\n",
            "resetting env. episode 2379.000000, reward total was -21.000000. running mean: -20.145176\n",
            "resetting env. episode 2380.000000, reward total was -21.000000. running mean: -20.153724\n",
            "resetting env. episode 2381.000000, reward total was -20.000000. running mean: -20.152187\n",
            "resetting env. episode 2382.000000, reward total was -18.000000. running mean: -20.130665\n",
            "resetting env. episode 2383.000000, reward total was -21.000000. running mean: -20.139358\n",
            "resetting env. episode 2384.000000, reward total was -20.000000. running mean: -20.137965\n",
            "resetting env. episode 2385.000000, reward total was -19.000000. running mean: -20.126585\n",
            "resetting env. episode 2386.000000, reward total was -20.000000. running mean: -20.125319\n",
            "resetting env. episode 2387.000000, reward total was -21.000000. running mean: -20.134066\n",
            "resetting env. episode 2388.000000, reward total was -20.000000. running mean: -20.132725\n",
            "resetting env. episode 2389.000000, reward total was -20.000000. running mean: -20.131398\n",
            "resetting env. episode 2390.000000, reward total was -20.000000. running mean: -20.130084\n",
            "resetting env. episode 2391.000000, reward total was -21.000000. running mean: -20.138783\n",
            "resetting env. episode 2392.000000, reward total was -20.000000. running mean: -20.137396\n",
            "resetting env. episode 2393.000000, reward total was -20.000000. running mean: -20.136022\n",
            "resetting env. episode 2394.000000, reward total was -20.000000. running mean: -20.134661\n",
            "resetting env. episode 2395.000000, reward total was -20.000000. running mean: -20.133315\n",
            "resetting env. episode 2396.000000, reward total was -21.000000. running mean: -20.141982\n",
            "resetting env. episode 2397.000000, reward total was -21.000000. running mean: -20.150562\n",
            "resetting env. episode 2398.000000, reward total was -20.000000. running mean: -20.149056\n",
            "resetting env. episode 2399.000000, reward total was -19.000000. running mean: -20.137566\n",
            "resetting env. episode 2400.000000, reward total was -19.000000. running mean: -20.126190\n",
            "resetting env. episode 2401.000000, reward total was -20.000000. running mean: -20.124928\n",
            "resetting env. episode 2402.000000, reward total was -21.000000. running mean: -20.133679\n",
            "resetting env. episode 2403.000000, reward total was -20.000000. running mean: -20.132342\n",
            "resetting env. episode 2404.000000, reward total was -17.000000. running mean: -20.101019\n",
            "resetting env. episode 2405.000000, reward total was -21.000000. running mean: -20.110008\n",
            "resetting env. episode 2406.000000, reward total was -19.000000. running mean: -20.098908\n",
            "resetting env. episode 2407.000000, reward total was -20.000000. running mean: -20.097919\n",
            "resetting env. episode 2408.000000, reward total was -21.000000. running mean: -20.106940\n",
            "resetting env. episode 2409.000000, reward total was -19.000000. running mean: -20.095871\n",
            "resetting env. episode 2410.000000, reward total was -20.000000. running mean: -20.094912\n",
            "resetting env. episode 2411.000000, reward total was -21.000000. running mean: -20.103963\n",
            "resetting env. episode 2412.000000, reward total was -19.000000. running mean: -20.092923\n",
            "resetting env. episode 2413.000000, reward total was -19.000000. running mean: -20.081994\n",
            "resetting env. episode 2414.000000, reward total was -21.000000. running mean: -20.091174\n",
            "resetting env. episode 2415.000000, reward total was -20.000000. running mean: -20.090262\n",
            "resetting env. episode 2416.000000, reward total was -18.000000. running mean: -20.069360\n",
            "resetting env. episode 2417.000000, reward total was -21.000000. running mean: -20.078666\n",
            "resetting env. episode 2418.000000, reward total was -18.000000. running mean: -20.057879\n",
            "resetting env. episode 2419.000000, reward total was -20.000000. running mean: -20.057301\n",
            "resetting env. episode 2420.000000, reward total was -21.000000. running mean: -20.066728\n",
            "resetting env. episode 2421.000000, reward total was -21.000000. running mean: -20.076060\n",
            "resetting env. episode 2422.000000, reward total was -20.000000. running mean: -20.075300\n",
            "resetting env. episode 2423.000000, reward total was -20.000000. running mean: -20.074547\n",
            "resetting env. episode 2424.000000, reward total was -21.000000. running mean: -20.083801\n",
            "resetting env. episode 2425.000000, reward total was -21.000000. running mean: -20.092963\n",
            "resetting env. episode 2426.000000, reward total was -21.000000. running mean: -20.102034\n",
            "resetting env. episode 2427.000000, reward total was -20.000000. running mean: -20.101013\n",
            "resetting env. episode 2428.000000, reward total was -21.000000. running mean: -20.110003\n",
            "resetting env. episode 2429.000000, reward total was -21.000000. running mean: -20.118903\n",
            "resetting env. episode 2430.000000, reward total was -20.000000. running mean: -20.117714\n",
            "resetting env. episode 2431.000000, reward total was -21.000000. running mean: -20.126537\n",
            "resetting env. episode 2432.000000, reward total was -19.000000. running mean: -20.115272\n",
            "resetting env. episode 2433.000000, reward total was -21.000000. running mean: -20.124119\n",
            "resetting env. episode 2434.000000, reward total was -19.000000. running mean: -20.112878\n",
            "resetting env. episode 2435.000000, reward total was -20.000000. running mean: -20.111749\n",
            "resetting env. episode 2436.000000, reward total was -21.000000. running mean: -20.120631\n",
            "resetting env. episode 2437.000000, reward total was -21.000000. running mean: -20.129425\n",
            "resetting env. episode 2438.000000, reward total was -21.000000. running mean: -20.138131\n",
            "resetting env. episode 2439.000000, reward total was -20.000000. running mean: -20.136750\n",
            "resetting env. episode 2440.000000, reward total was -19.000000. running mean: -20.125382\n",
            "resetting env. episode 2441.000000, reward total was -21.000000. running mean: -20.134128\n",
            "resetting env. episode 2442.000000, reward total was -19.000000. running mean: -20.122787\n",
            "resetting env. episode 2443.000000, reward total was -19.000000. running mean: -20.111559\n",
            "resetting env. episode 2444.000000, reward total was -20.000000. running mean: -20.110443\n",
            "resetting env. episode 2445.000000, reward total was -19.000000. running mean: -20.099339\n",
            "resetting env. episode 2446.000000, reward total was -17.000000. running mean: -20.068346\n",
            "resetting env. episode 2447.000000, reward total was -21.000000. running mean: -20.077662\n",
            "resetting env. episode 2448.000000, reward total was -20.000000. running mean: -20.076886\n",
            "resetting env. episode 2449.000000, reward total was -21.000000. running mean: -20.086117\n",
            "resetting env. episode 2450.000000, reward total was -21.000000. running mean: -20.095256\n",
            "resetting env. episode 2451.000000, reward total was -18.000000. running mean: -20.074303\n",
            "resetting env. episode 2452.000000, reward total was -21.000000. running mean: -20.083560\n",
            "resetting env. episode 2453.000000, reward total was -21.000000. running mean: -20.092724\n",
            "resetting env. episode 2454.000000, reward total was -19.000000. running mean: -20.081797\n",
            "resetting env. episode 2455.000000, reward total was -20.000000. running mean: -20.080979\n",
            "resetting env. episode 2456.000000, reward total was -16.000000. running mean: -20.040169\n",
            "resetting env. episode 2457.000000, reward total was -19.000000. running mean: -20.029768\n",
            "resetting env. episode 2458.000000, reward total was -20.000000. running mean: -20.029470\n",
            "resetting env. episode 2459.000000, reward total was -21.000000. running mean: -20.039175\n",
            "resetting env. episode 2460.000000, reward total was -18.000000. running mean: -20.018784\n",
            "resetting env. episode 2461.000000, reward total was -21.000000. running mean: -20.028596\n",
            "resetting env. episode 2462.000000, reward total was -21.000000. running mean: -20.038310\n",
            "resetting env. episode 2463.000000, reward total was -21.000000. running mean: -20.047927\n",
            "resetting env. episode 2464.000000, reward total was -16.000000. running mean: -20.007447\n",
            "resetting env. episode 2465.000000, reward total was -20.000000. running mean: -20.007373\n",
            "resetting env. episode 2466.000000, reward total was -21.000000. running mean: -20.017299\n",
            "resetting env. episode 2467.000000, reward total was -21.000000. running mean: -20.027126\n",
            "resetting env. episode 2468.000000, reward total was -21.000000. running mean: -20.036855\n",
            "resetting env. episode 2469.000000, reward total was -20.000000. running mean: -20.036486\n",
            "resetting env. episode 2470.000000, reward total was -19.000000. running mean: -20.026121\n",
            "resetting env. episode 2471.000000, reward total was -20.000000. running mean: -20.025860\n",
            "resetting env. episode 2472.000000, reward total was -21.000000. running mean: -20.035602\n",
            "resetting env. episode 2473.000000, reward total was -20.000000. running mean: -20.035246\n",
            "resetting env. episode 2474.000000, reward total was -21.000000. running mean: -20.044893\n",
            "resetting env. episode 2475.000000, reward total was -21.000000. running mean: -20.054444\n",
            "resetting env. episode 2476.000000, reward total was -20.000000. running mean: -20.053900\n",
            "resetting env. episode 2477.000000, reward total was -21.000000. running mean: -20.063361\n",
            "resetting env. episode 2478.000000, reward total was -20.000000. running mean: -20.062727\n",
            "resetting env. episode 2479.000000, reward total was -21.000000. running mean: -20.072100\n",
            "resetting env. episode 2480.000000, reward total was -20.000000. running mean: -20.071379\n",
            "resetting env. episode 2481.000000, reward total was -21.000000. running mean: -20.080665\n",
            "resetting env. episode 2482.000000, reward total was -21.000000. running mean: -20.089859\n",
            "resetting env. episode 2483.000000, reward total was -20.000000. running mean: -20.088960\n",
            "resetting env. episode 2484.000000, reward total was -21.000000. running mean: -20.098070\n",
            "resetting env. episode 2485.000000, reward total was -21.000000. running mean: -20.107090\n",
            "resetting env. episode 2486.000000, reward total was -20.000000. running mean: -20.106019\n",
            "resetting env. episode 2487.000000, reward total was -21.000000. running mean: -20.114959\n",
            "resetting env. episode 2488.000000, reward total was -20.000000. running mean: -20.113809\n",
            "resetting env. episode 2489.000000, reward total was -20.000000. running mean: -20.112671\n",
            "resetting env. episode 2490.000000, reward total was -19.000000. running mean: -20.101544\n",
            "resetting env. episode 2491.000000, reward total was -21.000000. running mean: -20.110529\n",
            "resetting env. episode 2492.000000, reward total was -19.000000. running mean: -20.099423\n",
            "resetting env. episode 2493.000000, reward total was -20.000000. running mean: -20.098429\n",
            "resetting env. episode 2494.000000, reward total was -20.000000. running mean: -20.097445\n",
            "resetting env. episode 2495.000000, reward total was -20.000000. running mean: -20.096470\n",
            "resetting env. episode 2496.000000, reward total was -20.000000. running mean: -20.095506\n",
            "resetting env. episode 2497.000000, reward total was -20.000000. running mean: -20.094551\n",
            "resetting env. episode 2498.000000, reward total was -18.000000. running mean: -20.073605\n",
            "resetting env. episode 2499.000000, reward total was -19.000000. running mean: -20.062869\n",
            "resetting env. episode 2500.000000, reward total was -20.000000. running mean: -20.062240\n",
            "resetting env. episode 2501.000000, reward total was -19.000000. running mean: -20.051618\n",
            "resetting env. episode 2502.000000, reward total was -21.000000. running mean: -20.061102\n",
            "resetting env. episode 2503.000000, reward total was -20.000000. running mean: -20.060491\n",
            "resetting env. episode 2504.000000, reward total was -20.000000. running mean: -20.059886\n",
            "resetting env. episode 2505.000000, reward total was -21.000000. running mean: -20.069287\n",
            "resetting env. episode 2506.000000, reward total was -21.000000. running mean: -20.078594\n",
            "resetting env. episode 2507.000000, reward total was -20.000000. running mean: -20.077808\n",
            "resetting env. episode 2508.000000, reward total was -21.000000. running mean: -20.087030\n",
            "resetting env. episode 2509.000000, reward total was -20.000000. running mean: -20.086160\n",
            "resetting env. episode 2510.000000, reward total was -21.000000. running mean: -20.095298\n",
            "resetting env. episode 2511.000000, reward total was -20.000000. running mean: -20.094345\n",
            "resetting env. episode 2512.000000, reward total was -21.000000. running mean: -20.103402\n",
            "resetting env. episode 2513.000000, reward total was -20.000000. running mean: -20.102368\n",
            "resetting env. episode 2514.000000, reward total was -19.000000. running mean: -20.091344\n",
            "resetting env. episode 2515.000000, reward total was -20.000000. running mean: -20.090431\n",
            "resetting env. episode 2516.000000, reward total was -20.000000. running mean: -20.089526\n",
            "resetting env. episode 2517.000000, reward total was -20.000000. running mean: -20.088631\n",
            "resetting env. episode 2518.000000, reward total was -19.000000. running mean: -20.077745\n",
            "resetting env. episode 2519.000000, reward total was -21.000000. running mean: -20.086967\n",
            "resetting env. episode 2520.000000, reward total was -19.000000. running mean: -20.076098\n",
            "resetting env. episode 2521.000000, reward total was -21.000000. running mean: -20.085337\n",
            "resetting env. episode 2522.000000, reward total was -20.000000. running mean: -20.084483\n",
            "resetting env. episode 2523.000000, reward total was -21.000000. running mean: -20.093639\n",
            "resetting env. episode 2524.000000, reward total was -20.000000. running mean: -20.092702\n",
            "resetting env. episode 2525.000000, reward total was -21.000000. running mean: -20.101775\n",
            "resetting env. episode 2526.000000, reward total was -18.000000. running mean: -20.080757\n",
            "resetting env. episode 2527.000000, reward total was -20.000000. running mean: -20.079950\n",
            "resetting env. episode 2528.000000, reward total was -20.000000. running mean: -20.079150\n",
            "resetting env. episode 2529.000000, reward total was -21.000000. running mean: -20.088359\n",
            "resetting env. episode 2530.000000, reward total was -21.000000. running mean: -20.097475\n",
            "resetting env. episode 2531.000000, reward total was -21.000000. running mean: -20.106500\n",
            "resetting env. episode 2532.000000, reward total was -21.000000. running mean: -20.115435\n",
            "resetting env. episode 2533.000000, reward total was -21.000000. running mean: -20.124281\n",
            "resetting env. episode 2534.000000, reward total was -21.000000. running mean: -20.133038\n",
            "resetting env. episode 2535.000000, reward total was -19.000000. running mean: -20.121708\n",
            "resetting env. episode 2536.000000, reward total was -21.000000. running mean: -20.130491\n",
            "resetting env. episode 2537.000000, reward total was -21.000000. running mean: -20.139186\n",
            "resetting env. episode 2538.000000, reward total was -21.000000. running mean: -20.147794\n",
            "resetting env. episode 2539.000000, reward total was -21.000000. running mean: -20.156316\n",
            "resetting env. episode 2540.000000, reward total was -20.000000. running mean: -20.154753\n",
            "resetting env. episode 2541.000000, reward total was -21.000000. running mean: -20.163205\n",
            "resetting env. episode 2542.000000, reward total was -21.000000. running mean: -20.171573\n",
            "resetting env. episode 2543.000000, reward total was -16.000000. running mean: -20.129858\n",
            "resetting env. episode 2544.000000, reward total was -20.000000. running mean: -20.128559\n",
            "resetting env. episode 2545.000000, reward total was -18.000000. running mean: -20.107273\n",
            "resetting env. episode 2546.000000, reward total was -18.000000. running mean: -20.086201\n",
            "resetting env. episode 2547.000000, reward total was -21.000000. running mean: -20.095339\n",
            "resetting env. episode 2548.000000, reward total was -21.000000. running mean: -20.104385\n",
            "resetting env. episode 2549.000000, reward total was -21.000000. running mean: -20.113341\n",
            "resetting env. episode 2550.000000, reward total was -19.000000. running mean: -20.102208\n",
            "resetting env. episode 2551.000000, reward total was -21.000000. running mean: -20.111186\n",
            "resetting env. episode 2552.000000, reward total was -21.000000. running mean: -20.120074\n",
            "resetting env. episode 2553.000000, reward total was -21.000000. running mean: -20.128873\n",
            "resetting env. episode 2554.000000, reward total was -21.000000. running mean: -20.137585\n",
            "resetting env. episode 2555.000000, reward total was -19.000000. running mean: -20.126209\n",
            "resetting env. episode 2556.000000, reward total was -20.000000. running mean: -20.124947\n",
            "resetting env. episode 2557.000000, reward total was -20.000000. running mean: -20.123697\n",
            "resetting env. episode 2558.000000, reward total was -21.000000. running mean: -20.132460\n",
            "resetting env. episode 2559.000000, reward total was -19.000000. running mean: -20.121136\n",
            "resetting env. episode 2560.000000, reward total was -19.000000. running mean: -20.109924\n",
            "resetting env. episode 2561.000000, reward total was -20.000000. running mean: -20.108825\n",
            "resetting env. episode 2562.000000, reward total was -19.000000. running mean: -20.097737\n",
            "resetting env. episode 2563.000000, reward total was -18.000000. running mean: -20.076759\n",
            "resetting env. episode 2564.000000, reward total was -20.000000. running mean: -20.075992\n",
            "resetting env. episode 2565.000000, reward total was -19.000000. running mean: -20.065232\n",
            "resetting env. episode 2566.000000, reward total was -21.000000. running mean: -20.074580\n",
            "resetting env. episode 2567.000000, reward total was -20.000000. running mean: -20.073834\n",
            "resetting env. episode 2568.000000, reward total was -21.000000. running mean: -20.083095\n",
            "resetting env. episode 2569.000000, reward total was -21.000000. running mean: -20.092265\n",
            "resetting env. episode 2570.000000, reward total was -20.000000. running mean: -20.091342\n",
            "resetting env. episode 2571.000000, reward total was -20.000000. running mean: -20.090428\n",
            "resetting env. episode 2572.000000, reward total was -20.000000. running mean: -20.089524\n",
            "resetting env. episode 2573.000000, reward total was -21.000000. running mean: -20.098629\n",
            "resetting env. episode 2574.000000, reward total was -21.000000. running mean: -20.107643\n",
            "resetting env. episode 2575.000000, reward total was -20.000000. running mean: -20.106566\n",
            "resetting env. episode 2576.000000, reward total was -17.000000. running mean: -20.075501\n",
            "resetting env. episode 2577.000000, reward total was -19.000000. running mean: -20.064746\n",
            "resetting env. episode 2578.000000, reward total was -21.000000. running mean: -20.074098\n",
            "resetting env. episode 2579.000000, reward total was -21.000000. running mean: -20.083357\n",
            "resetting env. episode 2580.000000, reward total was -21.000000. running mean: -20.092524\n",
            "resetting env. episode 2581.000000, reward total was -20.000000. running mean: -20.091598\n",
            "resetting env. episode 2582.000000, reward total was -21.000000. running mean: -20.100682\n",
            "resetting env. episode 2583.000000, reward total was -21.000000. running mean: -20.109676\n",
            "resetting env. episode 2584.000000, reward total was -21.000000. running mean: -20.118579\n",
            "resetting env. episode 2585.000000, reward total was -20.000000. running mean: -20.117393\n",
            "resetting env. episode 2586.000000, reward total was -19.000000. running mean: -20.106219\n",
            "resetting env. episode 2587.000000, reward total was -21.000000. running mean: -20.115157\n",
            "resetting env. episode 2588.000000, reward total was -19.000000. running mean: -20.104005\n",
            "resetting env. episode 2589.000000, reward total was -20.000000. running mean: -20.102965\n",
            "resetting env. episode 2590.000000, reward total was -19.000000. running mean: -20.091936\n",
            "resetting env. episode 2591.000000, reward total was -20.000000. running mean: -20.091016\n",
            "resetting env. episode 2592.000000, reward total was -21.000000. running mean: -20.100106\n",
            "resetting env. episode 2593.000000, reward total was -20.000000. running mean: -20.099105\n",
            "resetting env. episode 2594.000000, reward total was -21.000000. running mean: -20.108114\n",
            "resetting env. episode 2595.000000, reward total was -19.000000. running mean: -20.097033\n",
            "resetting env. episode 2596.000000, reward total was -21.000000. running mean: -20.106062\n",
            "resetting env. episode 2597.000000, reward total was -20.000000. running mean: -20.105002\n",
            "resetting env. episode 2598.000000, reward total was -18.000000. running mean: -20.083952\n",
            "resetting env. episode 2599.000000, reward total was -20.000000. running mean: -20.083112\n",
            "resetting env. episode 2600.000000, reward total was -21.000000. running mean: -20.092281\n",
            "resetting env. episode 2601.000000, reward total was -19.000000. running mean: -20.081358\n",
            "resetting env. episode 2602.000000, reward total was -21.000000. running mean: -20.090545\n",
            "resetting env. episode 2603.000000, reward total was -20.000000. running mean: -20.089639\n",
            "resetting env. episode 2604.000000, reward total was -18.000000. running mean: -20.068743\n",
            "resetting env. episode 2605.000000, reward total was -20.000000. running mean: -20.068056\n",
            "resetting env. episode 2606.000000, reward total was -21.000000. running mean: -20.077375\n",
            "resetting env. episode 2607.000000, reward total was -21.000000. running mean: -20.086601\n",
            "resetting env. episode 2608.000000, reward total was -19.000000. running mean: -20.075735\n",
            "resetting env. episode 2609.000000, reward total was -21.000000. running mean: -20.084978\n",
            "resetting env. episode 2610.000000, reward total was -21.000000. running mean: -20.094128\n",
            "resetting env. episode 2611.000000, reward total was -19.000000. running mean: -20.083187\n",
            "resetting env. episode 2612.000000, reward total was -18.000000. running mean: -20.062355\n",
            "resetting env. episode 2613.000000, reward total was -21.000000. running mean: -20.071731\n",
            "resetting env. episode 2614.000000, reward total was -21.000000. running mean: -20.081014\n",
            "resetting env. episode 2615.000000, reward total was -21.000000. running mean: -20.090204\n",
            "resetting env. episode 2616.000000, reward total was -19.000000. running mean: -20.079302\n",
            "resetting env. episode 2617.000000, reward total was -21.000000. running mean: -20.088509\n",
            "resetting env. episode 2618.000000, reward total was -20.000000. running mean: -20.087624\n",
            "resetting env. episode 2619.000000, reward total was -19.000000. running mean: -20.076748\n",
            "resetting env. episode 2620.000000, reward total was -19.000000. running mean: -20.065980\n",
            "resetting env. episode 2621.000000, reward total was -21.000000. running mean: -20.075320\n",
            "resetting env. episode 2622.000000, reward total was -21.000000. running mean: -20.084567\n",
            "resetting env. episode 2623.000000, reward total was -20.000000. running mean: -20.083721\n",
            "resetting env. episode 2624.000000, reward total was -20.000000. running mean: -20.082884\n",
            "resetting env. episode 2625.000000, reward total was -21.000000. running mean: -20.092055\n",
            "resetting env. episode 2626.000000, reward total was -21.000000. running mean: -20.101135\n",
            "resetting env. episode 2627.000000, reward total was -19.000000. running mean: -20.090123\n",
            "resetting env. episode 2628.000000, reward total was -20.000000. running mean: -20.089222\n",
            "resetting env. episode 2629.000000, reward total was -19.000000. running mean: -20.078330\n",
            "resetting env. episode 2630.000000, reward total was -19.000000. running mean: -20.067547\n",
            "resetting env. episode 2631.000000, reward total was -20.000000. running mean: -20.066871\n",
            "resetting env. episode 2632.000000, reward total was -21.000000. running mean: -20.076202\n",
            "resetting env. episode 2633.000000, reward total was -21.000000. running mean: -20.085440\n",
            "resetting env. episode 2634.000000, reward total was -20.000000. running mean: -20.084586\n",
            "resetting env. episode 2635.000000, reward total was -21.000000. running mean: -20.093740\n",
            "resetting env. episode 2636.000000, reward total was -21.000000. running mean: -20.102803\n",
            "resetting env. episode 2637.000000, reward total was -21.000000. running mean: -20.111775\n",
            "resetting env. episode 2638.000000, reward total was -20.000000. running mean: -20.110657\n",
            "resetting env. episode 2639.000000, reward total was -20.000000. running mean: -20.109550\n",
            "resetting env. episode 2640.000000, reward total was -20.000000. running mean: -20.108455\n",
            "resetting env. episode 2641.000000, reward total was -20.000000. running mean: -20.107370\n",
            "resetting env. episode 2642.000000, reward total was -21.000000. running mean: -20.116297\n",
            "resetting env. episode 2643.000000, reward total was -20.000000. running mean: -20.115134\n",
            "resetting env. episode 2644.000000, reward total was -20.000000. running mean: -20.113982\n",
            "resetting env. episode 2645.000000, reward total was -20.000000. running mean: -20.112843\n",
            "resetting env. episode 2646.000000, reward total was -20.000000. running mean: -20.111714\n",
            "resetting env. episode 2647.000000, reward total was -21.000000. running mean: -20.120597\n",
            "resetting env. episode 2648.000000, reward total was -21.000000. running mean: -20.129391\n",
            "resetting env. episode 2649.000000, reward total was -21.000000. running mean: -20.138097\n",
            "resetting env. episode 2650.000000, reward total was -20.000000. running mean: -20.136716\n",
            "resetting env. episode 2651.000000, reward total was -21.000000. running mean: -20.145349\n",
            "resetting env. episode 2652.000000, reward total was -21.000000. running mean: -20.153896\n",
            "resetting env. episode 2653.000000, reward total was -21.000000. running mean: -20.162357\n",
            "resetting env. episode 2654.000000, reward total was -21.000000. running mean: -20.170733\n",
            "resetting env. episode 2655.000000, reward total was -21.000000. running mean: -20.179026\n",
            "resetting env. episode 2656.000000, reward total was -20.000000. running mean: -20.177235\n",
            "resetting env. episode 2657.000000, reward total was -19.000000. running mean: -20.165463\n",
            "resetting env. episode 2658.000000, reward total was -21.000000. running mean: -20.173808\n",
            "resetting env. episode 2659.000000, reward total was -19.000000. running mean: -20.162070\n",
            "resetting env. episode 2660.000000, reward total was -18.000000. running mean: -20.140450\n",
            "resetting env. episode 2661.000000, reward total was -19.000000. running mean: -20.129045\n",
            "resetting env. episode 2662.000000, reward total was -21.000000. running mean: -20.137755\n",
            "resetting env. episode 2663.000000, reward total was -21.000000. running mean: -20.146377\n",
            "resetting env. episode 2664.000000, reward total was -21.000000. running mean: -20.154913\n",
            "resetting env. episode 2665.000000, reward total was -21.000000. running mean: -20.163364\n",
            "resetting env. episode 2666.000000, reward total was -21.000000. running mean: -20.171731\n",
            "resetting env. episode 2667.000000, reward total was -21.000000. running mean: -20.180013\n",
            "resetting env. episode 2668.000000, reward total was -20.000000. running mean: -20.178213\n",
            "resetting env. episode 2669.000000, reward total was -20.000000. running mean: -20.176431\n",
            "resetting env. episode 2670.000000, reward total was -21.000000. running mean: -20.184667\n",
            "resetting env. episode 2671.000000, reward total was -19.000000. running mean: -20.172820\n",
            "resetting env. episode 2672.000000, reward total was -20.000000. running mean: -20.171092\n",
            "resetting env. episode 2673.000000, reward total was -20.000000. running mean: -20.169381\n",
            "resetting env. episode 2674.000000, reward total was -21.000000. running mean: -20.177687\n",
            "resetting env. episode 2675.000000, reward total was -21.000000. running mean: -20.185910\n",
            "resetting env. episode 2676.000000, reward total was -18.000000. running mean: -20.164051\n",
            "resetting env. episode 2677.000000, reward total was -19.000000. running mean: -20.152411\n",
            "resetting env. episode 2678.000000, reward total was -20.000000. running mean: -20.150887\n",
            "resetting env. episode 2679.000000, reward total was -19.000000. running mean: -20.139378\n",
            "resetting env. episode 2680.000000, reward total was -19.000000. running mean: -20.127984\n",
            "resetting env. episode 2681.000000, reward total was -21.000000. running mean: -20.136704\n",
            "resetting env. episode 2682.000000, reward total was -21.000000. running mean: -20.145337\n",
            "resetting env. episode 2683.000000, reward total was -21.000000. running mean: -20.153884\n",
            "resetting env. episode 2684.000000, reward total was -20.000000. running mean: -20.152345\n",
            "resetting env. episode 2685.000000, reward total was -19.000000. running mean: -20.140821\n",
            "resetting env. episode 2686.000000, reward total was -20.000000. running mean: -20.139413\n",
            "resetting env. episode 2687.000000, reward total was -20.000000. running mean: -20.138019\n",
            "resetting env. episode 2688.000000, reward total was -21.000000. running mean: -20.146639\n",
            "resetting env. episode 2689.000000, reward total was -20.000000. running mean: -20.145172\n",
            "resetting env. episode 2690.000000, reward total was -21.000000. running mean: -20.153721\n",
            "resetting env. episode 2691.000000, reward total was -21.000000. running mean: -20.162183\n",
            "resetting env. episode 2692.000000, reward total was -18.000000. running mean: -20.140562\n",
            "resetting env. episode 2693.000000, reward total was -20.000000. running mean: -20.139156\n",
            "resetting env. episode 2694.000000, reward total was -18.000000. running mean: -20.117764\n",
            "resetting env. episode 2695.000000, reward total was -21.000000. running mean: -20.126587\n",
            "resetting env. episode 2696.000000, reward total was -21.000000. running mean: -20.135321\n",
            "resetting env. episode 2697.000000, reward total was -18.000000. running mean: -20.113968\n",
            "resetting env. episode 2698.000000, reward total was -20.000000. running mean: -20.112828\n",
            "resetting env. episode 2699.000000, reward total was -20.000000. running mean: -20.111700\n",
            "resetting env. episode 2700.000000, reward total was -21.000000. running mean: -20.120583\n",
            "resetting env. episode 2701.000000, reward total was -20.000000. running mean: -20.119377\n",
            "resetting env. episode 2702.000000, reward total was -18.000000. running mean: -20.098183\n",
            "resetting env. episode 2703.000000, reward total was -19.000000. running mean: -20.087201\n",
            "resetting env. episode 2704.000000, reward total was -21.000000. running mean: -20.096329\n",
            "resetting env. episode 2705.000000, reward total was -20.000000. running mean: -20.095366\n",
            "resetting env. episode 2706.000000, reward total was -20.000000. running mean: -20.094412\n",
            "resetting env. episode 2707.000000, reward total was -18.000000. running mean: -20.073468\n",
            "resetting env. episode 2708.000000, reward total was -21.000000. running mean: -20.082734\n",
            "resetting env. episode 2709.000000, reward total was -21.000000. running mean: -20.091906\n",
            "resetting env. episode 2710.000000, reward total was -20.000000. running mean: -20.090987\n",
            "resetting env. episode 2711.000000, reward total was -19.000000. running mean: -20.080077\n",
            "resetting env. episode 2712.000000, reward total was -19.000000. running mean: -20.069277\n",
            "resetting env. episode 2713.000000, reward total was -21.000000. running mean: -20.078584\n",
            "resetting env. episode 2714.000000, reward total was -21.000000. running mean: -20.087798\n",
            "resetting env. episode 2715.000000, reward total was -20.000000. running mean: -20.086920\n",
            "resetting env. episode 2716.000000, reward total was -21.000000. running mean: -20.096051\n",
            "resetting env. episode 2717.000000, reward total was -20.000000. running mean: -20.095090\n",
            "resetting env. episode 2718.000000, reward total was -21.000000. running mean: -20.104139\n",
            "resetting env. episode 2719.000000, reward total was -21.000000. running mean: -20.113098\n",
            "resetting env. episode 2720.000000, reward total was -20.000000. running mean: -20.111967\n",
            "resetting env. episode 2721.000000, reward total was -20.000000. running mean: -20.110847\n",
            "resetting env. episode 2722.000000, reward total was -21.000000. running mean: -20.119739\n",
            "resetting env. episode 2723.000000, reward total was -21.000000. running mean: -20.128541\n",
            "resetting env. episode 2724.000000, reward total was -21.000000. running mean: -20.137256\n",
            "resetting env. episode 2725.000000, reward total was -21.000000. running mean: -20.145883\n",
            "resetting env. episode 2726.000000, reward total was -21.000000. running mean: -20.154425\n",
            "resetting env. episode 2727.000000, reward total was -19.000000. running mean: -20.142880\n",
            "resetting env. episode 2728.000000, reward total was -17.000000. running mean: -20.111452\n",
            "resetting env. episode 2729.000000, reward total was -19.000000. running mean: -20.100337\n",
            "resetting env. episode 2730.000000, reward total was -20.000000. running mean: -20.099334\n",
            "resetting env. episode 2731.000000, reward total was -19.000000. running mean: -20.088340\n",
            "resetting env. episode 2732.000000, reward total was -20.000000. running mean: -20.087457\n",
            "resetting env. episode 2733.000000, reward total was -20.000000. running mean: -20.086582\n",
            "resetting env. episode 2734.000000, reward total was -20.000000. running mean: -20.085717\n",
            "resetting env. episode 2735.000000, reward total was -20.000000. running mean: -20.084859\n",
            "resetting env. episode 2736.000000, reward total was -20.000000. running mean: -20.084011\n",
            "resetting env. episode 2737.000000, reward total was -20.000000. running mean: -20.083171\n",
            "resetting env. episode 2738.000000, reward total was -20.000000. running mean: -20.082339\n",
            "resetting env. episode 2739.000000, reward total was -20.000000. running mean: -20.081516\n",
            "resetting env. episode 2740.000000, reward total was -20.000000. running mean: -20.080700\n",
            "resetting env. episode 2741.000000, reward total was -19.000000. running mean: -20.069893\n",
            "resetting env. episode 2742.000000, reward total was -21.000000. running mean: -20.079195\n",
            "resetting env. episode 2743.000000, reward total was -20.000000. running mean: -20.078403\n",
            "resetting env. episode 2744.000000, reward total was -21.000000. running mean: -20.087619\n",
            "resetting env. episode 2745.000000, reward total was -19.000000. running mean: -20.076742\n",
            "resetting env. episode 2746.000000, reward total was -19.000000. running mean: -20.065975\n",
            "resetting env. episode 2747.000000, reward total was -18.000000. running mean: -20.045315\n",
            "resetting env. episode 2748.000000, reward total was -20.000000. running mean: -20.044862\n",
            "resetting env. episode 2749.000000, reward total was -21.000000. running mean: -20.054413\n",
            "resetting env. episode 2750.000000, reward total was -20.000000. running mean: -20.053869\n",
            "resetting env. episode 2751.000000, reward total was -21.000000. running mean: -20.063331\n",
            "resetting env. episode 2752.000000, reward total was -21.000000. running mean: -20.072697\n",
            "resetting env. episode 2753.000000, reward total was -20.000000. running mean: -20.071970\n",
            "resetting env. episode 2754.000000, reward total was -20.000000. running mean: -20.071251\n",
            "resetting env. episode 2755.000000, reward total was -20.000000. running mean: -20.070538\n",
            "resetting env. episode 2756.000000, reward total was -21.000000. running mean: -20.079833\n",
            "resetting env. episode 2757.000000, reward total was -21.000000. running mean: -20.089034\n",
            "resetting env. episode 2758.000000, reward total was -20.000000. running mean: -20.088144\n",
            "resetting env. episode 2759.000000, reward total was -20.000000. running mean: -20.087263\n",
            "resetting env. episode 2760.000000, reward total was -21.000000. running mean: -20.096390\n",
            "resetting env. episode 2761.000000, reward total was -19.000000. running mean: -20.085426\n",
            "resetting env. episode 2762.000000, reward total was -19.000000. running mean: -20.074572\n",
            "resetting env. episode 2763.000000, reward total was -21.000000. running mean: -20.083826\n",
            "resetting env. episode 2764.000000, reward total was -19.000000. running mean: -20.072988\n",
            "resetting env. episode 2765.000000, reward total was -21.000000. running mean: -20.082258\n",
            "resetting env. episode 2766.000000, reward total was -20.000000. running mean: -20.081435\n",
            "resetting env. episode 2767.000000, reward total was -19.000000. running mean: -20.070621\n",
            "resetting env. episode 2768.000000, reward total was -20.000000. running mean: -20.069915\n",
            "resetting env. episode 2769.000000, reward total was -19.000000. running mean: -20.059216\n",
            "resetting env. episode 2770.000000, reward total was -20.000000. running mean: -20.058624\n",
            "resetting env. episode 2771.000000, reward total was -21.000000. running mean: -20.068037\n",
            "resetting env. episode 2772.000000, reward total was -21.000000. running mean: -20.077357\n",
            "resetting env. episode 2773.000000, reward total was -21.000000. running mean: -20.086583\n",
            "resetting env. episode 2774.000000, reward total was -21.000000. running mean: -20.095718\n",
            "resetting env. episode 2775.000000, reward total was -21.000000. running mean: -20.104760\n",
            "resetting env. episode 2776.000000, reward total was -21.000000. running mean: -20.113713\n",
            "resetting env. episode 2777.000000, reward total was -20.000000. running mean: -20.112576\n",
            "resetting env. episode 2778.000000, reward total was -21.000000. running mean: -20.121450\n",
            "resetting env. episode 2779.000000, reward total was -21.000000. running mean: -20.130235\n",
            "resetting env. episode 2780.000000, reward total was -20.000000. running mean: -20.128933\n",
            "resetting env. episode 2781.000000, reward total was -20.000000. running mean: -20.127644\n",
            "resetting env. episode 2782.000000, reward total was -20.000000. running mean: -20.126367\n",
            "resetting env. episode 2783.000000, reward total was -19.000000. running mean: -20.115104\n",
            "resetting env. episode 2784.000000, reward total was -21.000000. running mean: -20.123953\n",
            "resetting env. episode 2785.000000, reward total was -20.000000. running mean: -20.122713\n",
            "resetting env. episode 2786.000000, reward total was -21.000000. running mean: -20.131486\n",
            "resetting env. episode 2787.000000, reward total was -21.000000. running mean: -20.140171\n",
            "resetting env. episode 2788.000000, reward total was -21.000000. running mean: -20.148769\n",
            "resetting env. episode 2789.000000, reward total was -20.000000. running mean: -20.147282\n",
            "resetting env. episode 2790.000000, reward total was -21.000000. running mean: -20.155809\n",
            "resetting env. episode 2791.000000, reward total was -20.000000. running mean: -20.154251\n",
            "resetting env. episode 2792.000000, reward total was -20.000000. running mean: -20.152708\n",
            "resetting env. episode 2793.000000, reward total was -19.000000. running mean: -20.141181\n",
            "resetting env. episode 2794.000000, reward total was -20.000000. running mean: -20.139769\n",
            "resetting env. episode 2795.000000, reward total was -20.000000. running mean: -20.138372\n",
            "resetting env. episode 2796.000000, reward total was -21.000000. running mean: -20.146988\n",
            "resetting env. episode 2797.000000, reward total was -21.000000. running mean: -20.155518\n",
            "resetting env. episode 2798.000000, reward total was -19.000000. running mean: -20.143963\n",
            "resetting env. episode 2799.000000, reward total was -21.000000. running mean: -20.152523\n",
            "resetting env. episode 2800.000000, reward total was -21.000000. running mean: -20.160998\n",
            "resetting env. episode 2801.000000, reward total was -16.000000. running mean: -20.119388\n",
            "resetting env. episode 2802.000000, reward total was -21.000000. running mean: -20.128194\n",
            "resetting env. episode 2803.000000, reward total was -21.000000. running mean: -20.136912\n",
            "resetting env. episode 2804.000000, reward total was -19.000000. running mean: -20.125543\n",
            "resetting env. episode 2805.000000, reward total was -20.000000. running mean: -20.124288\n",
            "resetting env. episode 2806.000000, reward total was -20.000000. running mean: -20.123045\n",
            "resetting env. episode 2807.000000, reward total was -21.000000. running mean: -20.131814\n",
            "resetting env. episode 2808.000000, reward total was -20.000000. running mean: -20.130496\n",
            "resetting env. episode 2809.000000, reward total was -18.000000. running mean: -20.109191\n",
            "resetting env. episode 2810.000000, reward total was -19.000000. running mean: -20.098099\n",
            "resetting env. episode 2811.000000, reward total was -21.000000. running mean: -20.107118\n",
            "resetting env. episode 2812.000000, reward total was -19.000000. running mean: -20.096047\n",
            "resetting env. episode 2813.000000, reward total was -19.000000. running mean: -20.085087\n",
            "resetting env. episode 2814.000000, reward total was -20.000000. running mean: -20.084236\n",
            "resetting env. episode 2815.000000, reward total was -19.000000. running mean: -20.073393\n",
            "resetting env. episode 2816.000000, reward total was -20.000000. running mean: -20.072659\n",
            "resetting env. episode 2817.000000, reward total was -21.000000. running mean: -20.081933\n",
            "resetting env. episode 2818.000000, reward total was -21.000000. running mean: -20.091114\n",
            "resetting env. episode 2819.000000, reward total was -21.000000. running mean: -20.100202\n",
            "resetting env. episode 2820.000000, reward total was -20.000000. running mean: -20.099200\n",
            "resetting env. episode 2821.000000, reward total was -21.000000. running mean: -20.108208\n",
            "resetting env. episode 2822.000000, reward total was -18.000000. running mean: -20.087126\n",
            "resetting env. episode 2823.000000, reward total was -20.000000. running mean: -20.086255\n",
            "resetting env. episode 2824.000000, reward total was -21.000000. running mean: -20.095392\n",
            "resetting env. episode 2825.000000, reward total was -19.000000. running mean: -20.084439\n",
            "resetting env. episode 2826.000000, reward total was -21.000000. running mean: -20.093594\n",
            "resetting env. episode 2827.000000, reward total was -21.000000. running mean: -20.102658\n",
            "resetting env. episode 2828.000000, reward total was -19.000000. running mean: -20.091632\n",
            "resetting env. episode 2829.000000, reward total was -21.000000. running mean: -20.100715\n",
            "resetting env. episode 2830.000000, reward total was -19.000000. running mean: -20.089708\n",
            "resetting env. episode 2831.000000, reward total was -21.000000. running mean: -20.098811\n",
            "resetting env. episode 2832.000000, reward total was -21.000000. running mean: -20.107823\n",
            "resetting env. episode 2833.000000, reward total was -21.000000. running mean: -20.116745\n",
            "resetting env. episode 2834.000000, reward total was -18.000000. running mean: -20.095577\n",
            "resetting env. episode 2835.000000, reward total was -17.000000. running mean: -20.064622\n",
            "resetting env. episode 2836.000000, reward total was -19.000000. running mean: -20.053975\n",
            "resetting env. episode 2837.000000, reward total was -21.000000. running mean: -20.063436\n",
            "resetting env. episode 2838.000000, reward total was -20.000000. running mean: -20.062801\n",
            "resetting env. episode 2839.000000, reward total was -20.000000. running mean: -20.062173\n",
            "resetting env. episode 2840.000000, reward total was -20.000000. running mean: -20.061551\n",
            "resetting env. episode 2841.000000, reward total was -19.000000. running mean: -20.050936\n",
            "resetting env. episode 2842.000000, reward total was -19.000000. running mean: -20.040427\n",
            "resetting env. episode 2843.000000, reward total was -21.000000. running mean: -20.050022\n",
            "resetting env. episode 2844.000000, reward total was -21.000000. running mean: -20.059522\n",
            "resetting env. episode 2845.000000, reward total was -21.000000. running mean: -20.068927\n",
            "resetting env. episode 2846.000000, reward total was -21.000000. running mean: -20.078238\n",
            "resetting env. episode 2847.000000, reward total was -21.000000. running mean: -20.087455\n",
            "resetting env. episode 2848.000000, reward total was -20.000000. running mean: -20.086581\n",
            "resetting env. episode 2849.000000, reward total was -19.000000. running mean: -20.075715\n",
            "resetting env. episode 2850.000000, reward total was -19.000000. running mean: -20.064958\n",
            "resetting env. episode 2851.000000, reward total was -20.000000. running mean: -20.064308\n",
            "resetting env. episode 2852.000000, reward total was -21.000000. running mean: -20.073665\n",
            "resetting env. episode 2853.000000, reward total was -21.000000. running mean: -20.082928\n",
            "resetting env. episode 2854.000000, reward total was -20.000000. running mean: -20.082099\n",
            "resetting env. episode 2855.000000, reward total was -19.000000. running mean: -20.071278\n",
            "resetting env. episode 2856.000000, reward total was -20.000000. running mean: -20.070565\n",
            "resetting env. episode 2857.000000, reward total was -19.000000. running mean: -20.059860\n",
            "resetting env. episode 2858.000000, reward total was -21.000000. running mean: -20.069261\n",
            "resetting env. episode 2859.000000, reward total was -21.000000. running mean: -20.078569\n",
            "resetting env. episode 2860.000000, reward total was -19.000000. running mean: -20.067783\n",
            "resetting env. episode 2861.000000, reward total was -20.000000. running mean: -20.067105\n",
            "resetting env. episode 2862.000000, reward total was -19.000000. running mean: -20.056434\n",
            "resetting env. episode 2863.000000, reward total was -21.000000. running mean: -20.065870\n",
            "resetting env. episode 2864.000000, reward total was -21.000000. running mean: -20.075211\n",
            "resetting env. episode 2865.000000, reward total was -20.000000. running mean: -20.074459\n",
            "resetting env. episode 2866.000000, reward total was -19.000000. running mean: -20.063714\n",
            "resetting env. episode 2867.000000, reward total was -21.000000. running mean: -20.073077\n",
            "resetting env. episode 2868.000000, reward total was -20.000000. running mean: -20.072346\n",
            "resetting env. episode 2869.000000, reward total was -20.000000. running mean: -20.071623\n",
            "resetting env. episode 2870.000000, reward total was -20.000000. running mean: -20.070907\n",
            "resetting env. episode 2871.000000, reward total was -20.000000. running mean: -20.070198\n",
            "resetting env. episode 2872.000000, reward total was -21.000000. running mean: -20.079496\n",
            "resetting env. episode 2873.000000, reward total was -19.000000. running mean: -20.068701\n",
            "resetting env. episode 2874.000000, reward total was -21.000000. running mean: -20.078014\n",
            "resetting env. episode 2875.000000, reward total was -19.000000. running mean: -20.067233\n",
            "resetting env. episode 2876.000000, reward total was -21.000000. running mean: -20.076561\n",
            "resetting env. episode 2877.000000, reward total was -21.000000. running mean: -20.085796\n",
            "resetting env. episode 2878.000000, reward total was -21.000000. running mean: -20.094938\n",
            "resetting env. episode 2879.000000, reward total was -20.000000. running mean: -20.093988\n",
            "resetting env. episode 2880.000000, reward total was -18.000000. running mean: -20.073048\n",
            "resetting env. episode 2881.000000, reward total was -20.000000. running mean: -20.072318\n",
            "resetting env. episode 2882.000000, reward total was -21.000000. running mean: -20.081595\n",
            "resetting env. episode 2883.000000, reward total was -21.000000. running mean: -20.090779\n",
            "resetting env. episode 2884.000000, reward total was -20.000000. running mean: -20.089871\n",
            "resetting env. episode 2885.000000, reward total was -21.000000. running mean: -20.098972\n",
            "resetting env. episode 2886.000000, reward total was -20.000000. running mean: -20.097982\n",
            "resetting env. episode 2887.000000, reward total was -20.000000. running mean: -20.097003\n",
            "resetting env. episode 2888.000000, reward total was -19.000000. running mean: -20.086033\n",
            "resetting env. episode 2889.000000, reward total was -20.000000. running mean: -20.085172\n",
            "resetting env. episode 2890.000000, reward total was -18.000000. running mean: -20.064321\n",
            "resetting env. episode 2891.000000, reward total was -21.000000. running mean: -20.073677\n",
            "resetting env. episode 2892.000000, reward total was -21.000000. running mean: -20.082941\n",
            "resetting env. episode 2893.000000, reward total was -21.000000. running mean: -20.092111\n",
            "resetting env. episode 2894.000000, reward total was -19.000000. running mean: -20.081190\n",
            "resetting env. episode 2895.000000, reward total was -17.000000. running mean: -20.050378\n",
            "resetting env. episode 2896.000000, reward total was -20.000000. running mean: -20.049874\n",
            "resetting env. episode 2897.000000, reward total was -21.000000. running mean: -20.059376\n",
            "resetting env. episode 2898.000000, reward total was -21.000000. running mean: -20.068782\n",
            "resetting env. episode 2899.000000, reward total was -20.000000. running mean: -20.068094\n",
            "resetting env. episode 2900.000000, reward total was -20.000000. running mean: -20.067413\n",
            "resetting env. episode 2901.000000, reward total was -20.000000. running mean: -20.066739\n",
            "resetting env. episode 2902.000000, reward total was -21.000000. running mean: -20.076072\n",
            "resetting env. episode 2903.000000, reward total was -21.000000. running mean: -20.085311\n",
            "resetting env. episode 2904.000000, reward total was -17.000000. running mean: -20.054458\n",
            "resetting env. episode 2905.000000, reward total was -21.000000. running mean: -20.063913\n",
            "resetting env. episode 2906.000000, reward total was -21.000000. running mean: -20.073274\n",
            "resetting env. episode 2907.000000, reward total was -21.000000. running mean: -20.082541\n",
            "resetting env. episode 2908.000000, reward total was -20.000000. running mean: -20.081716\n",
            "resetting env. episode 2909.000000, reward total was -20.000000. running mean: -20.080899\n",
            "resetting env. episode 2910.000000, reward total was -19.000000. running mean: -20.070090\n",
            "resetting env. episode 2911.000000, reward total was -21.000000. running mean: -20.079389\n",
            "resetting env. episode 2912.000000, reward total was -19.000000. running mean: -20.068595\n",
            "resetting env. episode 2913.000000, reward total was -18.000000. running mean: -20.047909\n",
            "resetting env. episode 2914.000000, reward total was -20.000000. running mean: -20.047430\n",
            "resetting env. episode 2915.000000, reward total was -20.000000. running mean: -20.046956\n",
            "resetting env. episode 2916.000000, reward total was -20.000000. running mean: -20.046486\n",
            "resetting env. episode 2917.000000, reward total was -20.000000. running mean: -20.046021\n",
            "resetting env. episode 2918.000000, reward total was -21.000000. running mean: -20.055561\n",
            "resetting env. episode 2919.000000, reward total was -20.000000. running mean: -20.055005\n",
            "resetting env. episode 2920.000000, reward total was -19.000000. running mean: -20.044455\n",
            "resetting env. episode 2921.000000, reward total was -21.000000. running mean: -20.054011\n",
            "resetting env. episode 2922.000000, reward total was -20.000000. running mean: -20.053471\n",
            "resetting env. episode 2923.000000, reward total was -21.000000. running mean: -20.062936\n",
            "resetting env. episode 2924.000000, reward total was -21.000000. running mean: -20.072307\n",
            "resetting env. episode 2925.000000, reward total was -18.000000. running mean: -20.051584\n",
            "resetting env. episode 2926.000000, reward total was -21.000000. running mean: -20.061068\n",
            "resetting env. episode 2927.000000, reward total was -21.000000. running mean: -20.070457\n",
            "resetting env. episode 2928.000000, reward total was -21.000000. running mean: -20.079752\n",
            "resetting env. episode 2929.000000, reward total was -19.000000. running mean: -20.068955\n",
            "resetting env. episode 2930.000000, reward total was -19.000000. running mean: -20.058265\n",
            "resetting env. episode 2931.000000, reward total was -21.000000. running mean: -20.067683\n",
            "resetting env. episode 2932.000000, reward total was -21.000000. running mean: -20.077006\n",
            "resetting env. episode 2933.000000, reward total was -21.000000. running mean: -20.086236\n",
            "resetting env. episode 2934.000000, reward total was -18.000000. running mean: -20.065374\n",
            "resetting env. episode 2935.000000, reward total was -21.000000. running mean: -20.074720\n",
            "resetting env. episode 2936.000000, reward total was -19.000000. running mean: -20.063973\n",
            "resetting env. episode 2937.000000, reward total was -21.000000. running mean: -20.073333\n",
            "resetting env. episode 2938.000000, reward total was -20.000000. running mean: -20.072600\n",
            "resetting env. episode 2939.000000, reward total was -20.000000. running mean: -20.071874\n",
            "resetting env. episode 2940.000000, reward total was -19.000000. running mean: -20.061155\n",
            "resetting env. episode 2941.000000, reward total was -21.000000. running mean: -20.070543\n",
            "resetting env. episode 2942.000000, reward total was -20.000000. running mean: -20.069838\n",
            "resetting env. episode 2943.000000, reward total was -19.000000. running mean: -20.059139\n",
            "resetting env. episode 2944.000000, reward total was -20.000000. running mean: -20.058548\n",
            "resetting env. episode 2945.000000, reward total was -21.000000. running mean: -20.067963\n",
            "resetting env. episode 2946.000000, reward total was -19.000000. running mean: -20.057283\n",
            "resetting env. episode 2947.000000, reward total was -19.000000. running mean: -20.046710\n",
            "resetting env. episode 2948.000000, reward total was -20.000000. running mean: -20.046243\n",
            "resetting env. episode 2949.000000, reward total was -18.000000. running mean: -20.025781\n",
            "resetting env. episode 2950.000000, reward total was -19.000000. running mean: -20.015523\n",
            "resetting env. episode 2951.000000, reward total was -20.000000. running mean: -20.015368\n",
            "resetting env. episode 2952.000000, reward total was -20.000000. running mean: -20.015214\n",
            "resetting env. episode 2953.000000, reward total was -20.000000. running mean: -20.015062\n",
            "resetting env. episode 2954.000000, reward total was -19.000000. running mean: -20.004911\n",
            "resetting env. episode 2955.000000, reward total was -20.000000. running mean: -20.004862\n",
            "resetting env. episode 2956.000000, reward total was -21.000000. running mean: -20.014813\n",
            "resetting env. episode 2957.000000, reward total was -21.000000. running mean: -20.024665\n",
            "resetting env. episode 2958.000000, reward total was -20.000000. running mean: -20.024419\n",
            "resetting env. episode 2959.000000, reward total was -20.000000. running mean: -20.024174\n",
            "resetting env. episode 2960.000000, reward total was -21.000000. running mean: -20.033933\n",
            "resetting env. episode 2961.000000, reward total was -20.000000. running mean: -20.033593\n",
            "resetting env. episode 2962.000000, reward total was -21.000000. running mean: -20.043257\n",
            "resetting env. episode 2963.000000, reward total was -21.000000. running mean: -20.052825\n",
            "resetting env. episode 2964.000000, reward total was -20.000000. running mean: -20.052297\n",
            "resetting env. episode 2965.000000, reward total was -20.000000. running mean: -20.051774\n",
            "resetting env. episode 2966.000000, reward total was -21.000000. running mean: -20.061256\n",
            "resetting env. episode 2967.000000, reward total was -20.000000. running mean: -20.060643\n",
            "resetting env. episode 2968.000000, reward total was -21.000000. running mean: -20.070037\n",
            "resetting env. episode 2969.000000, reward total was -21.000000. running mean: -20.079337\n",
            "resetting env. episode 2970.000000, reward total was -19.000000. running mean: -20.068543\n",
            "resetting env. episode 2971.000000, reward total was -20.000000. running mean: -20.067858\n",
            "resetting env. episode 2972.000000, reward total was -20.000000. running mean: -20.067179\n",
            "resetting env. episode 2973.000000, reward total was -21.000000. running mean: -20.076507\n",
            "resetting env. episode 2974.000000, reward total was -19.000000. running mean: -20.065742\n",
            "resetting env. episode 2975.000000, reward total was -20.000000. running mean: -20.065085\n",
            "resetting env. episode 2976.000000, reward total was -21.000000. running mean: -20.074434\n",
            "resetting env. episode 2977.000000, reward total was -20.000000. running mean: -20.073690\n",
            "resetting env. episode 2978.000000, reward total was -21.000000. running mean: -20.082953\n",
            "resetting env. episode 2979.000000, reward total was -19.000000. running mean: -20.072123\n",
            "resetting env. episode 2980.000000, reward total was -20.000000. running mean: -20.071402\n",
            "resetting env. episode 2981.000000, reward total was -20.000000. running mean: -20.070688\n",
            "resetting env. episode 2982.000000, reward total was -20.000000. running mean: -20.069981\n",
            "resetting env. episode 2983.000000, reward total was -20.000000. running mean: -20.069281\n",
            "resetting env. episode 2984.000000, reward total was -21.000000. running mean: -20.078588\n",
            "resetting env. episode 2985.000000, reward total was -21.000000. running mean: -20.087803\n",
            "resetting env. episode 2986.000000, reward total was -18.000000. running mean: -20.066925\n",
            "resetting env. episode 2987.000000, reward total was -21.000000. running mean: -20.076255\n",
            "resetting env. episode 2988.000000, reward total was -20.000000. running mean: -20.075493\n",
            "resetting env. episode 2989.000000, reward total was -21.000000. running mean: -20.084738\n",
            "resetting env. episode 2990.000000, reward total was -21.000000. running mean: -20.093890\n",
            "resetting env. episode 2991.000000, reward total was -21.000000. running mean: -20.102952\n",
            "resetting env. episode 2992.000000, reward total was -20.000000. running mean: -20.101922\n",
            "resetting env. episode 2993.000000, reward total was -19.000000. running mean: -20.090903\n",
            "resetting env. episode 2994.000000, reward total was -19.000000. running mean: -20.079994\n",
            "resetting env. episode 2995.000000, reward total was -21.000000. running mean: -20.089194\n",
            "resetting env. episode 2996.000000, reward total was -18.000000. running mean: -20.068302\n",
            "resetting env. episode 2997.000000, reward total was -20.000000. running mean: -20.067619\n",
            "resetting env. episode 2998.000000, reward total was -19.000000. running mean: -20.056943\n",
            "resetting env. episode 2999.000000, reward total was -21.000000. running mean: -20.066373\n",
            "resetting env. episode 3000.000000, reward total was -20.000000. running mean: -20.065710\n",
            "resetting env. episode 3001.000000, reward total was -21.000000. running mean: -20.075052\n",
            "resetting env. episode 3002.000000, reward total was -20.000000. running mean: -20.074302\n",
            "resetting env. episode 3003.000000, reward total was -21.000000. running mean: -20.083559\n",
            "resetting env. episode 3004.000000, reward total was -21.000000. running mean: -20.092723\n",
            "resetting env. episode 3005.000000, reward total was -21.000000. running mean: -20.101796\n",
            "resetting env. episode 3006.000000, reward total was -19.000000. running mean: -20.090778\n",
            "resetting env. episode 3007.000000, reward total was -20.000000. running mean: -20.089870\n",
            "resetting env. episode 3008.000000, reward total was -19.000000. running mean: -20.078972\n",
            "resetting env. episode 3009.000000, reward total was -21.000000. running mean: -20.088182\n",
            "resetting env. episode 3010.000000, reward total was -21.000000. running mean: -20.097300\n",
            "resetting env. episode 3011.000000, reward total was -19.000000. running mean: -20.086327\n",
            "resetting env. episode 3012.000000, reward total was -20.000000. running mean: -20.085464\n",
            "resetting env. episode 3013.000000, reward total was -20.000000. running mean: -20.084609\n",
            "resetting env. episode 3014.000000, reward total was -19.000000. running mean: -20.073763\n",
            "resetting env. episode 3015.000000, reward total was -20.000000. running mean: -20.073025\n",
            "resetting env. episode 3016.000000, reward total was -20.000000. running mean: -20.072295\n",
            "resetting env. episode 3017.000000, reward total was -19.000000. running mean: -20.061572\n",
            "resetting env. episode 3018.000000, reward total was -18.000000. running mean: -20.040957\n",
            "resetting env. episode 3019.000000, reward total was -19.000000. running mean: -20.030547\n",
            "resetting env. episode 3020.000000, reward total was -20.000000. running mean: -20.030242\n",
            "resetting env. episode 3021.000000, reward total was -20.000000. running mean: -20.029939\n",
            "resetting env. episode 3022.000000, reward total was -20.000000. running mean: -20.029640\n",
            "resetting env. episode 3023.000000, reward total was -19.000000. running mean: -20.019343\n",
            "resetting env. episode 3024.000000, reward total was -20.000000. running mean: -20.019150\n",
            "resetting env. episode 3025.000000, reward total was -21.000000. running mean: -20.028958\n",
            "resetting env. episode 3026.000000, reward total was -21.000000. running mean: -20.038669\n",
            "resetting env. episode 3027.000000, reward total was -21.000000. running mean: -20.048282\n",
            "resetting env. episode 3028.000000, reward total was -21.000000. running mean: -20.057799\n",
            "resetting env. episode 3029.000000, reward total was -20.000000. running mean: -20.057221\n",
            "resetting env. episode 3030.000000, reward total was -21.000000. running mean: -20.066649\n",
            "resetting env. episode 3031.000000, reward total was -20.000000. running mean: -20.065983\n",
            "resetting env. episode 3032.000000, reward total was -20.000000. running mean: -20.065323\n",
            "resetting env. episode 3033.000000, reward total was -20.000000. running mean: -20.064670\n",
            "resetting env. episode 3034.000000, reward total was -21.000000. running mean: -20.074023\n",
            "resetting env. episode 3035.000000, reward total was -19.000000. running mean: -20.063283\n",
            "resetting env. episode 3036.000000, reward total was -20.000000. running mean: -20.062650\n",
            "resetting env. episode 3037.000000, reward total was -20.000000. running mean: -20.062023\n",
            "resetting env. episode 3038.000000, reward total was -20.000000. running mean: -20.061403\n",
            "resetting env. episode 3039.000000, reward total was -21.000000. running mean: -20.070789\n",
            "resetting env. episode 3040.000000, reward total was -20.000000. running mean: -20.070081\n",
            "resetting env. episode 3041.000000, reward total was -19.000000. running mean: -20.059380\n",
            "resetting env. episode 3042.000000, reward total was -20.000000. running mean: -20.058787\n",
            "resetting env. episode 3043.000000, reward total was -21.000000. running mean: -20.068199\n",
            "resetting env. episode 3044.000000, reward total was -21.000000. running mean: -20.077517\n",
            "resetting env. episode 3045.000000, reward total was -21.000000. running mean: -20.086741\n",
            "resetting env. episode 3046.000000, reward total was -21.000000. running mean: -20.095874\n",
            "resetting env. episode 3047.000000, reward total was -20.000000. running mean: -20.094915\n",
            "resetting env. episode 3048.000000, reward total was -20.000000. running mean: -20.093966\n",
            "resetting env. episode 3049.000000, reward total was -19.000000. running mean: -20.083027\n",
            "resetting env. episode 3050.000000, reward total was -21.000000. running mean: -20.092196\n",
            "resetting env. episode 3051.000000, reward total was -18.000000. running mean: -20.071274\n",
            "resetting env. episode 3052.000000, reward total was -19.000000. running mean: -20.060562\n",
            "resetting env. episode 3053.000000, reward total was -20.000000. running mean: -20.059956\n",
            "resetting env. episode 3054.000000, reward total was -21.000000. running mean: -20.069356\n",
            "resetting env. episode 3055.000000, reward total was -21.000000. running mean: -20.078663\n",
            "resetting env. episode 3056.000000, reward total was -20.000000. running mean: -20.077876\n",
            "resetting env. episode 3057.000000, reward total was -19.000000. running mean: -20.067097\n",
            "resetting env. episode 3058.000000, reward total was -19.000000. running mean: -20.056426\n",
            "resetting env. episode 3059.000000, reward total was -20.000000. running mean: -20.055862\n",
            "resetting env. episode 3060.000000, reward total was -21.000000. running mean: -20.065304\n",
            "resetting env. episode 3061.000000, reward total was -20.000000. running mean: -20.064651\n",
            "resetting env. episode 3062.000000, reward total was -21.000000. running mean: -20.074004\n",
            "resetting env. episode 3063.000000, reward total was -19.000000. running mean: -20.063264\n",
            "resetting env. episode 3064.000000, reward total was -21.000000. running mean: -20.072631\n",
            "resetting env. episode 3065.000000, reward total was -21.000000. running mean: -20.081905\n",
            "resetting env. episode 3066.000000, reward total was -21.000000. running mean: -20.091086\n",
            "resetting env. episode 3067.000000, reward total was -21.000000. running mean: -20.100175\n",
            "resetting env. episode 3068.000000, reward total was -17.000000. running mean: -20.069173\n",
            "resetting env. episode 3069.000000, reward total was -21.000000. running mean: -20.078482\n",
            "resetting env. episode 3070.000000, reward total was -21.000000. running mean: -20.087697\n",
            "resetting env. episode 3071.000000, reward total was -20.000000. running mean: -20.086820\n",
            "resetting env. episode 3072.000000, reward total was -20.000000. running mean: -20.085952\n",
            "resetting env. episode 3073.000000, reward total was -20.000000. running mean: -20.085092\n",
            "resetting env. episode 3074.000000, reward total was -21.000000. running mean: -20.094241\n",
            "resetting env. episode 3075.000000, reward total was -19.000000. running mean: -20.083299\n",
            "resetting env. episode 3076.000000, reward total was -21.000000. running mean: -20.092466\n",
            "resetting env. episode 3077.000000, reward total was -21.000000. running mean: -20.101541\n",
            "resetting env. episode 3078.000000, reward total was -20.000000. running mean: -20.100526\n",
            "resetting env. episode 3079.000000, reward total was -21.000000. running mean: -20.109520\n",
            "resetting env. episode 3080.000000, reward total was -19.000000. running mean: -20.098425\n",
            "resetting env. episode 3081.000000, reward total was -21.000000. running mean: -20.107441\n",
            "resetting env. episode 3082.000000, reward total was -21.000000. running mean: -20.116367\n",
            "resetting env. episode 3083.000000, reward total was -19.000000. running mean: -20.105203\n",
            "resetting env. episode 3084.000000, reward total was -20.000000. running mean: -20.104151\n",
            "resetting env. episode 3085.000000, reward total was -21.000000. running mean: -20.113109\n",
            "resetting env. episode 3086.000000, reward total was -19.000000. running mean: -20.101978\n",
            "resetting env. episode 3087.000000, reward total was -21.000000. running mean: -20.110959\n",
            "resetting env. episode 3088.000000, reward total was -20.000000. running mean: -20.109849\n",
            "resetting env. episode 3089.000000, reward total was -21.000000. running mean: -20.118750\n",
            "resetting env. episode 3090.000000, reward total was -19.000000. running mean: -20.107563\n",
            "resetting env. episode 3091.000000, reward total was -20.000000. running mean: -20.106487\n",
            "resetting env. episode 3092.000000, reward total was -20.000000. running mean: -20.105422\n",
            "resetting env. episode 3093.000000, reward total was -19.000000. running mean: -20.094368\n",
            "resetting env. episode 3094.000000, reward total was -21.000000. running mean: -20.103425\n",
            "resetting env. episode 3095.000000, reward total was -21.000000. running mean: -20.112390\n",
            "resetting env. episode 3096.000000, reward total was -20.000000. running mean: -20.111266\n",
            "resetting env. episode 3097.000000, reward total was -20.000000. running mean: -20.110154\n",
            "resetting env. episode 3098.000000, reward total was -21.000000. running mean: -20.119052\n",
            "resetting env. episode 3099.000000, reward total was -21.000000. running mean: -20.127862\n",
            "resetting env. episode 3100.000000, reward total was -21.000000. running mean: -20.136583\n",
            "resetting env. episode 3101.000000, reward total was -19.000000. running mean: -20.125217\n",
            "resetting env. episode 3102.000000, reward total was -21.000000. running mean: -20.133965\n",
            "resetting env. episode 3103.000000, reward total was -21.000000. running mean: -20.142625\n",
            "resetting env. episode 3104.000000, reward total was -19.000000. running mean: -20.131199\n",
            "resetting env. episode 3105.000000, reward total was -21.000000. running mean: -20.139887\n",
            "resetting env. episode 3106.000000, reward total was -18.000000. running mean: -20.118488\n",
            "resetting env. episode 3107.000000, reward total was -21.000000. running mean: -20.127303\n",
            "resetting env. episode 3108.000000, reward total was -20.000000. running mean: -20.126030\n",
            "resetting env. episode 3109.000000, reward total was -19.000000. running mean: -20.114770\n",
            "resetting env. episode 3110.000000, reward total was -16.000000. running mean: -20.073622\n",
            "resetting env. episode 3111.000000, reward total was -20.000000. running mean: -20.072886\n",
            "resetting env. episode 3112.000000, reward total was -19.000000. running mean: -20.062157\n",
            "resetting env. episode 3113.000000, reward total was -21.000000. running mean: -20.071536\n",
            "resetting env. episode 3114.000000, reward total was -21.000000. running mean: -20.080820\n",
            "resetting env. episode 3115.000000, reward total was -21.000000. running mean: -20.090012\n",
            "resetting env. episode 3116.000000, reward total was -19.000000. running mean: -20.079112\n",
            "resetting env. episode 3117.000000, reward total was -21.000000. running mean: -20.088321\n",
            "resetting env. episode 3118.000000, reward total was -21.000000. running mean: -20.097438\n",
            "resetting env. episode 3119.000000, reward total was -20.000000. running mean: -20.096463\n",
            "resetting env. episode 3120.000000, reward total was -21.000000. running mean: -20.105499\n",
            "resetting env. episode 3121.000000, reward total was -20.000000. running mean: -20.104444\n",
            "resetting env. episode 3122.000000, reward total was -21.000000. running mean: -20.113399\n",
            "resetting env. episode 3123.000000, reward total was -20.000000. running mean: -20.112265\n",
            "resetting env. episode 3124.000000, reward total was -19.000000. running mean: -20.101143\n",
            "resetting env. episode 3125.000000, reward total was -20.000000. running mean: -20.100131\n",
            "resetting env. episode 3126.000000, reward total was -21.000000. running mean: -20.109130\n",
            "resetting env. episode 3127.000000, reward total was -21.000000. running mean: -20.118039\n",
            "resetting env. episode 3128.000000, reward total was -19.000000. running mean: -20.106858\n",
            "resetting env. episode 3129.000000, reward total was -21.000000. running mean: -20.115790\n",
            "resetting env. episode 3130.000000, reward total was -21.000000. running mean: -20.124632\n",
            "resetting env. episode 3131.000000, reward total was -20.000000. running mean: -20.123385\n",
            "resetting env. episode 3132.000000, reward total was -21.000000. running mean: -20.132152\n",
            "resetting env. episode 3133.000000, reward total was -21.000000. running mean: -20.140830\n",
            "resetting env. episode 3134.000000, reward total was -20.000000. running mean: -20.139422\n",
            "resetting env. episode 3135.000000, reward total was -20.000000. running mean: -20.138028\n",
            "resetting env. episode 3136.000000, reward total was -19.000000. running mean: -20.126647\n",
            "resetting env. episode 3137.000000, reward total was -20.000000. running mean: -20.125381\n",
            "resetting env. episode 3138.000000, reward total was -21.000000. running mean: -20.134127\n",
            "resetting env. episode 3139.000000, reward total was -20.000000. running mean: -20.132786\n",
            "resetting env. episode 3140.000000, reward total was -21.000000. running mean: -20.141458\n",
            "resetting env. episode 3141.000000, reward total was -21.000000. running mean: -20.150043\n",
            "resetting env. episode 3142.000000, reward total was -20.000000. running mean: -20.148543\n",
            "resetting env. episode 3143.000000, reward total was -21.000000. running mean: -20.157057\n",
            "resetting env. episode 3144.000000, reward total was -17.000000. running mean: -20.125487\n",
            "resetting env. episode 3145.000000, reward total was -19.000000. running mean: -20.114232\n",
            "resetting env. episode 3146.000000, reward total was -21.000000. running mean: -20.123090\n",
            "resetting env. episode 3147.000000, reward total was -20.000000. running mean: -20.121859\n",
            "resetting env. episode 3148.000000, reward total was -21.000000. running mean: -20.130640\n",
            "resetting env. episode 3149.000000, reward total was -20.000000. running mean: -20.129334\n",
            "resetting env. episode 3150.000000, reward total was -21.000000. running mean: -20.138040\n",
            "resetting env. episode 3151.000000, reward total was -19.000000. running mean: -20.126660\n",
            "resetting env. episode 3152.000000, reward total was -21.000000. running mean: -20.135393\n",
            "resetting env. episode 3153.000000, reward total was -21.000000. running mean: -20.144039\n",
            "resetting env. episode 3154.000000, reward total was -20.000000. running mean: -20.142599\n",
            "resetting env. episode 3155.000000, reward total was -21.000000. running mean: -20.151173\n",
            "resetting env. episode 3156.000000, reward total was -20.000000. running mean: -20.149661\n",
            "resetting env. episode 3157.000000, reward total was -21.000000. running mean: -20.158165\n",
            "resetting env. episode 3158.000000, reward total was -20.000000. running mean: -20.156583\n",
            "resetting env. episode 3159.000000, reward total was -21.000000. running mean: -20.165017\n",
            "resetting env. episode 3160.000000, reward total was -20.000000. running mean: -20.163367\n",
            "resetting env. episode 3161.000000, reward total was -20.000000. running mean: -20.161733\n",
            "resetting env. episode 3162.000000, reward total was -21.000000. running mean: -20.170116\n",
            "resetting env. episode 3163.000000, reward total was -21.000000. running mean: -20.178415\n",
            "resetting env. episode 3164.000000, reward total was -21.000000. running mean: -20.186631\n",
            "resetting env. episode 3165.000000, reward total was -21.000000. running mean: -20.194764\n",
            "resetting env. episode 3166.000000, reward total was -21.000000. running mean: -20.202817\n",
            "resetting env. episode 3167.000000, reward total was -19.000000. running mean: -20.190789\n",
            "resetting env. episode 3168.000000, reward total was -19.000000. running mean: -20.178881\n",
            "resetting env. episode 3169.000000, reward total was -21.000000. running mean: -20.187092\n",
            "resetting env. episode 3170.000000, reward total was -21.000000. running mean: -20.195221\n",
            "resetting env. episode 3171.000000, reward total was -21.000000. running mean: -20.203269\n",
            "resetting env. episode 3172.000000, reward total was -20.000000. running mean: -20.201236\n",
            "resetting env. episode 3173.000000, reward total was -21.000000. running mean: -20.209224\n",
            "resetting env. episode 3174.000000, reward total was -20.000000. running mean: -20.207132\n",
            "resetting env. episode 3175.000000, reward total was -21.000000. running mean: -20.215060\n",
            "resetting env. episode 3176.000000, reward total was -19.000000. running mean: -20.202910\n",
            "resetting env. episode 3177.000000, reward total was -19.000000. running mean: -20.190881\n",
            "resetting env. episode 3178.000000, reward total was -19.000000. running mean: -20.178972\n",
            "resetting env. episode 3179.000000, reward total was -21.000000. running mean: -20.187182\n",
            "resetting env. episode 3180.000000, reward total was -21.000000. running mean: -20.195310\n",
            "resetting env. episode 3181.000000, reward total was -20.000000. running mean: -20.193357\n",
            "resetting env. episode 3182.000000, reward total was -20.000000. running mean: -20.191424\n",
            "resetting env. episode 3183.000000, reward total was -19.000000. running mean: -20.179509\n",
            "resetting env. episode 3184.000000, reward total was -20.000000. running mean: -20.177714\n",
            "resetting env. episode 3185.000000, reward total was -21.000000. running mean: -20.185937\n",
            "resetting env. episode 3186.000000, reward total was -21.000000. running mean: -20.194078\n",
            "resetting env. episode 3187.000000, reward total was -21.000000. running mean: -20.202137\n",
            "resetting env. episode 3188.000000, reward total was -21.000000. running mean: -20.210116\n",
            "resetting env. episode 3189.000000, reward total was -21.000000. running mean: -20.218014\n",
            "resetting env. episode 3190.000000, reward total was -21.000000. running mean: -20.225834\n",
            "resetting env. episode 3191.000000, reward total was -17.000000. running mean: -20.193576\n",
            "resetting env. episode 3192.000000, reward total was -21.000000. running mean: -20.201640\n",
            "resetting env. episode 3193.000000, reward total was -20.000000. running mean: -20.199624\n",
            "resetting env. episode 3194.000000, reward total was -19.000000. running mean: -20.187627\n",
            "resetting env. episode 3195.000000, reward total was -20.000000. running mean: -20.185751\n",
            "resetting env. episode 3196.000000, reward total was -21.000000. running mean: -20.193894\n",
            "resetting env. episode 3197.000000, reward total was -20.000000. running mean: -20.191955\n",
            "resetting env. episode 3198.000000, reward total was -20.000000. running mean: -20.190035\n",
            "resetting env. episode 3199.000000, reward total was -19.000000. running mean: -20.178135\n",
            "resetting env. episode 3200.000000, reward total was -21.000000. running mean: -20.186354\n",
            "resetting env. episode 3201.000000, reward total was -20.000000. running mean: -20.184490\n",
            "resetting env. episode 3202.000000, reward total was -20.000000. running mean: -20.182645\n",
            "resetting env. episode 3203.000000, reward total was -19.000000. running mean: -20.170819\n",
            "resetting env. episode 3204.000000, reward total was -20.000000. running mean: -20.169110\n",
            "resetting env. episode 3205.000000, reward total was -21.000000. running mean: -20.177419\n",
            "resetting env. episode 3206.000000, reward total was -20.000000. running mean: -20.175645\n",
            "resetting env. episode 3207.000000, reward total was -21.000000. running mean: -20.183889\n",
            "resetting env. episode 3208.000000, reward total was -21.000000. running mean: -20.192050\n",
            "resetting env. episode 3209.000000, reward total was -21.000000. running mean: -20.200129\n",
            "resetting env. episode 3210.000000, reward total was -19.000000. running mean: -20.188128\n",
            "resetting env. episode 3211.000000, reward total was -21.000000. running mean: -20.196247\n",
            "resetting env. episode 3212.000000, reward total was -20.000000. running mean: -20.194284\n",
            "resetting env. episode 3213.000000, reward total was -20.000000. running mean: -20.192341\n",
            "resetting env. episode 3214.000000, reward total was -19.000000. running mean: -20.180418\n",
            "resetting env. episode 3215.000000, reward total was -20.000000. running mean: -20.178614\n",
            "resetting env. episode 3216.000000, reward total was -21.000000. running mean: -20.186828\n",
            "resetting env. episode 3217.000000, reward total was -20.000000. running mean: -20.184959\n",
            "resetting env. episode 3218.000000, reward total was -21.000000. running mean: -20.193110\n",
            "resetting env. episode 3219.000000, reward total was -21.000000. running mean: -20.201179\n",
            "resetting env. episode 3220.000000, reward total was -20.000000. running mean: -20.199167\n",
            "resetting env. episode 3221.000000, reward total was -20.000000. running mean: -20.197175\n",
            "resetting env. episode 3222.000000, reward total was -21.000000. running mean: -20.205204\n",
            "resetting env. episode 3223.000000, reward total was -21.000000. running mean: -20.213151\n",
            "resetting env. episode 3224.000000, reward total was -19.000000. running mean: -20.201020\n",
            "resetting env. episode 3225.000000, reward total was -21.000000. running mean: -20.209010\n",
            "resetting env. episode 3226.000000, reward total was -21.000000. running mean: -20.216920\n",
            "resetting env. episode 3227.000000, reward total was -20.000000. running mean: -20.214750\n",
            "resetting env. episode 3228.000000, reward total was -20.000000. running mean: -20.212603\n",
            "resetting env. episode 3229.000000, reward total was -19.000000. running mean: -20.200477\n",
            "resetting env. episode 3230.000000, reward total was -21.000000. running mean: -20.208472\n",
            "resetting env. episode 3231.000000, reward total was -21.000000. running mean: -20.216387\n",
            "resetting env. episode 3232.000000, reward total was -18.000000. running mean: -20.194224\n",
            "resetting env. episode 3233.000000, reward total was -20.000000. running mean: -20.192281\n",
            "resetting env. episode 3234.000000, reward total was -19.000000. running mean: -20.180359\n",
            "resetting env. episode 3235.000000, reward total was -19.000000. running mean: -20.168555\n",
            "resetting env. episode 3236.000000, reward total was -21.000000. running mean: -20.176869\n",
            "resetting env. episode 3237.000000, reward total was -19.000000. running mean: -20.165101\n",
            "resetting env. episode 3238.000000, reward total was -19.000000. running mean: -20.153450\n",
            "resetting env. episode 3239.000000, reward total was -21.000000. running mean: -20.161915\n",
            "resetting env. episode 3240.000000, reward total was -20.000000. running mean: -20.160296\n",
            "resetting env. episode 3241.000000, reward total was -19.000000. running mean: -20.148693\n",
            "resetting env. episode 3242.000000, reward total was -21.000000. running mean: -20.157206\n",
            "resetting env. episode 3243.000000, reward total was -19.000000. running mean: -20.145634\n",
            "resetting env. episode 3244.000000, reward total was -20.000000. running mean: -20.144178\n",
            "resetting env. episode 3245.000000, reward total was -19.000000. running mean: -20.132736\n",
            "resetting env. episode 3246.000000, reward total was -18.000000. running mean: -20.111409\n",
            "resetting env. episode 3247.000000, reward total was -21.000000. running mean: -20.120295\n",
            "resetting env. episode 3248.000000, reward total was -19.000000. running mean: -20.109092\n",
            "resetting env. episode 3249.000000, reward total was -20.000000. running mean: -20.108001\n",
            "resetting env. episode 3250.000000, reward total was -19.000000. running mean: -20.096921\n",
            "resetting env. episode 3251.000000, reward total was -21.000000. running mean: -20.105951\n",
            "resetting env. episode 3252.000000, reward total was -19.000000. running mean: -20.094892\n",
            "resetting env. episode 3253.000000, reward total was -20.000000. running mean: -20.093943\n",
            "resetting env. episode 3254.000000, reward total was -20.000000. running mean: -20.093004\n",
            "resetting env. episode 3255.000000, reward total was -19.000000. running mean: -20.082074\n",
            "resetting env. episode 3256.000000, reward total was -21.000000. running mean: -20.091253\n",
            "resetting env. episode 3257.000000, reward total was -21.000000. running mean: -20.100340\n",
            "resetting env. episode 3258.000000, reward total was -20.000000. running mean: -20.099337\n",
            "resetting env. episode 3259.000000, reward total was -21.000000. running mean: -20.108344\n",
            "resetting env. episode 3260.000000, reward total was -20.000000. running mean: -20.107260\n",
            "resetting env. episode 3261.000000, reward total was -20.000000. running mean: -20.106187\n",
            "resetting env. episode 3262.000000, reward total was -21.000000. running mean: -20.115126\n",
            "resetting env. episode 3263.000000, reward total was -19.000000. running mean: -20.103974\n",
            "resetting env. episode 3264.000000, reward total was -19.000000. running mean: -20.092935\n",
            "resetting env. episode 3265.000000, reward total was -20.000000. running mean: -20.092005\n",
            "resetting env. episode 3266.000000, reward total was -19.000000. running mean: -20.081085\n",
            "resetting env. episode 3267.000000, reward total was -21.000000. running mean: -20.090274\n",
            "resetting env. episode 3268.000000, reward total was -21.000000. running mean: -20.099372\n",
            "resetting env. episode 3269.000000, reward total was -18.000000. running mean: -20.078378\n",
            "resetting env. episode 3270.000000, reward total was -21.000000. running mean: -20.087594\n",
            "resetting env. episode 3271.000000, reward total was -19.000000. running mean: -20.076718\n",
            "resetting env. episode 3272.000000, reward total was -20.000000. running mean: -20.075951\n",
            "resetting env. episode 3273.000000, reward total was -21.000000. running mean: -20.085191\n",
            "resetting env. episode 3274.000000, reward total was -20.000000. running mean: -20.084340\n",
            "resetting env. episode 3275.000000, reward total was -20.000000. running mean: -20.083496\n",
            "resetting env. episode 3276.000000, reward total was -21.000000. running mean: -20.092661\n",
            "resetting env. episode 3277.000000, reward total was -20.000000. running mean: -20.091735\n",
            "resetting env. episode 3278.000000, reward total was -20.000000. running mean: -20.090817\n",
            "resetting env. episode 3279.000000, reward total was -20.000000. running mean: -20.089909\n",
            "resetting env. episode 3280.000000, reward total was -21.000000. running mean: -20.099010\n",
            "resetting env. episode 3281.000000, reward total was -20.000000. running mean: -20.098020\n",
            "resetting env. episode 3282.000000, reward total was -21.000000. running mean: -20.107040\n",
            "resetting env. episode 3283.000000, reward total was -20.000000. running mean: -20.105969\n",
            "resetting env. episode 3284.000000, reward total was -18.000000. running mean: -20.084910\n",
            "resetting env. episode 3285.000000, reward total was -21.000000. running mean: -20.094061\n",
            "resetting env. episode 3286.000000, reward total was -21.000000. running mean: -20.103120\n",
            "resetting env. episode 3287.000000, reward total was -18.000000. running mean: -20.082089\n",
            "resetting env. episode 3288.000000, reward total was -21.000000. running mean: -20.091268\n",
            "resetting env. episode 3289.000000, reward total was -21.000000. running mean: -20.100355\n",
            "resetting env. episode 3290.000000, reward total was -20.000000. running mean: -20.099352\n",
            "resetting env. episode 3291.000000, reward total was -20.000000. running mean: -20.098358\n",
            "resetting env. episode 3292.000000, reward total was -21.000000. running mean: -20.107374\n",
            "resetting env. episode 3293.000000, reward total was -21.000000. running mean: -20.116301\n",
            "resetting env. episode 3294.000000, reward total was -20.000000. running mean: -20.115138\n",
            "resetting env. episode 3295.000000, reward total was -19.000000. running mean: -20.103986\n",
            "resetting env. episode 3296.000000, reward total was -21.000000. running mean: -20.112946\n",
            "resetting env. episode 3297.000000, reward total was -19.000000. running mean: -20.101817\n",
            "resetting env. episode 3298.000000, reward total was -20.000000. running mean: -20.100799\n",
            "resetting env. episode 3299.000000, reward total was -21.000000. running mean: -20.109791\n",
            "resetting env. episode 3300.000000, reward total was -21.000000. running mean: -20.118693\n",
            "resetting env. episode 3301.000000, reward total was -20.000000. running mean: -20.117506\n",
            "resetting env. episode 3302.000000, reward total was -20.000000. running mean: -20.116331\n",
            "resetting env. episode 3303.000000, reward total was -18.000000. running mean: -20.095168\n",
            "resetting env. episode 3304.000000, reward total was -21.000000. running mean: -20.104216\n",
            "resetting env. episode 3305.000000, reward total was -20.000000. running mean: -20.103174\n",
            "resetting env. episode 3306.000000, reward total was -21.000000. running mean: -20.112142\n",
            "resetting env. episode 3307.000000, reward total was -20.000000. running mean: -20.111021\n",
            "resetting env. episode 3308.000000, reward total was -20.000000. running mean: -20.109910\n",
            "resetting env. episode 3309.000000, reward total was -20.000000. running mean: -20.108811\n",
            "resetting env. episode 3310.000000, reward total was -19.000000. running mean: -20.097723\n",
            "resetting env. episode 3311.000000, reward total was -21.000000. running mean: -20.106746\n",
            "resetting env. episode 3312.000000, reward total was -21.000000. running mean: -20.115679\n",
            "resetting env. episode 3313.000000, reward total was -20.000000. running mean: -20.114522\n",
            "resetting env. episode 3314.000000, reward total was -21.000000. running mean: -20.123377\n",
            "resetting env. episode 3315.000000, reward total was -21.000000. running mean: -20.132143\n",
            "resetting env. episode 3316.000000, reward total was -21.000000. running mean: -20.140821\n",
            "resetting env. episode 3317.000000, reward total was -21.000000. running mean: -20.149413\n",
            "resetting env. episode 3318.000000, reward total was -21.000000. running mean: -20.157919\n",
            "resetting env. episode 3319.000000, reward total was -19.000000. running mean: -20.146340\n",
            "resetting env. episode 3320.000000, reward total was -20.000000. running mean: -20.144876\n",
            "resetting env. episode 3321.000000, reward total was -20.000000. running mean: -20.143428\n",
            "resetting env. episode 3322.000000, reward total was -19.000000. running mean: -20.131993\n",
            "resetting env. episode 3323.000000, reward total was -21.000000. running mean: -20.140673\n",
            "resetting env. episode 3324.000000, reward total was -21.000000. running mean: -20.149267\n",
            "resetting env. episode 3325.000000, reward total was -21.000000. running mean: -20.157774\n",
            "resetting env. episode 3326.000000, reward total was -19.000000. running mean: -20.146196\n",
            "resetting env. episode 3327.000000, reward total was -19.000000. running mean: -20.134734\n",
            "resetting env. episode 3328.000000, reward total was -19.000000. running mean: -20.123387\n",
            "resetting env. episode 3329.000000, reward total was -21.000000. running mean: -20.132153\n",
            "resetting env. episode 3330.000000, reward total was -19.000000. running mean: -20.120832\n",
            "resetting env. episode 3331.000000, reward total was -19.000000. running mean: -20.109623\n",
            "resetting env. episode 3332.000000, reward total was -21.000000. running mean: -20.118527\n",
            "resetting env. episode 3333.000000, reward total was -20.000000. running mean: -20.117342\n",
            "resetting env. episode 3334.000000, reward total was -21.000000. running mean: -20.126168\n",
            "resetting env. episode 3335.000000, reward total was -20.000000. running mean: -20.124907\n",
            "resetting env. episode 3336.000000, reward total was -20.000000. running mean: -20.123658\n",
            "resetting env. episode 3337.000000, reward total was -21.000000. running mean: -20.132421\n",
            "resetting env. episode 3338.000000, reward total was -18.000000. running mean: -20.111097\n",
            "resetting env. episode 3339.000000, reward total was -21.000000. running mean: -20.119986\n",
            "resetting env. episode 3340.000000, reward total was -21.000000. running mean: -20.128786\n",
            "resetting env. episode 3341.000000, reward total was -20.000000. running mean: -20.127498\n",
            "resetting env. episode 3342.000000, reward total was -21.000000. running mean: -20.136223\n",
            "resetting env. episode 3343.000000, reward total was -21.000000. running mean: -20.144861\n",
            "resetting env. episode 3344.000000, reward total was -21.000000. running mean: -20.153412\n",
            "resetting env. episode 3345.000000, reward total was -19.000000. running mean: -20.141878\n",
            "resetting env. episode 3346.000000, reward total was -20.000000. running mean: -20.140459\n",
            "resetting env. episode 3347.000000, reward total was -20.000000. running mean: -20.139055\n",
            "resetting env. episode 3348.000000, reward total was -20.000000. running mean: -20.137664\n",
            "resetting env. episode 3349.000000, reward total was -21.000000. running mean: -20.146288\n",
            "resetting env. episode 3350.000000, reward total was -20.000000. running mean: -20.144825\n",
            "resetting env. episode 3351.000000, reward total was -18.000000. running mean: -20.123376\n",
            "resetting env. episode 3352.000000, reward total was -20.000000. running mean: -20.122143\n",
            "resetting env. episode 3353.000000, reward total was -21.000000. running mean: -20.130921\n",
            "resetting env. episode 3354.000000, reward total was -20.000000. running mean: -20.129612\n",
            "resetting env. episode 3355.000000, reward total was -20.000000. running mean: -20.128316\n",
            "resetting env. episode 3356.000000, reward total was -18.000000. running mean: -20.107033\n",
            "resetting env. episode 3357.000000, reward total was -21.000000. running mean: -20.115962\n",
            "resetting env. episode 3358.000000, reward total was -20.000000. running mean: -20.114803\n",
            "resetting env. episode 3359.000000, reward total was -19.000000. running mean: -20.103655\n",
            "resetting env. episode 3360.000000, reward total was -18.000000. running mean: -20.082618\n",
            "resetting env. episode 3361.000000, reward total was -21.000000. running mean: -20.091792\n",
            "resetting env. episode 3362.000000, reward total was -20.000000. running mean: -20.090874\n",
            "resetting env. episode 3363.000000, reward total was -19.000000. running mean: -20.079965\n",
            "resetting env. episode 3364.000000, reward total was -20.000000. running mean: -20.079166\n",
            "resetting env. episode 3365.000000, reward total was -21.000000. running mean: -20.088374\n",
            "resetting env. episode 3366.000000, reward total was -19.000000. running mean: -20.077490\n",
            "resetting env. episode 3367.000000, reward total was -21.000000. running mean: -20.086715\n",
            "resetting env. episode 3368.000000, reward total was -21.000000. running mean: -20.095848\n",
            "resetting env. episode 3369.000000, reward total was -18.000000. running mean: -20.074890\n",
            "resetting env. episode 3370.000000, reward total was -17.000000. running mean: -20.044141\n",
            "resetting env. episode 3371.000000, reward total was -20.000000. running mean: -20.043700\n",
            "resetting env. episode 3372.000000, reward total was -21.000000. running mean: -20.053263\n",
            "resetting env. episode 3373.000000, reward total was -21.000000. running mean: -20.062730\n",
            "resetting env. episode 3374.000000, reward total was -21.000000. running mean: -20.072103\n",
            "resetting env. episode 3375.000000, reward total was -19.000000. running mean: -20.061382\n",
            "resetting env. episode 3376.000000, reward total was -20.000000. running mean: -20.060768\n",
            "resetting env. episode 3377.000000, reward total was -20.000000. running mean: -20.060160\n",
            "resetting env. episode 3378.000000, reward total was -21.000000. running mean: -20.069558\n",
            "resetting env. episode 3379.000000, reward total was -21.000000. running mean: -20.078863\n",
            "resetting env. episode 3380.000000, reward total was -18.000000. running mean: -20.058074\n",
            "resetting env. episode 3381.000000, reward total was -19.000000. running mean: -20.047494\n",
            "resetting env. episode 3382.000000, reward total was -21.000000. running mean: -20.057019\n",
            "resetting env. episode 3383.000000, reward total was -20.000000. running mean: -20.056448\n",
            "resetting env. episode 3384.000000, reward total was -21.000000. running mean: -20.065884\n",
            "resetting env. episode 3385.000000, reward total was -21.000000. running mean: -20.075225\n",
            "resetting env. episode 3386.000000, reward total was -18.000000. running mean: -20.054473\n",
            "resetting env. episode 3387.000000, reward total was -21.000000. running mean: -20.063928\n",
            "resetting env. episode 3388.000000, reward total was -21.000000. running mean: -20.073289\n",
            "resetting env. episode 3389.000000, reward total was -19.000000. running mean: -20.062556\n",
            "resetting env. episode 3390.000000, reward total was -21.000000. running mean: -20.071930\n",
            "resetting env. episode 3391.000000, reward total was -21.000000. running mean: -20.081211\n",
            "resetting env. episode 3392.000000, reward total was -21.000000. running mean: -20.090399\n",
            "resetting env. episode 3393.000000, reward total was -21.000000. running mean: -20.099495\n",
            "resetting env. episode 3394.000000, reward total was -19.000000. running mean: -20.088500\n",
            "resetting env. episode 3395.000000, reward total was -21.000000. running mean: -20.097615\n",
            "resetting env. episode 3396.000000, reward total was -20.000000. running mean: -20.096639\n",
            "resetting env. episode 3397.000000, reward total was -19.000000. running mean: -20.085672\n",
            "resetting env. episode 3398.000000, reward total was -19.000000. running mean: -20.074816\n",
            "resetting env. episode 3399.000000, reward total was -21.000000. running mean: -20.084068\n",
            "resetting env. episode 3400.000000, reward total was -21.000000. running mean: -20.093227\n",
            "resetting env. episode 3401.000000, reward total was -17.000000. running mean: -20.062295\n",
            "resetting env. episode 3402.000000, reward total was -21.000000. running mean: -20.071672\n",
            "resetting env. episode 3403.000000, reward total was -17.000000. running mean: -20.040955\n",
            "resetting env. episode 3404.000000, reward total was -20.000000. running mean: -20.040545\n",
            "resetting env. episode 3405.000000, reward total was -20.000000. running mean: -20.040140\n",
            "resetting env. episode 3406.000000, reward total was -18.000000. running mean: -20.019739\n",
            "resetting env. episode 3407.000000, reward total was -20.000000. running mean: -20.019541\n",
            "resetting env. episode 3408.000000, reward total was -19.000000. running mean: -20.009346\n",
            "resetting env. episode 3409.000000, reward total was -20.000000. running mean: -20.009252\n",
            "resetting env. episode 3410.000000, reward total was -21.000000. running mean: -20.019160\n",
            "resetting env. episode 3411.000000, reward total was -20.000000. running mean: -20.018968\n",
            "resetting env. episode 3412.000000, reward total was -21.000000. running mean: -20.028779\n",
            "resetting env. episode 3413.000000, reward total was -21.000000. running mean: -20.038491\n",
            "resetting env. episode 3414.000000, reward total was -19.000000. running mean: -20.028106\n",
            "resetting env. episode 3415.000000, reward total was -20.000000. running mean: -20.027825\n",
            "resetting env. episode 3416.000000, reward total was -20.000000. running mean: -20.027547\n",
            "resetting env. episode 3417.000000, reward total was -20.000000. running mean: -20.027271\n",
            "resetting env. episode 3418.000000, reward total was -20.000000. running mean: -20.026998\n",
            "resetting env. episode 3419.000000, reward total was -18.000000. running mean: -20.006728\n",
            "resetting env. episode 3420.000000, reward total was -21.000000. running mean: -20.016661\n",
            "resetting env. episode 3421.000000, reward total was -20.000000. running mean: -20.016494\n",
            "resetting env. episode 3422.000000, reward total was -20.000000. running mean: -20.016330\n",
            "resetting env. episode 3423.000000, reward total was -19.000000. running mean: -20.006166\n",
            "resetting env. episode 3424.000000, reward total was -18.000000. running mean: -19.986105\n",
            "resetting env. episode 3425.000000, reward total was -20.000000. running mean: -19.986244\n",
            "resetting env. episode 3426.000000, reward total was -20.000000. running mean: -19.986381\n",
            "resetting env. episode 3427.000000, reward total was -21.000000. running mean: -19.996517\n",
            "resetting env. episode 3428.000000, reward total was -20.000000. running mean: -19.996552\n",
            "resetting env. episode 3429.000000, reward total was -19.000000. running mean: -19.986587\n",
            "resetting env. episode 3430.000000, reward total was -20.000000. running mean: -19.986721\n",
            "resetting env. episode 3431.000000, reward total was -19.000000. running mean: -19.976854\n",
            "resetting env. episode 3432.000000, reward total was -21.000000. running mean: -19.987085\n",
            "resetting env. episode 3433.000000, reward total was -20.000000. running mean: -19.987214\n",
            "resetting env. episode 3434.000000, reward total was -20.000000. running mean: -19.987342\n",
            "resetting env. episode 3435.000000, reward total was -20.000000. running mean: -19.987469\n",
            "resetting env. episode 3436.000000, reward total was -21.000000. running mean: -19.997594\n",
            "resetting env. episode 3437.000000, reward total was -20.000000. running mean: -19.997618\n",
            "resetting env. episode 3438.000000, reward total was -21.000000. running mean: -20.007642\n",
            "resetting env. episode 3439.000000, reward total was -20.000000. running mean: -20.007565\n",
            "resetting env. episode 3440.000000, reward total was -21.000000. running mean: -20.017490\n",
            "resetting env. episode 3441.000000, reward total was -19.000000. running mean: -20.007315\n",
            "resetting env. episode 3442.000000, reward total was -20.000000. running mean: -20.007242\n",
            "resetting env. episode 3443.000000, reward total was -21.000000. running mean: -20.017169\n",
            "resetting env. episode 3444.000000, reward total was -21.000000. running mean: -20.026998\n",
            "resetting env. episode 3445.000000, reward total was -21.000000. running mean: -20.036728\n",
            "resetting env. episode 3446.000000, reward total was -21.000000. running mean: -20.046360\n",
            "resetting env. episode 3447.000000, reward total was -20.000000. running mean: -20.045897\n",
            "resetting env. episode 3448.000000, reward total was -21.000000. running mean: -20.055438\n",
            "resetting env. episode 3449.000000, reward total was -18.000000. running mean: -20.034883\n",
            "resetting env. episode 3450.000000, reward total was -21.000000. running mean: -20.044535\n",
            "resetting env. episode 3451.000000, reward total was -21.000000. running mean: -20.054089\n",
            "resetting env. episode 3452.000000, reward total was -20.000000. running mean: -20.053548\n",
            "resetting env. episode 3453.000000, reward total was -19.000000. running mean: -20.043013\n",
            "resetting env. episode 3454.000000, reward total was -20.000000. running mean: -20.042583\n",
            "resetting env. episode 3455.000000, reward total was -21.000000. running mean: -20.052157\n",
            "resetting env. episode 3456.000000, reward total was -20.000000. running mean: -20.051635\n",
            "resetting env. episode 3457.000000, reward total was -21.000000. running mean: -20.061119\n",
            "resetting env. episode 3458.000000, reward total was -19.000000. running mean: -20.050508\n",
            "resetting env. episode 3459.000000, reward total was -21.000000. running mean: -20.060003\n",
            "resetting env. episode 3460.000000, reward total was -21.000000. running mean: -20.069403\n",
            "resetting env. episode 3461.000000, reward total was -20.000000. running mean: -20.068709\n",
            "resetting env. episode 3462.000000, reward total was -21.000000. running mean: -20.078022\n",
            "resetting env. episode 3463.000000, reward total was -21.000000. running mean: -20.087241\n",
            "resetting env. episode 3464.000000, reward total was -21.000000. running mean: -20.096369\n",
            "resetting env. episode 3465.000000, reward total was -21.000000. running mean: -20.105405\n",
            "resetting env. episode 3466.000000, reward total was -19.000000. running mean: -20.094351\n",
            "resetting env. episode 3467.000000, reward total was -19.000000. running mean: -20.083408\n",
            "resetting env. episode 3468.000000, reward total was -19.000000. running mean: -20.072574\n",
            "resetting env. episode 3469.000000, reward total was -19.000000. running mean: -20.061848\n",
            "resetting env. episode 3470.000000, reward total was -21.000000. running mean: -20.071229\n",
            "resetting env. episode 3471.000000, reward total was -21.000000. running mean: -20.080517\n",
            "resetting env. episode 3472.000000, reward total was -18.000000. running mean: -20.059712\n",
            "resetting env. episode 3473.000000, reward total was -21.000000. running mean: -20.069115\n",
            "resetting env. episode 3474.000000, reward total was -18.000000. running mean: -20.048424\n",
            "resetting env. episode 3475.000000, reward total was -21.000000. running mean: -20.057939\n",
            "resetting env. episode 3476.000000, reward total was -21.000000. running mean: -20.067360\n",
            "resetting env. episode 3477.000000, reward total was -20.000000. running mean: -20.066686\n",
            "resetting env. episode 3478.000000, reward total was -21.000000. running mean: -20.076020\n",
            "resetting env. episode 3479.000000, reward total was -21.000000. running mean: -20.085259\n",
            "resetting env. episode 3480.000000, reward total was -21.000000. running mean: -20.094407\n",
            "resetting env. episode 3481.000000, reward total was -19.000000. running mean: -20.083463\n",
            "resetting env. episode 3482.000000, reward total was -21.000000. running mean: -20.092628\n",
            "resetting env. episode 3483.000000, reward total was -20.000000. running mean: -20.091702\n",
            "resetting env. episode 3484.000000, reward total was -20.000000. running mean: -20.090785\n",
            "resetting env. episode 3485.000000, reward total was -21.000000. running mean: -20.099877\n",
            "resetting env. episode 3486.000000, reward total was -19.000000. running mean: -20.088878\n",
            "resetting env. episode 3487.000000, reward total was -19.000000. running mean: -20.077989\n",
            "resetting env. episode 3488.000000, reward total was -18.000000. running mean: -20.057209\n",
            "resetting env. episode 3489.000000, reward total was -18.000000. running mean: -20.036637\n",
            "resetting env. episode 3490.000000, reward total was -18.000000. running mean: -20.016271\n",
            "resetting env. episode 3491.000000, reward total was -21.000000. running mean: -20.026108\n",
            "resetting env. episode 3492.000000, reward total was -20.000000. running mean: -20.025847\n",
            "resetting env. episode 3493.000000, reward total was -21.000000. running mean: -20.035589\n",
            "resetting env. episode 3494.000000, reward total was -21.000000. running mean: -20.045233\n",
            "resetting env. episode 3495.000000, reward total was -20.000000. running mean: -20.044780\n",
            "resetting env. episode 3496.000000, reward total was -21.000000. running mean: -20.054333\n",
            "resetting env. episode 3497.000000, reward total was -21.000000. running mean: -20.063789\n",
            "resetting env. episode 3498.000000, reward total was -21.000000. running mean: -20.073151\n",
            "resetting env. episode 3499.000000, reward total was -17.000000. running mean: -20.042420\n",
            "resetting env. episode 3500.000000, reward total was -21.000000. running mean: -20.051996\n",
            "CPU times: user 2h 49min 30s, sys: 1h 18min 12s, total: 4h 7min 42s\n",
            "Wall time: 2h 10min 34s\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "cHYCDYwhlVLV"
      },
      "cell_type": "code",
      "source": [
        "#%time hist2 = train_model(env, model, total_episodes=500)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8fheN9DRlWXQ",
        "outputId": "8dd54be3-309e-4ce2-ea14-d540949d38a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "cell_type": "code",
      "source": [
        "play_game(env, model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode finished without success, accumulated reward = -8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 320x420 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9AxOcQhIsKow"
      },
      "cell_type": "code",
      "source": [
        "#%time hist3 = train_model(env, model, total_episodes=1500)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w2NblmwDsL3y"
      },
      "cell_type": "code",
      "source": [
        "#play_game(env, model)"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}